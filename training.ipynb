{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import mlflow\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# %run ../utils/utils-graph.ipynb\n",
    "\n",
    "global baseField\n",
    "baseField = \"like_label\"\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "global start_time\n",
    "start_time = datetime.now()\n",
    "print(xgb.__version__)\n",
    "print(start_time)\n"
   ],
   "metadata": {
    "gather": {
     "logged": 1761149401686
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:33:45.668265Z",
     "start_time": "2025-12-04T20:33:45.656546Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.2\n",
      "2025-12-04 15:33:45.664379\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "source": [
    "# time_train = 'bucketN_0'\n",
    "\n",
    "# os.system('cp ../data_and_models/'+time_train+'/x_train.pkl  ../data/')\n",
    "# os.system('cp ../data_and_models/'+time_train+'/x_test.pkl  ../data/')\n",
    "\n",
    "# os.system('cp ../data_and_models/'+time_train+'/y_train.pkl  ../data/')\n",
    "# os.system('cp ../data_and_models/'+time_train+'/y_test.pkl  ../data/') \n",
    "\n",
    "# os.system('cp ../data_and_models/'+time_train+'/cat_ordinal_encoder.pkl  ../data/') \n",
    "# os.system('cp ../data_and_models/'+time_train+'/training_categories_array.pkl  ../data/') "
   ],
   "metadata": {
    "gather": {
     "logged": 1761149401834
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:27:20.710155Z",
     "start_time": "2025-12-04T20:27:20.701298Z"
    }
   },
   "outputs": [],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "source": [
    "X_train_path = \"./data/x_train.pkl\"\n",
    "y_train_path = \"./data/y_train.pkl\"\n",
    "\n",
    "X_train = pd.read_pickle(X_train_path)\n",
    "# exclude_fields = [\"timestamp\", \"OriginalPaymentId\", \"void-success\", \"capture-success\", \"row_id\", \"Tenants_tntid\"]\n",
    "#\n",
    "# X_train.drop(exclude_fields, axis=1, inplace=True)\n",
    "\n",
    "y_train = pd.read_pickle(y_train_path)[baseField]"
   ],
   "metadata": {
    "gather": {
     "logged": 1761149402690
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:27:20.768011Z",
     "start_time": "2025-12-04T20:27:20.758450Z"
    }
   },
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Train Size X:\",len(X_train))\n",
    "print(\"Train Size Y:\",len(y_train))\n"
   ],
   "metadata": {
    "gather": {
     "logged": 1761149402827
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:27:20.840700Z",
     "start_time": "2025-12-04T20:27:20.821766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Size X: 3721\n",
      "Train Size Y: 3721\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "source": [
    "y_train.describe()"
   ],
   "metadata": {
    "gather": {
     "logged": 1761149402996
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:27:20.928174Z",
     "start_time": "2025-12-04T20:27:20.902521Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3721.000000\n",
       "mean        0.332438\n",
       "std         0.471150\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         1.000000\n",
       "max         1.000000\n",
       "Name: like_label, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "spw = y_train.value_counts()[0]/y_train.value_counts()[1]\n",
    "print(\"======= TRAIN =======\")\n",
    "print(\"positive: \", y_train.value_counts()[1])\n",
    "print(\"negative: \", y_train.value_counts()[0])\n",
    "spw = math.sqrt(spw)\n",
    "print(\"SPW: \",spw)\n",
    "print(\"==============\")"
   ],
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1761149403132
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:27:20.998591Z",
     "start_time": "2025-12-04T20:27:20.980384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= TRAIN =======\n",
      "positive:  1237\n",
      "negative:  2484\n",
      "SPW:  1.417068831910957\n",
      "==============\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "source": [
    "features_list = sorted(X_train.columns.tolist())\n",
    "exclude_list = [baseField, 'mb_id']\n",
    "features_list = [x for x in features_list if x not in exclude_list]\n",
    "\n",
    "print(features_list)\n",
    "print(len(features_list))"
   ],
   "metadata": {
    "gather": {
     "logged": 1761149403266
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:27:21.118931Z",
     "start_time": "2025-12-04T20:27:21.106281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chroma_A', 'chroma_A#', 'chroma_B', 'chroma_C', 'chroma_C#', 'chroma_D', 'chroma_D#', 'chroma_E', 'chroma_F', 'chroma_F#', 'chroma_G', 'chroma_G#', 'genre', 'mfcc_1', 'mfcc_10', 'mfcc_11', 'mfcc_12', 'mfcc_13', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7', 'mfcc_8', 'mfcc_9', 'rms', 'spectral_centroid', 'spectral_rolloff', 'zcr']\n",
      "30\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "source": [
    "X_train = X_train[features_list]"
   ],
   "metadata": {
    "gather": {
     "logged": 1761149403401
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:27:21.163887Z",
     "start_time": "2025-12-04T20:27:21.156910Z"
    }
   },
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "source": [
    "X_train.info(verbose=True, show_counts=True)"
   ],
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1761149403552
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:27:21.224344Z",
     "start_time": "2025-12-04T20:27:21.211244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3721 entries, 5477 to 5141\n",
      "Data columns (total 30 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   chroma_A           3721 non-null   float64 \n",
      " 1   chroma_A#          3721 non-null   float64 \n",
      " 2   chroma_B           3721 non-null   float64 \n",
      " 3   chroma_C           3721 non-null   float64 \n",
      " 4   chroma_C#          3721 non-null   float64 \n",
      " 5   chroma_D           3721 non-null   float64 \n",
      " 6   chroma_D#          3721 non-null   float64 \n",
      " 7   chroma_E           3721 non-null   float64 \n",
      " 8   chroma_F           3721 non-null   float64 \n",
      " 9   chroma_F#          3721 non-null   float64 \n",
      " 10  chroma_G           3721 non-null   float64 \n",
      " 11  chroma_G#          3721 non-null   float64 \n",
      " 12  genre              3721 non-null   category\n",
      " 13  mfcc_1             3721 non-null   float64 \n",
      " 14  mfcc_10            3721 non-null   float64 \n",
      " 15  mfcc_11            3721 non-null   float64 \n",
      " 16  mfcc_12            3721 non-null   float64 \n",
      " 17  mfcc_13            3721 non-null   float64 \n",
      " 18  mfcc_2             3721 non-null   float64 \n",
      " 19  mfcc_3             3721 non-null   float64 \n",
      " 20  mfcc_4             3721 non-null   float64 \n",
      " 21  mfcc_5             3721 non-null   float64 \n",
      " 22  mfcc_6             3721 non-null   float64 \n",
      " 23  mfcc_7             3721 non-null   float64 \n",
      " 24  mfcc_8             3721 non-null   float64 \n",
      " 25  mfcc_9             3721 non-null   float64 \n",
      " 26  rms                3721 non-null   float64 \n",
      " 27  spectral_centroid  3721 non-null   float64 \n",
      " 28  spectral_rolloff   3721 non-null   float64 \n",
      " 29  zcr                3721 non-null   float64 \n",
      "dtypes: category(1), float64(29)\n",
      "memory usage: 880.7 KB\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "### Search Hyper parameters\n",
    "if False:\n",
    "    rs_param_grid = {\n",
    "        'alpha': range(5, 30, 5),\n",
    "        'colsample_bytree': stats.uniform(0.2, 1),\n",
    "        'gamma': stats.uniform(0, 0.5),\n",
    "        'lambda': stats.uniform(0, 1.5),\n",
    "        'learning_rate' : stats.uniform(0.01, 0.5),\n",
    "        'max_depth': [5, 6, 7, 8, 9, 10, 11],\n",
    "        'min_child_weight' : [ 1, 3],\n",
    "        'n_estimators': range(200, 800, 50),\n",
    "        'scale_pos_weight': stats.uniform(0.5*spw, 1.5*spw),\n",
    "        'subsample' : stats.uniform(0.6, 1),\n",
    "    }\n",
    "    cv_p = 4\n",
    "    n_iter_p = 500\n",
    "\n",
    "    xgb_clf = xgb.XGBClassifier(\n",
    "    enable_categorical=True,\n",
    "    verbosity=0,\n",
    "    )\n",
    "\n",
    "    xgb_rs = RandomizedSearchCV(\n",
    "        estimator=xgb_clf,\n",
    "        param_distributions=rs_param_grid,\n",
    "        cv=cv_p,\n",
    "        n_iter=n_iter_p,\n",
    "        verbose=2\n",
    "    )\n",
    "    xgb_rs.fit(X_train, y_train)\n",
    "\n",
    "    # Print the best parameters and highest accuracy\n",
    "    print(\"Best parameters found: \", xgb_rs.best_params_)\n",
    "    print(\"Best accuracy found: \", xgb_rs.best_score_)\n",
    "    best_parameters = xgb_rs.best_params_\n"
   ],
   "metadata": {
    "gather": {
     "logged": 1761149403696
    },
    "editable": true,
    "run_control": {
     "frozen": false
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:31:52.253085Z",
     "start_time": "2025-12-04T20:27:21.265745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 500 candidates, totalling 2000 fits\n",
      "[CV] END alpha=25, colsample_bytree=0.9924589713136944, gamma=0.28800199180157177, lambda=0.7537213544910234, learning_rate=0.400047118153516, max_depth=7, min_child_weight=3, n_estimators=250, scale_pos_weight=1.307730340526554, subsample=1.4586230697140565; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.9924589713136944, gamma=0.28800199180157177, lambda=0.7537213544910234, learning_rate=0.400047118153516, max_depth=7, min_child_weight=3, n_estimators=250, scale_pos_weight=1.307730340526554, subsample=1.4586230697140565; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.9924589713136944, gamma=0.28800199180157177, lambda=0.7537213544910234, learning_rate=0.400047118153516, max_depth=7, min_child_weight=3, n_estimators=250, scale_pos_weight=1.307730340526554, subsample=1.4586230697140565; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.9924589713136944, gamma=0.28800199180157177, lambda=0.7537213544910234, learning_rate=0.400047118153516, max_depth=7, min_child_weight=3, n_estimators=250, scale_pos_weight=1.307730340526554, subsample=1.4586230697140565; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.4539138620434043, gamma=0.4344449781556742, lambda=0.4755480119377141, learning_rate=0.33702769561375817, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=2.35511356303661, subsample=0.9848873497655716; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.4539138620434043, gamma=0.4344449781556742, lambda=0.4755480119377141, learning_rate=0.33702769561375817, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=2.35511356303661, subsample=0.9848873497655716; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.4539138620434043, gamma=0.4344449781556742, lambda=0.4755480119377141, learning_rate=0.33702769561375817, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=2.35511356303661, subsample=0.9848873497655716; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.4539138620434043, gamma=0.4344449781556742, lambda=0.4755480119377141, learning_rate=0.33702769561375817, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=2.35511356303661, subsample=0.9848873497655716; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=1.1295177973835338, gamma=0.210723599141388, lambda=1.426906481740712, learning_rate=0.3082349149580514, max_depth=6, min_child_weight=1, n_estimators=350, scale_pos_weight=1.1747831036498615, subsample=1.4511106868014187; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1295177973835338, gamma=0.210723599141388, lambda=1.426906481740712, learning_rate=0.3082349149580514, max_depth=6, min_child_weight=1, n_estimators=350, scale_pos_weight=1.1747831036498615, subsample=1.4511106868014187; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1295177973835338, gamma=0.210723599141388, lambda=1.426906481740712, learning_rate=0.3082349149580514, max_depth=6, min_child_weight=1, n_estimators=350, scale_pos_weight=1.1747831036498615, subsample=1.4511106868014187; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1295177973835338, gamma=0.210723599141388, lambda=1.426906481740712, learning_rate=0.3082349149580514, max_depth=6, min_child_weight=1, n_estimators=350, scale_pos_weight=1.1747831036498615, subsample=1.4511106868014187; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1149946188443343, gamma=0.12645106147631846, lambda=1.1974280363502792, learning_rate=0.06514177839027845, max_depth=5, min_child_weight=1, n_estimators=400, scale_pos_weight=2.025059447948734, subsample=1.1117487065755194; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1149946188443343, gamma=0.12645106147631846, lambda=1.1974280363502792, learning_rate=0.06514177839027845, max_depth=5, min_child_weight=1, n_estimators=400, scale_pos_weight=2.025059447948734, subsample=1.1117487065755194; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1149946188443343, gamma=0.12645106147631846, lambda=1.1974280363502792, learning_rate=0.06514177839027845, max_depth=5, min_child_weight=1, n_estimators=400, scale_pos_weight=2.025059447948734, subsample=1.1117487065755194; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1149946188443343, gamma=0.12645106147631846, lambda=1.1974280363502792, learning_rate=0.06514177839027845, max_depth=5, min_child_weight=1, n_estimators=400, scale_pos_weight=2.025059447948734, subsample=1.1117487065755194; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9434842501640819, gamma=0.2095778052632657, lambda=1.0796857875741286, learning_rate=0.15094743939960847, max_depth=10, min_child_weight=1, n_estimators=250, scale_pos_weight=2.5777303710302317, subsample=1.5008795339614855; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9434842501640819, gamma=0.2095778052632657, lambda=1.0796857875741286, learning_rate=0.15094743939960847, max_depth=10, min_child_weight=1, n_estimators=250, scale_pos_weight=2.5777303710302317, subsample=1.5008795339614855; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9434842501640819, gamma=0.2095778052632657, lambda=1.0796857875741286, learning_rate=0.15094743939960847, max_depth=10, min_child_weight=1, n_estimators=250, scale_pos_weight=2.5777303710302317, subsample=1.5008795339614855; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9434842501640819, gamma=0.2095778052632657, lambda=1.0796857875741286, learning_rate=0.15094743939960847, max_depth=10, min_child_weight=1, n_estimators=250, scale_pos_weight=2.5777303710302317, subsample=1.5008795339614855; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.0243205557490906, gamma=0.32309941281186066, lambda=0.5323912713834291, learning_rate=0.11128811972528711, max_depth=10, min_child_weight=3, n_estimators=700, scale_pos_weight=1.7712323922361308, subsample=1.296824847657803; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.0243205557490906, gamma=0.32309941281186066, lambda=0.5323912713834291, learning_rate=0.11128811972528711, max_depth=10, min_child_weight=3, n_estimators=700, scale_pos_weight=1.7712323922361308, subsample=1.296824847657803; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.0243205557490906, gamma=0.32309941281186066, lambda=0.5323912713834291, learning_rate=0.11128811972528711, max_depth=10, min_child_weight=3, n_estimators=700, scale_pos_weight=1.7712323922361308, subsample=1.296824847657803; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.0243205557490906, gamma=0.32309941281186066, lambda=0.5323912713834291, learning_rate=0.11128811972528711, max_depth=10, min_child_weight=3, n_estimators=700, scale_pos_weight=1.7712323922361308, subsample=1.296824847657803; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.20064262185061982, gamma=0.2709970515374704, lambda=1.4024281209348277, learning_rate=0.09500714760344169, max_depth=11, min_child_weight=3, n_estimators=600, scale_pos_weight=2.551576617984339, subsample=1.2461041517974851; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.20064262185061982, gamma=0.2709970515374704, lambda=1.4024281209348277, learning_rate=0.09500714760344169, max_depth=11, min_child_weight=3, n_estimators=600, scale_pos_weight=2.551576617984339, subsample=1.2461041517974851; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.20064262185061982, gamma=0.2709970515374704, lambda=1.4024281209348277, learning_rate=0.09500714760344169, max_depth=11, min_child_weight=3, n_estimators=600, scale_pos_weight=2.551576617984339, subsample=1.2461041517974851; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.20064262185061982, gamma=0.2709970515374704, lambda=1.4024281209348277, learning_rate=0.09500714760344169, max_depth=11, min_child_weight=3, n_estimators=600, scale_pos_weight=2.551576617984339, subsample=1.2461041517974851; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.2672664710652192, gamma=0.05537359541715664, lambda=0.06117574676187476, learning_rate=0.24883560539325922, max_depth=6, min_child_weight=1, n_estimators=750, scale_pos_weight=2.1166866733784966, subsample=0.8957638724301831; total time=   0.4s\n",
      "[CV] END alpha=5, colsample_bytree=0.2672664710652192, gamma=0.05537359541715664, lambda=0.06117574676187476, learning_rate=0.24883560539325922, max_depth=6, min_child_weight=1, n_estimators=750, scale_pos_weight=2.1166866733784966, subsample=0.8957638724301831; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.2672664710652192, gamma=0.05537359541715664, lambda=0.06117574676187476, learning_rate=0.24883560539325922, max_depth=6, min_child_weight=1, n_estimators=750, scale_pos_weight=2.1166866733784966, subsample=0.8957638724301831; total time=   0.4s\n",
      "[CV] END alpha=5, colsample_bytree=0.2672664710652192, gamma=0.05537359541715664, lambda=0.06117574676187476, learning_rate=0.24883560539325922, max_depth=6, min_child_weight=1, n_estimators=750, scale_pos_weight=2.1166866733784966, subsample=0.8957638724301831; total time=   0.4s\n",
      "[CV] END alpha=5, colsample_bytree=0.40746318381846997, gamma=0.4265779575316532, lambda=0.03058614772861734, learning_rate=0.4637882876012003, max_depth=10, min_child_weight=3, n_estimators=500, scale_pos_weight=1.3009717744570577, subsample=0.9359765296052261; total time=   0.2s\n",
      "[CV] END alpha=5, colsample_bytree=0.40746318381846997, gamma=0.4265779575316532, lambda=0.03058614772861734, learning_rate=0.4637882876012003, max_depth=10, min_child_weight=3, n_estimators=500, scale_pos_weight=1.3009717744570577, subsample=0.9359765296052261; total time=   0.2s\n",
      "[CV] END alpha=5, colsample_bytree=0.40746318381846997, gamma=0.4265779575316532, lambda=0.03058614772861734, learning_rate=0.4637882876012003, max_depth=10, min_child_weight=3, n_estimators=500, scale_pos_weight=1.3009717744570577, subsample=0.9359765296052261; total time=   0.2s\n",
      "[CV] END alpha=5, colsample_bytree=0.40746318381846997, gamma=0.4265779575316532, lambda=0.03058614772861734, learning_rate=0.4637882876012003, max_depth=10, min_child_weight=3, n_estimators=500, scale_pos_weight=1.3009717744570577, subsample=0.9359765296052261; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.8817250275394111, gamma=0.14718192988774553, lambda=0.7192837694414786, learning_rate=0.1927549465587361, max_depth=5, min_child_weight=1, n_estimators=350, scale_pos_weight=2.330983298577932, subsample=0.6008774197306274; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.8817250275394111, gamma=0.14718192988774553, lambda=0.7192837694414786, learning_rate=0.1927549465587361, max_depth=5, min_child_weight=1, n_estimators=350, scale_pos_weight=2.330983298577932, subsample=0.6008774197306274; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.8817250275394111, gamma=0.14718192988774553, lambda=0.7192837694414786, learning_rate=0.1927549465587361, max_depth=5, min_child_weight=1, n_estimators=350, scale_pos_weight=2.330983298577932, subsample=0.6008774197306274; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.8817250275394111, gamma=0.14718192988774553, lambda=0.7192837694414786, learning_rate=0.1927549465587361, max_depth=5, min_child_weight=1, n_estimators=350, scale_pos_weight=2.330983298577932, subsample=0.6008774197306274; total time=   0.3s\n",
      "[CV] END alpha=15, colsample_bytree=0.9045122059600408, gamma=0.01672584257726689, lambda=0.8953853056985062, learning_rate=0.38430039109881503, max_depth=9, min_child_weight=1, n_estimators=650, scale_pos_weight=1.0275307088973487, subsample=0.615164602625624; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.9045122059600408, gamma=0.01672584257726689, lambda=0.8953853056985062, learning_rate=0.38430039109881503, max_depth=9, min_child_weight=1, n_estimators=650, scale_pos_weight=1.0275307088973487, subsample=0.615164602625624; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.9045122059600408, gamma=0.01672584257726689, lambda=0.8953853056985062, learning_rate=0.38430039109881503, max_depth=9, min_child_weight=1, n_estimators=650, scale_pos_weight=1.0275307088973487, subsample=0.615164602625624; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.9045122059600408, gamma=0.01672584257726689, lambda=0.8953853056985062, learning_rate=0.38430039109881503, max_depth=9, min_child_weight=1, n_estimators=650, scale_pos_weight=1.0275307088973487, subsample=0.615164602625624; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.3389706567700363, gamma=0.07160599274627777, lambda=0.17914359732724627, learning_rate=0.2586270977263787, max_depth=7, min_child_weight=3, n_estimators=200, scale_pos_weight=2.584666843316083, subsample=1.1837744127295413; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.3389706567700363, gamma=0.07160599274627777, lambda=0.17914359732724627, learning_rate=0.2586270977263787, max_depth=7, min_child_weight=3, n_estimators=200, scale_pos_weight=2.584666843316083, subsample=1.1837744127295413; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.3389706567700363, gamma=0.07160599274627777, lambda=0.17914359732724627, learning_rate=0.2586270977263787, max_depth=7, min_child_weight=3, n_estimators=200, scale_pos_weight=2.584666843316083, subsample=1.1837744127295413; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.3389706567700363, gamma=0.07160599274627777, lambda=0.17914359732724627, learning_rate=0.2586270977263787, max_depth=7, min_child_weight=3, n_estimators=200, scale_pos_weight=2.584666843316083, subsample=1.1837744127295413; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5901726797112763, gamma=0.3950254566201664, lambda=1.1893311569749803, learning_rate=0.11268939552261124, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=2.7882402707511442, subsample=0.7810557002304035; total time=   0.4s\n",
      "[CV] END alpha=15, colsample_bytree=0.5901726797112763, gamma=0.3950254566201664, lambda=1.1893311569749803, learning_rate=0.11268939552261124, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=2.7882402707511442, subsample=0.7810557002304035; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.5901726797112763, gamma=0.3950254566201664, lambda=1.1893311569749803, learning_rate=0.11268939552261124, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=2.7882402707511442, subsample=0.7810557002304035; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.5901726797112763, gamma=0.3950254566201664, lambda=1.1893311569749803, learning_rate=0.11268939552261124, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=2.7882402707511442, subsample=0.7810557002304035; total time=   0.5s\n",
      "[CV] END alpha=25, colsample_bytree=0.9823344892821635, gamma=0.13589543587197928, lambda=0.03692222045695204, learning_rate=0.27879732331012125, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=1.0572061819613743, subsample=0.8169296049644018; total time=   0.1s\n",
      "[CV] END alpha=25, colsample_bytree=0.9823344892821635, gamma=0.13589543587197928, lambda=0.03692222045695204, learning_rate=0.27879732331012125, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=1.0572061819613743, subsample=0.8169296049644018; total time=   0.1s\n",
      "[CV] END alpha=25, colsample_bytree=0.9823344892821635, gamma=0.13589543587197928, lambda=0.03692222045695204, learning_rate=0.27879732331012125, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=1.0572061819613743, subsample=0.8169296049644018; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.9823344892821635, gamma=0.13589543587197928, lambda=0.03692222045695204, learning_rate=0.27879732331012125, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=1.0572061819613743, subsample=0.8169296049644018; total time=   0.1s\n",
      "[CV] END alpha=5, colsample_bytree=1.0178992163855252, gamma=0.18595276397615396, lambda=0.5408671882940075, learning_rate=0.02059972305866275, max_depth=7, min_child_weight=3, n_estimators=750, scale_pos_weight=1.5306690598665735, subsample=1.236729904111722; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0178992163855252, gamma=0.18595276397615396, lambda=0.5408671882940075, learning_rate=0.02059972305866275, max_depth=7, min_child_weight=3, n_estimators=750, scale_pos_weight=1.5306690598665735, subsample=1.236729904111722; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0178992163855252, gamma=0.18595276397615396, lambda=0.5408671882940075, learning_rate=0.02059972305866275, max_depth=7, min_child_weight=3, n_estimators=750, scale_pos_weight=1.5306690598665735, subsample=1.236729904111722; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0178992163855252, gamma=0.18595276397615396, lambda=0.5408671882940075, learning_rate=0.02059972305866275, max_depth=7, min_child_weight=3, n_estimators=750, scale_pos_weight=1.5306690598665735, subsample=1.236729904111722; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.3003233362249001, gamma=0.038990398274795335, lambda=1.2354435825147851, learning_rate=0.27664946349513525, max_depth=8, min_child_weight=1, n_estimators=500, scale_pos_weight=1.5061152802310867, subsample=1.3619868929572552; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.3003233362249001, gamma=0.038990398274795335, lambda=1.2354435825147851, learning_rate=0.27664946349513525, max_depth=8, min_child_weight=1, n_estimators=500, scale_pos_weight=1.5061152802310867, subsample=1.3619868929572552; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.3003233362249001, gamma=0.038990398274795335, lambda=1.2354435825147851, learning_rate=0.27664946349513525, max_depth=8, min_child_weight=1, n_estimators=500, scale_pos_weight=1.5061152802310867, subsample=1.3619868929572552; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.3003233362249001, gamma=0.038990398274795335, lambda=1.2354435825147851, learning_rate=0.27664946349513525, max_depth=8, min_child_weight=1, n_estimators=500, scale_pos_weight=1.5061152802310867, subsample=1.3619868929572552; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0053608442926725, gamma=0.49684092578810435, lambda=0.6284800724901667, learning_rate=0.09994631620134069, max_depth=6, min_child_weight=1, n_estimators=750, scale_pos_weight=1.7312997168924178, subsample=1.0852873631487672; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0053608442926725, gamma=0.49684092578810435, lambda=0.6284800724901667, learning_rate=0.09994631620134069, max_depth=6, min_child_weight=1, n_estimators=750, scale_pos_weight=1.7312997168924178, subsample=1.0852873631487672; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0053608442926725, gamma=0.49684092578810435, lambda=0.6284800724901667, learning_rate=0.09994631620134069, max_depth=6, min_child_weight=1, n_estimators=750, scale_pos_weight=1.7312997168924178, subsample=1.0852873631487672; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0053608442926725, gamma=0.49684092578810435, lambda=0.6284800724901667, learning_rate=0.09994631620134069, max_depth=6, min_child_weight=1, n_estimators=750, scale_pos_weight=1.7312997168924178, subsample=1.0852873631487672; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1588037832794065, gamma=0.11274054317027121, lambda=0.41348878936966954, learning_rate=0.07848813894294225, max_depth=8, min_child_weight=3, n_estimators=300, scale_pos_weight=1.7948746900834556, subsample=1.5284891436428807; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1588037832794065, gamma=0.11274054317027121, lambda=0.41348878936966954, learning_rate=0.07848813894294225, max_depth=8, min_child_weight=3, n_estimators=300, scale_pos_weight=1.7948746900834556, subsample=1.5284891436428807; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1588037832794065, gamma=0.11274054317027121, lambda=0.41348878936966954, learning_rate=0.07848813894294225, max_depth=8, min_child_weight=3, n_estimators=300, scale_pos_weight=1.7948746900834556, subsample=1.5284891436428807; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1588037832794065, gamma=0.11274054317027121, lambda=0.41348878936966954, learning_rate=0.07848813894294225, max_depth=8, min_child_weight=3, n_estimators=300, scale_pos_weight=1.7948746900834556, subsample=1.5284891436428807; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.9914802060727474, gamma=0.27927765985724434, lambda=0.862792576193218, learning_rate=0.24273943301466294, max_depth=10, min_child_weight=3, n_estimators=650, scale_pos_weight=1.8128254865346223, subsample=1.367690621760754; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.9914802060727474, gamma=0.27927765985724434, lambda=0.862792576193218, learning_rate=0.24273943301466294, max_depth=10, min_child_weight=3, n_estimators=650, scale_pos_weight=1.8128254865346223, subsample=1.367690621760754; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.9914802060727474, gamma=0.27927765985724434, lambda=0.862792576193218, learning_rate=0.24273943301466294, max_depth=10, min_child_weight=3, n_estimators=650, scale_pos_weight=1.8128254865346223, subsample=1.367690621760754; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.9914802060727474, gamma=0.27927765985724434, lambda=0.862792576193218, learning_rate=0.24273943301466294, max_depth=10, min_child_weight=3, n_estimators=650, scale_pos_weight=1.8128254865346223, subsample=1.367690621760754; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1133242025836143, gamma=0.15530534364375892, lambda=0.3794976469675158, learning_rate=0.3743800996714682, max_depth=10, min_child_weight=3, n_estimators=300, scale_pos_weight=2.481197022148815, subsample=0.9918637026614417; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1133242025836143, gamma=0.15530534364375892, lambda=0.3794976469675158, learning_rate=0.3743800996714682, max_depth=10, min_child_weight=3, n_estimators=300, scale_pos_weight=2.481197022148815, subsample=0.9918637026614417; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1133242025836143, gamma=0.15530534364375892, lambda=0.3794976469675158, learning_rate=0.3743800996714682, max_depth=10, min_child_weight=3, n_estimators=300, scale_pos_weight=2.481197022148815, subsample=0.9918637026614417; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1133242025836143, gamma=0.15530534364375892, lambda=0.3794976469675158, learning_rate=0.3743800996714682, max_depth=10, min_child_weight=3, n_estimators=300, scale_pos_weight=2.481197022148815, subsample=0.9918637026614417; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0291555594934385, gamma=0.45673006841017444, lambda=1.1289361966577822, learning_rate=0.25077913936520907, max_depth=8, min_child_weight=3, n_estimators=550, scale_pos_weight=1.8283994009799356, subsample=1.5508710129331231; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0291555594934385, gamma=0.45673006841017444, lambda=1.1289361966577822, learning_rate=0.25077913936520907, max_depth=8, min_child_weight=3, n_estimators=550, scale_pos_weight=1.8283994009799356, subsample=1.5508710129331231; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0291555594934385, gamma=0.45673006841017444, lambda=1.1289361966577822, learning_rate=0.25077913936520907, max_depth=8, min_child_weight=3, n_estimators=550, scale_pos_weight=1.8283994009799356, subsample=1.5508710129331231; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0291555594934385, gamma=0.45673006841017444, lambda=1.1289361966577822, learning_rate=0.25077913936520907, max_depth=8, min_child_weight=3, n_estimators=550, scale_pos_weight=1.8283994009799356, subsample=1.5508710129331231; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.3932603226345179, gamma=0.25818881725891385, lambda=1.135894238325824, learning_rate=0.09909085149222623, max_depth=8, min_child_weight=1, n_estimators=750, scale_pos_weight=0.9974840447923456, subsample=0.9626983676306851; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.3932603226345179, gamma=0.25818881725891385, lambda=1.135894238325824, learning_rate=0.09909085149222623, max_depth=8, min_child_weight=1, n_estimators=750, scale_pos_weight=0.9974840447923456, subsample=0.9626983676306851; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.3932603226345179, gamma=0.25818881725891385, lambda=1.135894238325824, learning_rate=0.09909085149222623, max_depth=8, min_child_weight=1, n_estimators=750, scale_pos_weight=0.9974840447923456, subsample=0.9626983676306851; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.3932603226345179, gamma=0.25818881725891385, lambda=1.135894238325824, learning_rate=0.09909085149222623, max_depth=8, min_child_weight=1, n_estimators=750, scale_pos_weight=0.9974840447923456, subsample=0.9626983676306851; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.4460448663526067, gamma=0.4514741699036995, lambda=0.47876260456261105, learning_rate=0.37177491720468103, max_depth=9, min_child_weight=3, n_estimators=200, scale_pos_weight=2.0259432825291004, subsample=0.8755139344749843; total time=   0.1s\n",
      "[CV] END alpha=20, colsample_bytree=0.4460448663526067, gamma=0.4514741699036995, lambda=0.47876260456261105, learning_rate=0.37177491720468103, max_depth=9, min_child_weight=3, n_estimators=200, scale_pos_weight=2.0259432825291004, subsample=0.8755139344749843; total time=   0.1s\n",
      "[CV] END alpha=20, colsample_bytree=0.4460448663526067, gamma=0.4514741699036995, lambda=0.47876260456261105, learning_rate=0.37177491720468103, max_depth=9, min_child_weight=3, n_estimators=200, scale_pos_weight=2.0259432825291004, subsample=0.8755139344749843; total time=   0.1s\n",
      "[CV] END alpha=20, colsample_bytree=0.4460448663526067, gamma=0.4514741699036995, lambda=0.47876260456261105, learning_rate=0.37177491720468103, max_depth=9, min_child_weight=3, n_estimators=200, scale_pos_weight=2.0259432825291004, subsample=0.8755139344749843; total time=   0.1s\n",
      "[CV] END alpha=15, colsample_bytree=1.1177113518167276, gamma=0.21916747003406162, lambda=0.6079101579816425, learning_rate=0.47040576247737137, max_depth=8, min_child_weight=1, n_estimators=700, scale_pos_weight=2.096118691504474, subsample=0.8078445334826573; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1177113518167276, gamma=0.21916747003406162, lambda=0.6079101579816425, learning_rate=0.47040576247737137, max_depth=8, min_child_weight=1, n_estimators=700, scale_pos_weight=2.096118691504474, subsample=0.8078445334826573; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1177113518167276, gamma=0.21916747003406162, lambda=0.6079101579816425, learning_rate=0.47040576247737137, max_depth=8, min_child_weight=1, n_estimators=700, scale_pos_weight=2.096118691504474, subsample=0.8078445334826573; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1177113518167276, gamma=0.21916747003406162, lambda=0.6079101579816425, learning_rate=0.47040576247737137, max_depth=8, min_child_weight=1, n_estimators=700, scale_pos_weight=2.096118691504474, subsample=0.8078445334826573; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4694440767184797, gamma=0.4806750274951943, lambda=1.3103528487112692, learning_rate=0.12455044579327217, max_depth=11, min_child_weight=3, n_estimators=500, scale_pos_weight=1.5796427626377034, subsample=1.216256513352084; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4694440767184797, gamma=0.4806750274951943, lambda=1.3103528487112692, learning_rate=0.12455044579327217, max_depth=11, min_child_weight=3, n_estimators=500, scale_pos_weight=1.5796427626377034, subsample=1.216256513352084; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4694440767184797, gamma=0.4806750274951943, lambda=1.3103528487112692, learning_rate=0.12455044579327217, max_depth=11, min_child_weight=3, n_estimators=500, scale_pos_weight=1.5796427626377034, subsample=1.216256513352084; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4694440767184797, gamma=0.4806750274951943, lambda=1.3103528487112692, learning_rate=0.12455044579327217, max_depth=11, min_child_weight=3, n_estimators=500, scale_pos_weight=1.5796427626377034, subsample=1.216256513352084; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.7528121670536931, gamma=0.3445331945421707, lambda=0.834673768446863, learning_rate=0.09267404220133323, max_depth=7, min_child_weight=3, n_estimators=650, scale_pos_weight=1.6331575935255858, subsample=0.6190350238503063; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.7528121670536931, gamma=0.3445331945421707, lambda=0.834673768446863, learning_rate=0.09267404220133323, max_depth=7, min_child_weight=3, n_estimators=650, scale_pos_weight=1.6331575935255858, subsample=0.6190350238503063; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.7528121670536931, gamma=0.3445331945421707, lambda=0.834673768446863, learning_rate=0.09267404220133323, max_depth=7, min_child_weight=3, n_estimators=650, scale_pos_weight=1.6331575935255858, subsample=0.6190350238503063; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.7528121670536931, gamma=0.3445331945421707, lambda=0.834673768446863, learning_rate=0.09267404220133323, max_depth=7, min_child_weight=3, n_estimators=650, scale_pos_weight=1.6331575935255858, subsample=0.6190350238503063; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.5265243665788468, gamma=0.04550429004801715, lambda=0.693375084884128, learning_rate=0.03102890371047661, max_depth=9, min_child_weight=3, n_estimators=300, scale_pos_weight=0.762195749928117, subsample=0.8217198279359933; total time=   0.4s\n",
      "[CV] END alpha=15, colsample_bytree=0.5265243665788468, gamma=0.04550429004801715, lambda=0.693375084884128, learning_rate=0.03102890371047661, max_depth=9, min_child_weight=3, n_estimators=300, scale_pos_weight=0.762195749928117, subsample=0.8217198279359933; total time=   0.4s\n",
      "[CV] END alpha=15, colsample_bytree=0.5265243665788468, gamma=0.04550429004801715, lambda=0.693375084884128, learning_rate=0.03102890371047661, max_depth=9, min_child_weight=3, n_estimators=300, scale_pos_weight=0.762195749928117, subsample=0.8217198279359933; total time=   0.4s\n",
      "[CV] END alpha=15, colsample_bytree=0.5265243665788468, gamma=0.04550429004801715, lambda=0.693375084884128, learning_rate=0.03102890371047661, max_depth=9, min_child_weight=3, n_estimators=300, scale_pos_weight=0.762195749928117, subsample=0.8217198279359933; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=1.0261688636949475, gamma=0.09197702763813786, lambda=0.2772232808156862, learning_rate=0.4447610772614438, max_depth=5, min_child_weight=1, n_estimators=300, scale_pos_weight=0.7433857497457385, subsample=1.0621272259149444; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.0261688636949475, gamma=0.09197702763813786, lambda=0.2772232808156862, learning_rate=0.4447610772614438, max_depth=5, min_child_weight=1, n_estimators=300, scale_pos_weight=0.7433857497457385, subsample=1.0621272259149444; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.0261688636949475, gamma=0.09197702763813786, lambda=0.2772232808156862, learning_rate=0.4447610772614438, max_depth=5, min_child_weight=1, n_estimators=300, scale_pos_weight=0.7433857497457385, subsample=1.0621272259149444; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.0261688636949475, gamma=0.09197702763813786, lambda=0.2772232808156862, learning_rate=0.4447610772614438, max_depth=5, min_child_weight=1, n_estimators=300, scale_pos_weight=0.7433857497457385, subsample=1.0621272259149444; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.8679181502337752, gamma=0.014144443865554024, lambda=0.6219893780332, learning_rate=0.22502031722791122, max_depth=11, min_child_weight=3, n_estimators=400, scale_pos_weight=1.523256950568841, subsample=1.1501774280477735; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.8679181502337752, gamma=0.014144443865554024, lambda=0.6219893780332, learning_rate=0.22502031722791122, max_depth=11, min_child_weight=3, n_estimators=400, scale_pos_weight=1.523256950568841, subsample=1.1501774280477735; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.8679181502337752, gamma=0.014144443865554024, lambda=0.6219893780332, learning_rate=0.22502031722791122, max_depth=11, min_child_weight=3, n_estimators=400, scale_pos_weight=1.523256950568841, subsample=1.1501774280477735; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.8679181502337752, gamma=0.014144443865554024, lambda=0.6219893780332, learning_rate=0.22502031722791122, max_depth=11, min_child_weight=3, n_estimators=400, scale_pos_weight=1.523256950568841, subsample=1.1501774280477735; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5907695403339799, gamma=0.1242311369559439, lambda=1.3558230893725034, learning_rate=0.0912112497639097, max_depth=10, min_child_weight=1, n_estimators=700, scale_pos_weight=1.057346643064847, subsample=1.2130990946218358; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5907695403339799, gamma=0.1242311369559439, lambda=1.3558230893725034, learning_rate=0.0912112497639097, max_depth=10, min_child_weight=1, n_estimators=700, scale_pos_weight=1.057346643064847, subsample=1.2130990946218358; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5907695403339799, gamma=0.1242311369559439, lambda=1.3558230893725034, learning_rate=0.0912112497639097, max_depth=10, min_child_weight=1, n_estimators=700, scale_pos_weight=1.057346643064847, subsample=1.2130990946218358; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5907695403339799, gamma=0.1242311369559439, lambda=1.3558230893725034, learning_rate=0.0912112497639097, max_depth=10, min_child_weight=1, n_estimators=700, scale_pos_weight=1.057346643064847, subsample=1.2130990946218358; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.9228982968253716, gamma=0.2530083643673148, lambda=1.362690329186085, learning_rate=0.12951420427406363, max_depth=6, min_child_weight=3, n_estimators=400, scale_pos_weight=1.5520419809638946, subsample=1.5301378133796746; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.9228982968253716, gamma=0.2530083643673148, lambda=1.362690329186085, learning_rate=0.12951420427406363, max_depth=6, min_child_weight=3, n_estimators=400, scale_pos_weight=1.5520419809638946, subsample=1.5301378133796746; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.9228982968253716, gamma=0.2530083643673148, lambda=1.362690329186085, learning_rate=0.12951420427406363, max_depth=6, min_child_weight=3, n_estimators=400, scale_pos_weight=1.5520419809638946, subsample=1.5301378133796746; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.9228982968253716, gamma=0.2530083643673148, lambda=1.362690329186085, learning_rate=0.12951420427406363, max_depth=6, min_child_weight=3, n_estimators=400, scale_pos_weight=1.5520419809638946, subsample=1.5301378133796746; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.8807330028473974, gamma=0.344675136767138, lambda=0.206120082971403, learning_rate=0.4368308210375319, max_depth=8, min_child_weight=3, n_estimators=350, scale_pos_weight=1.4847139129384914, subsample=0.6437275890757408; total time=   0.4s\n",
      "[CV] END alpha=10, colsample_bytree=0.8807330028473974, gamma=0.344675136767138, lambda=0.206120082971403, learning_rate=0.4368308210375319, max_depth=8, min_child_weight=3, n_estimators=350, scale_pos_weight=1.4847139129384914, subsample=0.6437275890757408; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.8807330028473974, gamma=0.344675136767138, lambda=0.206120082971403, learning_rate=0.4368308210375319, max_depth=8, min_child_weight=3, n_estimators=350, scale_pos_weight=1.4847139129384914, subsample=0.6437275890757408; total time=   0.4s\n",
      "[CV] END alpha=10, colsample_bytree=0.8807330028473974, gamma=0.344675136767138, lambda=0.206120082971403, learning_rate=0.4368308210375319, max_depth=8, min_child_weight=3, n_estimators=350, scale_pos_weight=1.4847139129384914, subsample=0.6437275890757408; total time=   0.3s\n",
      "[CV] END alpha=15, colsample_bytree=0.46277948793683704, gamma=0.16392417463118314, lambda=1.1460540230872982, learning_rate=0.40420085848534754, max_depth=9, min_child_weight=1, n_estimators=500, scale_pos_weight=1.2664925987116962, subsample=0.7767615530280054; total time=   0.3s\n",
      "[CV] END alpha=15, colsample_bytree=0.46277948793683704, gamma=0.16392417463118314, lambda=1.1460540230872982, learning_rate=0.40420085848534754, max_depth=9, min_child_weight=1, n_estimators=500, scale_pos_weight=1.2664925987116962, subsample=0.7767615530280054; total time=   0.3s\n",
      "[CV] END alpha=15, colsample_bytree=0.46277948793683704, gamma=0.16392417463118314, lambda=1.1460540230872982, learning_rate=0.40420085848534754, max_depth=9, min_child_weight=1, n_estimators=500, scale_pos_weight=1.2664925987116962, subsample=0.7767615530280054; total time=   0.3s\n",
      "[CV] END alpha=15, colsample_bytree=0.46277948793683704, gamma=0.16392417463118314, lambda=1.1460540230872982, learning_rate=0.40420085848534754, max_depth=9, min_child_weight=1, n_estimators=500, scale_pos_weight=1.2664925987116962, subsample=0.7767615530280054; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.8360105663612714, gamma=0.320643316247572, lambda=1.1322610738137675, learning_rate=0.10382548877392332, max_depth=8, min_child_weight=1, n_estimators=750, scale_pos_weight=2.6062601033889896, subsample=1.5771695430863248; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.8360105663612714, gamma=0.320643316247572, lambda=1.1322610738137675, learning_rate=0.10382548877392332, max_depth=8, min_child_weight=1, n_estimators=750, scale_pos_weight=2.6062601033889896, subsample=1.5771695430863248; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.8360105663612714, gamma=0.320643316247572, lambda=1.1322610738137675, learning_rate=0.10382548877392332, max_depth=8, min_child_weight=1, n_estimators=750, scale_pos_weight=2.6062601033889896, subsample=1.5771695430863248; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.8360105663612714, gamma=0.320643316247572, lambda=1.1322610738137675, learning_rate=0.10382548877392332, max_depth=8, min_child_weight=1, n_estimators=750, scale_pos_weight=2.6062601033889896, subsample=1.5771695430863248; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.9673346336567701, gamma=0.3514096789556465, lambda=0.05115132919816573, learning_rate=0.2227367290100445, max_depth=5, min_child_weight=3, n_estimators=350, scale_pos_weight=1.76370106542571, subsample=0.6670128563548313; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.9673346336567701, gamma=0.3514096789556465, lambda=0.05115132919816573, learning_rate=0.2227367290100445, max_depth=5, min_child_weight=3, n_estimators=350, scale_pos_weight=1.76370106542571, subsample=0.6670128563548313; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.9673346336567701, gamma=0.3514096789556465, lambda=0.05115132919816573, learning_rate=0.2227367290100445, max_depth=5, min_child_weight=3, n_estimators=350, scale_pos_weight=1.76370106542571, subsample=0.6670128563548313; total time=   0.4s\n",
      "[CV] END alpha=5, colsample_bytree=0.9673346336567701, gamma=0.3514096789556465, lambda=0.05115132919816573, learning_rate=0.2227367290100445, max_depth=5, min_child_weight=3, n_estimators=350, scale_pos_weight=1.76370106542571, subsample=0.6670128563548313; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.6156013175844433, gamma=0.3860597726227391, lambda=0.8559237986899881, learning_rate=0.3899178818033311, max_depth=6, min_child_weight=3, n_estimators=450, scale_pos_weight=0.9660639549949368, subsample=0.8426372359312849; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=0.6156013175844433, gamma=0.3860597726227391, lambda=0.8559237986899881, learning_rate=0.3899178818033311, max_depth=6, min_child_weight=3, n_estimators=450, scale_pos_weight=0.9660639549949368, subsample=0.8426372359312849; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=0.6156013175844433, gamma=0.3860597726227391, lambda=0.8559237986899881, learning_rate=0.3899178818033311, max_depth=6, min_child_weight=3, n_estimators=450, scale_pos_weight=0.9660639549949368, subsample=0.8426372359312849; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=0.6156013175844433, gamma=0.3860597726227391, lambda=0.8559237986899881, learning_rate=0.3899178818033311, max_depth=6, min_child_weight=3, n_estimators=450, scale_pos_weight=0.9660639549949368, subsample=0.8426372359312849; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.9190828448580206, gamma=0.38343733040747485, lambda=0.13725535885869217, learning_rate=0.21800507196724406, max_depth=5, min_child_weight=3, n_estimators=350, scale_pos_weight=2.3621065413091147, subsample=0.8746905420298784; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.9190828448580206, gamma=0.38343733040747485, lambda=0.13725535885869217, learning_rate=0.21800507196724406, max_depth=5, min_child_weight=3, n_estimators=350, scale_pos_weight=2.3621065413091147, subsample=0.8746905420298784; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.9190828448580206, gamma=0.38343733040747485, lambda=0.13725535885869217, learning_rate=0.21800507196724406, max_depth=5, min_child_weight=3, n_estimators=350, scale_pos_weight=2.3621065413091147, subsample=0.8746905420298784; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.9190828448580206, gamma=0.38343733040747485, lambda=0.13725535885869217, learning_rate=0.21800507196724406, max_depth=5, min_child_weight=3, n_estimators=350, scale_pos_weight=2.3621065413091147, subsample=0.8746905420298784; total time=   0.2s\n",
      "[CV] END alpha=15, colsample_bytree=0.9578457421892947, gamma=0.251856026186825, lambda=0.11644703041289645, learning_rate=0.30939328602403215, max_depth=7, min_child_weight=3, n_estimators=250, scale_pos_weight=1.227098885926278, subsample=0.897109823171755; total time=   0.2s\n",
      "[CV] END alpha=15, colsample_bytree=0.9578457421892947, gamma=0.251856026186825, lambda=0.11644703041289645, learning_rate=0.30939328602403215, max_depth=7, min_child_weight=3, n_estimators=250, scale_pos_weight=1.227098885926278, subsample=0.897109823171755; total time=   0.2s\n",
      "[CV] END alpha=15, colsample_bytree=0.9578457421892947, gamma=0.251856026186825, lambda=0.11644703041289645, learning_rate=0.30939328602403215, max_depth=7, min_child_weight=3, n_estimators=250, scale_pos_weight=1.227098885926278, subsample=0.897109823171755; total time=   0.2s\n",
      "[CV] END alpha=15, colsample_bytree=0.9578457421892947, gamma=0.251856026186825, lambda=0.11644703041289645, learning_rate=0.30939328602403215, max_depth=7, min_child_weight=3, n_estimators=250, scale_pos_weight=1.227098885926278, subsample=0.897109823171755; total time=   0.2s\n",
      "[CV] END alpha=15, colsample_bytree=0.5621489946513407, gamma=0.06947725371977109, lambda=0.6686086084208038, learning_rate=0.34814130671503274, max_depth=11, min_child_weight=3, n_estimators=750, scale_pos_weight=1.1207620873613415, subsample=1.4780200447243081; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5621489946513407, gamma=0.06947725371977109, lambda=0.6686086084208038, learning_rate=0.34814130671503274, max_depth=11, min_child_weight=3, n_estimators=750, scale_pos_weight=1.1207620873613415, subsample=1.4780200447243081; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5621489946513407, gamma=0.06947725371977109, lambda=0.6686086084208038, learning_rate=0.34814130671503274, max_depth=11, min_child_weight=3, n_estimators=750, scale_pos_weight=1.1207620873613415, subsample=1.4780200447243081; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5621489946513407, gamma=0.06947725371977109, lambda=0.6686086084208038, learning_rate=0.34814130671503274, max_depth=11, min_child_weight=3, n_estimators=750, scale_pos_weight=1.1207620873613415, subsample=1.4780200447243081; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7248046599475084, gamma=0.07935401895586064, lambda=0.022818808731764062, learning_rate=0.1583553679951616, max_depth=10, min_child_weight=3, n_estimators=700, scale_pos_weight=2.195087353749475, subsample=1.2855959181419983; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7248046599475084, gamma=0.07935401895586064, lambda=0.022818808731764062, learning_rate=0.1583553679951616, max_depth=10, min_child_weight=3, n_estimators=700, scale_pos_weight=2.195087353749475, subsample=1.2855959181419983; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7248046599475084, gamma=0.07935401895586064, lambda=0.022818808731764062, learning_rate=0.1583553679951616, max_depth=10, min_child_weight=3, n_estimators=700, scale_pos_weight=2.195087353749475, subsample=1.2855959181419983; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7248046599475084, gamma=0.07935401895586064, lambda=0.022818808731764062, learning_rate=0.1583553679951616, max_depth=10, min_child_weight=3, n_estimators=700, scale_pos_weight=2.195087353749475, subsample=1.2855959181419983; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.8952016005226038, gamma=0.05472384395399521, lambda=1.0987680529401151, learning_rate=0.12523093994789114, max_depth=6, min_child_weight=1, n_estimators=700, scale_pos_weight=2.0018524036655356, subsample=1.4113593330578866; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.8952016005226038, gamma=0.05472384395399521, lambda=1.0987680529401151, learning_rate=0.12523093994789114, max_depth=6, min_child_weight=1, n_estimators=700, scale_pos_weight=2.0018524036655356, subsample=1.4113593330578866; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.8952016005226038, gamma=0.05472384395399521, lambda=1.0987680529401151, learning_rate=0.12523093994789114, max_depth=6, min_child_weight=1, n_estimators=700, scale_pos_weight=2.0018524036655356, subsample=1.4113593330578866; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.8952016005226038, gamma=0.05472384395399521, lambda=1.0987680529401151, learning_rate=0.12523093994789114, max_depth=6, min_child_weight=1, n_estimators=700, scale_pos_weight=2.0018524036655356, subsample=1.4113593330578866; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.069609102740436, gamma=0.4194737151061476, lambda=0.18776581067857534, learning_rate=0.1698438629574736, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=2.175565526259658, subsample=1.2893199963531827; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.069609102740436, gamma=0.4194737151061476, lambda=0.18776581067857534, learning_rate=0.1698438629574736, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=2.175565526259658, subsample=1.2893199963531827; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.069609102740436, gamma=0.4194737151061476, lambda=0.18776581067857534, learning_rate=0.1698438629574736, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=2.175565526259658, subsample=1.2893199963531827; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.069609102740436, gamma=0.4194737151061476, lambda=0.18776581067857534, learning_rate=0.1698438629574736, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=2.175565526259658, subsample=1.2893199963531827; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.8981462139784364, gamma=0.0012544559719500081, lambda=0.16646974164681744, learning_rate=0.31965138538103427, max_depth=10, min_child_weight=3, n_estimators=500, scale_pos_weight=0.9754315964299728, subsample=1.5245751606187423; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.8981462139784364, gamma=0.0012544559719500081, lambda=0.16646974164681744, learning_rate=0.31965138538103427, max_depth=10, min_child_weight=3, n_estimators=500, scale_pos_weight=0.9754315964299728, subsample=1.5245751606187423; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.8981462139784364, gamma=0.0012544559719500081, lambda=0.16646974164681744, learning_rate=0.31965138538103427, max_depth=10, min_child_weight=3, n_estimators=500, scale_pos_weight=0.9754315964299728, subsample=1.5245751606187423; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.8981462139784364, gamma=0.0012544559719500081, lambda=0.16646974164681744, learning_rate=0.31965138538103427, max_depth=10, min_child_weight=3, n_estimators=500, scale_pos_weight=0.9754315964299728, subsample=1.5245751606187423; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.47863500618241167, gamma=0.2315609941789984, lambda=0.1895352240928173, learning_rate=0.3453205856388682, max_depth=10, min_child_weight=1, n_estimators=350, scale_pos_weight=2.0880245702337694, subsample=1.4738578044868342; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.47863500618241167, gamma=0.2315609941789984, lambda=0.1895352240928173, learning_rate=0.3453205856388682, max_depth=10, min_child_weight=1, n_estimators=350, scale_pos_weight=2.0880245702337694, subsample=1.4738578044868342; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.47863500618241167, gamma=0.2315609941789984, lambda=0.1895352240928173, learning_rate=0.3453205856388682, max_depth=10, min_child_weight=1, n_estimators=350, scale_pos_weight=2.0880245702337694, subsample=1.4738578044868342; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.47863500618241167, gamma=0.2315609941789984, lambda=0.1895352240928173, learning_rate=0.3453205856388682, max_depth=10, min_child_weight=1, n_estimators=350, scale_pos_weight=2.0880245702337694, subsample=1.4738578044868342; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1979074632796378, gamma=0.4551962632322616, lambda=0.5703294526722059, learning_rate=0.45945448798283406, max_depth=8, min_child_weight=1, n_estimators=650, scale_pos_weight=1.9423108774286133, subsample=0.9412678067271779; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1979074632796378, gamma=0.4551962632322616, lambda=0.5703294526722059, learning_rate=0.45945448798283406, max_depth=8, min_child_weight=1, n_estimators=650, scale_pos_weight=1.9423108774286133, subsample=0.9412678067271779; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1979074632796378, gamma=0.4551962632322616, lambda=0.5703294526722059, learning_rate=0.45945448798283406, max_depth=8, min_child_weight=1, n_estimators=650, scale_pos_weight=1.9423108774286133, subsample=0.9412678067271779; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1979074632796378, gamma=0.4551962632322616, lambda=0.5703294526722059, learning_rate=0.45945448798283406, max_depth=8, min_child_weight=1, n_estimators=650, scale_pos_weight=1.9423108774286133, subsample=0.9412678067271779; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0025298487135925, gamma=0.3350377366261612, lambda=0.32536817330259643, learning_rate=0.4424164590755471, max_depth=6, min_child_weight=3, n_estimators=600, scale_pos_weight=1.9133922593253774, subsample=1.2146938554265643; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0025298487135925, gamma=0.3350377366261612, lambda=0.32536817330259643, learning_rate=0.4424164590755471, max_depth=6, min_child_weight=3, n_estimators=600, scale_pos_weight=1.9133922593253774, subsample=1.2146938554265643; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0025298487135925, gamma=0.3350377366261612, lambda=0.32536817330259643, learning_rate=0.4424164590755471, max_depth=6, min_child_weight=3, n_estimators=600, scale_pos_weight=1.9133922593253774, subsample=1.2146938554265643; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0025298487135925, gamma=0.3350377366261612, lambda=0.32536817330259643, learning_rate=0.4424164590755471, max_depth=6, min_child_weight=3, n_estimators=600, scale_pos_weight=1.9133922593253774, subsample=1.2146938554265643; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.20641035280219816, gamma=0.36361948716211917, lambda=1.076006256116483, learning_rate=0.27271927922673206, max_depth=5, min_child_weight=1, n_estimators=500, scale_pos_weight=0.861787346544981, subsample=1.1595964692984415; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.20641035280219816, gamma=0.36361948716211917, lambda=1.076006256116483, learning_rate=0.27271927922673206, max_depth=5, min_child_weight=1, n_estimators=500, scale_pos_weight=0.861787346544981, subsample=1.1595964692984415; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.20641035280219816, gamma=0.36361948716211917, lambda=1.076006256116483, learning_rate=0.27271927922673206, max_depth=5, min_child_weight=1, n_estimators=500, scale_pos_weight=0.861787346544981, subsample=1.1595964692984415; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.20641035280219816, gamma=0.36361948716211917, lambda=1.076006256116483, learning_rate=0.27271927922673206, max_depth=5, min_child_weight=1, n_estimators=500, scale_pos_weight=0.861787346544981, subsample=1.1595964692984415; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.3044689699435566, gamma=0.4986714703106756, lambda=0.2062971824776505, learning_rate=0.4583764804158406, max_depth=11, min_child_weight=1, n_estimators=650, scale_pos_weight=1.1276973696272525, subsample=1.4605384761070108; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.3044689699435566, gamma=0.4986714703106756, lambda=0.2062971824776505, learning_rate=0.4583764804158406, max_depth=11, min_child_weight=1, n_estimators=650, scale_pos_weight=1.1276973696272525, subsample=1.4605384761070108; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.3044689699435566, gamma=0.4986714703106756, lambda=0.2062971824776505, learning_rate=0.4583764804158406, max_depth=11, min_child_weight=1, n_estimators=650, scale_pos_weight=1.1276973696272525, subsample=1.4605384761070108; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.3044689699435566, gamma=0.4986714703106756, lambda=0.2062971824776505, learning_rate=0.4583764804158406, max_depth=11, min_child_weight=1, n_estimators=650, scale_pos_weight=1.1276973696272525, subsample=1.4605384761070108; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1274418425634922, gamma=0.01558870366960835, lambda=0.8563015752155507, learning_rate=0.4192790569239174, max_depth=10, min_child_weight=3, n_estimators=700, scale_pos_weight=2.6578341203738756, subsample=0.9488620330302078; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1274418425634922, gamma=0.01558870366960835, lambda=0.8563015752155507, learning_rate=0.4192790569239174, max_depth=10, min_child_weight=3, n_estimators=700, scale_pos_weight=2.6578341203738756, subsample=0.9488620330302078; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1274418425634922, gamma=0.01558870366960835, lambda=0.8563015752155507, learning_rate=0.4192790569239174, max_depth=10, min_child_weight=3, n_estimators=700, scale_pos_weight=2.6578341203738756, subsample=0.9488620330302078; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1274418425634922, gamma=0.01558870366960835, lambda=0.8563015752155507, learning_rate=0.4192790569239174, max_depth=10, min_child_weight=3, n_estimators=700, scale_pos_weight=2.6578341203738756, subsample=0.9488620330302078; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.37400145765316345, gamma=0.4339498163615748, lambda=0.046233964451719345, learning_rate=0.07460460822059849, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=1.606349550185341, subsample=1.4334759272373252; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.37400145765316345, gamma=0.4339498163615748, lambda=0.046233964451719345, learning_rate=0.07460460822059849, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=1.606349550185341, subsample=1.4334759272373252; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.37400145765316345, gamma=0.4339498163615748, lambda=0.046233964451719345, learning_rate=0.07460460822059849, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=1.606349550185341, subsample=1.4334759272373252; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.37400145765316345, gamma=0.4339498163615748, lambda=0.046233964451719345, learning_rate=0.07460460822059849, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=1.606349550185341, subsample=1.4334759272373252; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1889035119230607, gamma=0.29039317598718045, lambda=1.4514268323653128, learning_rate=0.27720811829877573, max_depth=11, min_child_weight=3, n_estimators=700, scale_pos_weight=1.2107189276154235, subsample=0.6185012625630533; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1889035119230607, gamma=0.29039317598718045, lambda=1.4514268323653128, learning_rate=0.27720811829877573, max_depth=11, min_child_weight=3, n_estimators=700, scale_pos_weight=1.2107189276154235, subsample=0.6185012625630533; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1889035119230607, gamma=0.29039317598718045, lambda=1.4514268323653128, learning_rate=0.27720811829877573, max_depth=11, min_child_weight=3, n_estimators=700, scale_pos_weight=1.2107189276154235, subsample=0.6185012625630533; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1889035119230607, gamma=0.29039317598718045, lambda=1.4514268323653128, learning_rate=0.27720811829877573, max_depth=11, min_child_weight=3, n_estimators=700, scale_pos_weight=1.2107189276154235, subsample=0.6185012625630533; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.43139481252307027, gamma=0.25381796199468243, lambda=0.9396319099580999, learning_rate=0.48464246684789464, max_depth=8, min_child_weight=3, n_estimators=200, scale_pos_weight=0.8814440255339383, subsample=1.2623596574913205; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.43139481252307027, gamma=0.25381796199468243, lambda=0.9396319099580999, learning_rate=0.48464246684789464, max_depth=8, min_child_weight=3, n_estimators=200, scale_pos_weight=0.8814440255339383, subsample=1.2623596574913205; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.43139481252307027, gamma=0.25381796199468243, lambda=0.9396319099580999, learning_rate=0.48464246684789464, max_depth=8, min_child_weight=3, n_estimators=200, scale_pos_weight=0.8814440255339383, subsample=1.2623596574913205; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.43139481252307027, gamma=0.25381796199468243, lambda=0.9396319099580999, learning_rate=0.48464246684789464, max_depth=8, min_child_weight=3, n_estimators=200, scale_pos_weight=0.8814440255339383, subsample=1.2623596574913205; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.6097992937019532, gamma=0.3804744307789986, lambda=0.18687547927589354, learning_rate=0.27866587381425884, max_depth=7, min_child_weight=1, n_estimators=300, scale_pos_weight=2.062401170422241, subsample=1.5781304770555322; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.6097992937019532, gamma=0.3804744307789986, lambda=0.18687547927589354, learning_rate=0.27866587381425884, max_depth=7, min_child_weight=1, n_estimators=300, scale_pos_weight=2.062401170422241, subsample=1.5781304770555322; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.6097992937019532, gamma=0.3804744307789986, lambda=0.18687547927589354, learning_rate=0.27866587381425884, max_depth=7, min_child_weight=1, n_estimators=300, scale_pos_weight=2.062401170422241, subsample=1.5781304770555322; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.6097992937019532, gamma=0.3804744307789986, lambda=0.18687547927589354, learning_rate=0.27866587381425884, max_depth=7, min_child_weight=1, n_estimators=300, scale_pos_weight=2.062401170422241, subsample=1.5781304770555322; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5228402034409938, gamma=0.20883988904533418, lambda=1.2512559713769533, learning_rate=0.261035370573903, max_depth=8, min_child_weight=3, n_estimators=500, scale_pos_weight=1.6071156290568283, subsample=1.5802586971454504; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5228402034409938, gamma=0.20883988904533418, lambda=1.2512559713769533, learning_rate=0.261035370573903, max_depth=8, min_child_weight=3, n_estimators=500, scale_pos_weight=1.6071156290568283, subsample=1.5802586971454504; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5228402034409938, gamma=0.20883988904533418, lambda=1.2512559713769533, learning_rate=0.261035370573903, max_depth=8, min_child_weight=3, n_estimators=500, scale_pos_weight=1.6071156290568283, subsample=1.5802586971454504; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5228402034409938, gamma=0.20883988904533418, lambda=1.2512559713769533, learning_rate=0.261035370573903, max_depth=8, min_child_weight=3, n_estimators=500, scale_pos_weight=1.6071156290568283, subsample=1.5802586971454504; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.47209619582822787, gamma=0.06585345071786686, lambda=1.3062310525425127, learning_rate=0.21665974672674182, max_depth=5, min_child_weight=3, n_estimators=450, scale_pos_weight=1.582579599543846, subsample=1.0656008831627573; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.47209619582822787, gamma=0.06585345071786686, lambda=1.3062310525425127, learning_rate=0.21665974672674182, max_depth=5, min_child_weight=3, n_estimators=450, scale_pos_weight=1.582579599543846, subsample=1.0656008831627573; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.47209619582822787, gamma=0.06585345071786686, lambda=1.3062310525425127, learning_rate=0.21665974672674182, max_depth=5, min_child_weight=3, n_estimators=450, scale_pos_weight=1.582579599543846, subsample=1.0656008831627573; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.47209619582822787, gamma=0.06585345071786686, lambda=1.3062310525425127, learning_rate=0.21665974672674182, max_depth=5, min_child_weight=3, n_estimators=450, scale_pos_weight=1.582579599543846, subsample=1.0656008831627573; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1509148477502136, gamma=0.41369498906355606, lambda=0.24613168140341257, learning_rate=0.20949838718042496, max_depth=10, min_child_weight=3, n_estimators=650, scale_pos_weight=2.7869938445737636, subsample=0.6234089213405231; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1509148477502136, gamma=0.41369498906355606, lambda=0.24613168140341257, learning_rate=0.20949838718042496, max_depth=10, min_child_weight=3, n_estimators=650, scale_pos_weight=2.7869938445737636, subsample=0.6234089213405231; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1509148477502136, gamma=0.41369498906355606, lambda=0.24613168140341257, learning_rate=0.20949838718042496, max_depth=10, min_child_weight=3, n_estimators=650, scale_pos_weight=2.7869938445737636, subsample=0.6234089213405231; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1509148477502136, gamma=0.41369498906355606, lambda=0.24613168140341257, learning_rate=0.20949838718042496, max_depth=10, min_child_weight=3, n_estimators=650, scale_pos_weight=2.7869938445737636, subsample=0.6234089213405231; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.44086187292606643, gamma=0.03261316667273584, lambda=1.3105669379354468, learning_rate=0.40497001106502434, max_depth=7, min_child_weight=3, n_estimators=350, scale_pos_weight=2.372550825602554, subsample=1.0303652786073143; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.44086187292606643, gamma=0.03261316667273584, lambda=1.3105669379354468, learning_rate=0.40497001106502434, max_depth=7, min_child_weight=3, n_estimators=350, scale_pos_weight=2.372550825602554, subsample=1.0303652786073143; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.44086187292606643, gamma=0.03261316667273584, lambda=1.3105669379354468, learning_rate=0.40497001106502434, max_depth=7, min_child_weight=3, n_estimators=350, scale_pos_weight=2.372550825602554, subsample=1.0303652786073143; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.44086187292606643, gamma=0.03261316667273584, lambda=1.3105669379354468, learning_rate=0.40497001106502434, max_depth=7, min_child_weight=3, n_estimators=350, scale_pos_weight=2.372550825602554, subsample=1.0303652786073143; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7116872731574662, gamma=0.22930050172210686, lambda=0.6617443780777783, learning_rate=0.4411170080563089, max_depth=11, min_child_weight=3, n_estimators=550, scale_pos_weight=2.3924995584309157, subsample=0.9001328166554514; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.7116872731574662, gamma=0.22930050172210686, lambda=0.6617443780777783, learning_rate=0.4411170080563089, max_depth=11, min_child_weight=3, n_estimators=550, scale_pos_weight=2.3924995584309157, subsample=0.9001328166554514; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.7116872731574662, gamma=0.22930050172210686, lambda=0.6617443780777783, learning_rate=0.4411170080563089, max_depth=11, min_child_weight=3, n_estimators=550, scale_pos_weight=2.3924995584309157, subsample=0.9001328166554514; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.7116872731574662, gamma=0.22930050172210686, lambda=0.6617443780777783, learning_rate=0.4411170080563089, max_depth=11, min_child_weight=3, n_estimators=550, scale_pos_weight=2.3924995584309157, subsample=0.9001328166554514; total time=   0.3s\n",
      "[CV] END alpha=5, colsample_bytree=0.6424771929243345, gamma=0.41080458500654743, lambda=0.4768294855036538, learning_rate=0.5055271021544134, max_depth=11, min_child_weight=3, n_estimators=300, scale_pos_weight=2.434486404199963, subsample=0.6333736798484713; total time=   0.3s\n",
      "[CV] END alpha=5, colsample_bytree=0.6424771929243345, gamma=0.41080458500654743, lambda=0.4768294855036538, learning_rate=0.5055271021544134, max_depth=11, min_child_weight=3, n_estimators=300, scale_pos_weight=2.434486404199963, subsample=0.6333736798484713; total time=   0.3s\n",
      "[CV] END alpha=5, colsample_bytree=0.6424771929243345, gamma=0.41080458500654743, lambda=0.4768294855036538, learning_rate=0.5055271021544134, max_depth=11, min_child_weight=3, n_estimators=300, scale_pos_weight=2.434486404199963, subsample=0.6333736798484713; total time=   0.3s\n",
      "[CV] END alpha=5, colsample_bytree=0.6424771929243345, gamma=0.41080458500654743, lambda=0.4768294855036538, learning_rate=0.5055271021544134, max_depth=11, min_child_weight=3, n_estimators=300, scale_pos_weight=2.434486404199963, subsample=0.6333736798484713; total time=   0.3s\n",
      "[CV] END alpha=15, colsample_bytree=0.370746387952614, gamma=0.09517791573574247, lambda=1.4164464814459077, learning_rate=0.25778060553319043, max_depth=5, min_child_weight=1, n_estimators=600, scale_pos_weight=1.3419806011535367, subsample=1.1458050759947407; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.370746387952614, gamma=0.09517791573574247, lambda=1.4164464814459077, learning_rate=0.25778060553319043, max_depth=5, min_child_weight=1, n_estimators=600, scale_pos_weight=1.3419806011535367, subsample=1.1458050759947407; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.370746387952614, gamma=0.09517791573574247, lambda=1.4164464814459077, learning_rate=0.25778060553319043, max_depth=5, min_child_weight=1, n_estimators=600, scale_pos_weight=1.3419806011535367, subsample=1.1458050759947407; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.370746387952614, gamma=0.09517791573574247, lambda=1.4164464814459077, learning_rate=0.25778060553319043, max_depth=5, min_child_weight=1, n_estimators=600, scale_pos_weight=1.3419806011535367, subsample=1.1458050759947407; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.8025257160003005, gamma=0.06275513683925693, lambda=1.2676648582464516, learning_rate=0.2281646586177732, max_depth=8, min_child_weight=1, n_estimators=750, scale_pos_weight=0.769078336346567, subsample=1.5528431380872343; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.8025257160003005, gamma=0.06275513683925693, lambda=1.2676648582464516, learning_rate=0.2281646586177732, max_depth=8, min_child_weight=1, n_estimators=750, scale_pos_weight=0.769078336346567, subsample=1.5528431380872343; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.8025257160003005, gamma=0.06275513683925693, lambda=1.2676648582464516, learning_rate=0.2281646586177732, max_depth=8, min_child_weight=1, n_estimators=750, scale_pos_weight=0.769078336346567, subsample=1.5528431380872343; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.8025257160003005, gamma=0.06275513683925693, lambda=1.2676648582464516, learning_rate=0.2281646586177732, max_depth=8, min_child_weight=1, n_estimators=750, scale_pos_weight=0.769078336346567, subsample=1.5528431380872343; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.20094799768782473, gamma=0.48289594583937373, lambda=0.9887598021391006, learning_rate=0.44059246447229855, max_depth=6, min_child_weight=3, n_estimators=200, scale_pos_weight=2.7304723874809955, subsample=1.0731548719809094; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.20094799768782473, gamma=0.48289594583937373, lambda=0.9887598021391006, learning_rate=0.44059246447229855, max_depth=6, min_child_weight=3, n_estimators=200, scale_pos_weight=2.7304723874809955, subsample=1.0731548719809094; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.20094799768782473, gamma=0.48289594583937373, lambda=0.9887598021391006, learning_rate=0.44059246447229855, max_depth=6, min_child_weight=3, n_estimators=200, scale_pos_weight=2.7304723874809955, subsample=1.0731548719809094; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.20094799768782473, gamma=0.48289594583937373, lambda=0.9887598021391006, learning_rate=0.44059246447229855, max_depth=6, min_child_weight=3, n_estimators=200, scale_pos_weight=2.7304723874809955, subsample=1.0731548719809094; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.8673595437807149, gamma=0.2287076218502781, lambda=0.9516848481304183, learning_rate=0.49457062267812096, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=1.9986571353238571, subsample=0.9857242432433169; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.8673595437807149, gamma=0.2287076218502781, lambda=0.9516848481304183, learning_rate=0.49457062267812096, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=1.9986571353238571, subsample=0.9857242432433169; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.8673595437807149, gamma=0.2287076218502781, lambda=0.9516848481304183, learning_rate=0.49457062267812096, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=1.9986571353238571, subsample=0.9857242432433169; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.8673595437807149, gamma=0.2287076218502781, lambda=0.9516848481304183, learning_rate=0.49457062267812096, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=1.9986571353238571, subsample=0.9857242432433169; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=1.1721472913138886, gamma=0.49552277404133716, lambda=1.4417199981321076, learning_rate=0.06753994596941697, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=2.500293024587486, subsample=0.8519209552799994; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1721472913138886, gamma=0.49552277404133716, lambda=1.4417199981321076, learning_rate=0.06753994596941697, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=2.500293024587486, subsample=0.8519209552799994; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1721472913138886, gamma=0.49552277404133716, lambda=1.4417199981321076, learning_rate=0.06753994596941697, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=2.500293024587486, subsample=0.8519209552799994; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1721472913138886, gamma=0.49552277404133716, lambda=1.4417199981321076, learning_rate=0.06753994596941697, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=2.500293024587486, subsample=0.8519209552799994; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.6479873012000663, gamma=0.09727035775784437, lambda=0.18330113655498959, learning_rate=0.17268494004158297, max_depth=7, min_child_weight=1, n_estimators=250, scale_pos_weight=1.1374526862902048, subsample=0.7572302620126312; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.6479873012000663, gamma=0.09727035775784437, lambda=0.18330113655498959, learning_rate=0.17268494004158297, max_depth=7, min_child_weight=1, n_estimators=250, scale_pos_weight=1.1374526862902048, subsample=0.7572302620126312; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.6479873012000663, gamma=0.09727035775784437, lambda=0.18330113655498959, learning_rate=0.17268494004158297, max_depth=7, min_child_weight=1, n_estimators=250, scale_pos_weight=1.1374526862902048, subsample=0.7572302620126312; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.6479873012000663, gamma=0.09727035775784437, lambda=0.18330113655498959, learning_rate=0.17268494004158297, max_depth=7, min_child_weight=1, n_estimators=250, scale_pos_weight=1.1374526862902048, subsample=0.7572302620126312; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=0.6066554149856507, gamma=0.43693997033593424, lambda=0.4888498641994315, learning_rate=0.5003656314159001, max_depth=8, min_child_weight=3, n_estimators=350, scale_pos_weight=1.25749272525287, subsample=1.4892411670319943; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6066554149856507, gamma=0.43693997033593424, lambda=0.4888498641994315, learning_rate=0.5003656314159001, max_depth=8, min_child_weight=3, n_estimators=350, scale_pos_weight=1.25749272525287, subsample=1.4892411670319943; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6066554149856507, gamma=0.43693997033593424, lambda=0.4888498641994315, learning_rate=0.5003656314159001, max_depth=8, min_child_weight=3, n_estimators=350, scale_pos_weight=1.25749272525287, subsample=1.4892411670319943; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6066554149856507, gamma=0.43693997033593424, lambda=0.4888498641994315, learning_rate=0.5003656314159001, max_depth=8, min_child_weight=3, n_estimators=350, scale_pos_weight=1.25749272525287, subsample=1.4892411670319943; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.081672669807031, gamma=0.3615181655047599, lambda=0.6621489642671974, learning_rate=0.15337146228060883, max_depth=5, min_child_weight=3, n_estimators=400, scale_pos_weight=0.9514837649660839, subsample=1.5881414954093631; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.081672669807031, gamma=0.3615181655047599, lambda=0.6621489642671974, learning_rate=0.15337146228060883, max_depth=5, min_child_weight=3, n_estimators=400, scale_pos_weight=0.9514837649660839, subsample=1.5881414954093631; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.081672669807031, gamma=0.3615181655047599, lambda=0.6621489642671974, learning_rate=0.15337146228060883, max_depth=5, min_child_weight=3, n_estimators=400, scale_pos_weight=0.9514837649660839, subsample=1.5881414954093631; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.081672669807031, gamma=0.3615181655047599, lambda=0.6621489642671974, learning_rate=0.15337146228060883, max_depth=5, min_child_weight=3, n_estimators=400, scale_pos_weight=0.9514837649660839, subsample=1.5881414954093631; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.192862140956226, gamma=0.3451190933216557, lambda=0.2763781303532092, learning_rate=0.3963416725114164, max_depth=7, min_child_weight=1, n_estimators=700, scale_pos_weight=2.537791346686718, subsample=1.3748511860330053; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.192862140956226, gamma=0.3451190933216557, lambda=0.2763781303532092, learning_rate=0.3963416725114164, max_depth=7, min_child_weight=1, n_estimators=700, scale_pos_weight=2.537791346686718, subsample=1.3748511860330053; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.192862140956226, gamma=0.3451190933216557, lambda=0.2763781303532092, learning_rate=0.3963416725114164, max_depth=7, min_child_weight=1, n_estimators=700, scale_pos_weight=2.537791346686718, subsample=1.3748511860330053; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.192862140956226, gamma=0.3451190933216557, lambda=0.2763781303532092, learning_rate=0.3963416725114164, max_depth=7, min_child_weight=1, n_estimators=700, scale_pos_weight=2.537791346686718, subsample=1.3748511860330053; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9384462866095227, gamma=0.19673423070481594, lambda=0.23502419239683325, learning_rate=0.4939067923811809, max_depth=7, min_child_weight=3, n_estimators=450, scale_pos_weight=0.9359759629694597, subsample=1.4192781083186183; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9384462866095227, gamma=0.19673423070481594, lambda=0.23502419239683325, learning_rate=0.4939067923811809, max_depth=7, min_child_weight=3, n_estimators=450, scale_pos_weight=0.9359759629694597, subsample=1.4192781083186183; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9384462866095227, gamma=0.19673423070481594, lambda=0.23502419239683325, learning_rate=0.4939067923811809, max_depth=7, min_child_weight=3, n_estimators=450, scale_pos_weight=0.9359759629694597, subsample=1.4192781083186183; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9384462866095227, gamma=0.19673423070481594, lambda=0.23502419239683325, learning_rate=0.4939067923811809, max_depth=7, min_child_weight=3, n_estimators=450, scale_pos_weight=0.9359759629694597, subsample=1.4192781083186183; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1466035643673032, gamma=0.04342168098369992, lambda=0.07291995745777152, learning_rate=0.21040175474855521, max_depth=8, min_child_weight=3, n_estimators=600, scale_pos_weight=0.9277760368277931, subsample=1.5673359135723377; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1466035643673032, gamma=0.04342168098369992, lambda=0.07291995745777152, learning_rate=0.21040175474855521, max_depth=8, min_child_weight=3, n_estimators=600, scale_pos_weight=0.9277760368277931, subsample=1.5673359135723377; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1466035643673032, gamma=0.04342168098369992, lambda=0.07291995745777152, learning_rate=0.21040175474855521, max_depth=8, min_child_weight=3, n_estimators=600, scale_pos_weight=0.9277760368277931, subsample=1.5673359135723377; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1466035643673032, gamma=0.04342168098369992, lambda=0.07291995745777152, learning_rate=0.21040175474855521, max_depth=8, min_child_weight=3, n_estimators=600, scale_pos_weight=0.9277760368277931, subsample=1.5673359135723377; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.9607550804051221, gamma=0.19392860923569039, lambda=1.2110352205432626, learning_rate=0.16821872934791565, max_depth=9, min_child_weight=1, n_estimators=450, scale_pos_weight=2.3157466738552097, subsample=0.7629908594148068; total time=   0.7s\n",
      "[CV] END alpha=5, colsample_bytree=0.9607550804051221, gamma=0.19392860923569039, lambda=1.2110352205432626, learning_rate=0.16821872934791565, max_depth=9, min_child_weight=1, n_estimators=450, scale_pos_weight=2.3157466738552097, subsample=0.7629908594148068; total time=   0.7s\n",
      "[CV] END alpha=5, colsample_bytree=0.9607550804051221, gamma=0.19392860923569039, lambda=1.2110352205432626, learning_rate=0.16821872934791565, max_depth=9, min_child_weight=1, n_estimators=450, scale_pos_weight=2.3157466738552097, subsample=0.7629908594148068; total time=   0.7s\n",
      "[CV] END alpha=5, colsample_bytree=0.9607550804051221, gamma=0.19392860923569039, lambda=1.2110352205432626, learning_rate=0.16821872934791565, max_depth=9, min_child_weight=1, n_estimators=450, scale_pos_weight=2.3157466738552097, subsample=0.7629908594148068; total time=   0.7s\n",
      "[CV] END alpha=5, colsample_bytree=0.8702561048428474, gamma=0.20362589825839128, lambda=0.8789139080930446, learning_rate=0.04083423771095484, max_depth=10, min_child_weight=1, n_estimators=750, scale_pos_weight=2.465516513807111, subsample=0.794563716335177; total time=   2.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8702561048428474, gamma=0.20362589825839128, lambda=0.8789139080930446, learning_rate=0.04083423771095484, max_depth=10, min_child_weight=1, n_estimators=750, scale_pos_weight=2.465516513807111, subsample=0.794563716335177; total time=   2.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8702561048428474, gamma=0.20362589825839128, lambda=0.8789139080930446, learning_rate=0.04083423771095484, max_depth=10, min_child_weight=1, n_estimators=750, scale_pos_weight=2.465516513807111, subsample=0.794563716335177; total time=   2.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8702561048428474, gamma=0.20362589825839128, lambda=0.8789139080930446, learning_rate=0.04083423771095484, max_depth=10, min_child_weight=1, n_estimators=750, scale_pos_weight=2.465516513807111, subsample=0.794563716335177; total time=   2.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.5983499655376798, gamma=0.3825333846577882, lambda=0.5214806181762257, learning_rate=0.04606056452937834, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=2.3805907416326493, subsample=1.11751092353177; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.5983499655376798, gamma=0.3825333846577882, lambda=0.5214806181762257, learning_rate=0.04606056452937834, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=2.3805907416326493, subsample=1.11751092353177; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.5983499655376798, gamma=0.3825333846577882, lambda=0.5214806181762257, learning_rate=0.04606056452937834, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=2.3805907416326493, subsample=1.11751092353177; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.5983499655376798, gamma=0.3825333846577882, lambda=0.5214806181762257, learning_rate=0.04606056452937834, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=2.3805907416326493, subsample=1.11751092353177; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0094664005682898, gamma=0.23245566078369567, lambda=0.48012738570020463, learning_rate=0.4610980989020997, max_depth=6, min_child_weight=1, n_estimators=600, scale_pos_weight=0.7146305877943591, subsample=1.4277326056179394; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0094664005682898, gamma=0.23245566078369567, lambda=0.48012738570020463, learning_rate=0.4610980989020997, max_depth=6, min_child_weight=1, n_estimators=600, scale_pos_weight=0.7146305877943591, subsample=1.4277326056179394; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0094664005682898, gamma=0.23245566078369567, lambda=0.48012738570020463, learning_rate=0.4610980989020997, max_depth=6, min_child_weight=1, n_estimators=600, scale_pos_weight=0.7146305877943591, subsample=1.4277326056179394; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0094664005682898, gamma=0.23245566078369567, lambda=0.48012738570020463, learning_rate=0.4610980989020997, max_depth=6, min_child_weight=1, n_estimators=600, scale_pos_weight=0.7146305877943591, subsample=1.4277326056179394; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.9784713983296918, gamma=0.4106938691854815, lambda=0.03251618906013004, learning_rate=0.3675121991919777, max_depth=8, min_child_weight=3, n_estimators=450, scale_pos_weight=1.2192991899946386, subsample=1.1017821866889772; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.9784713983296918, gamma=0.4106938691854815, lambda=0.03251618906013004, learning_rate=0.3675121991919777, max_depth=8, min_child_weight=3, n_estimators=450, scale_pos_weight=1.2192991899946386, subsample=1.1017821866889772; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.9784713983296918, gamma=0.4106938691854815, lambda=0.03251618906013004, learning_rate=0.3675121991919777, max_depth=8, min_child_weight=3, n_estimators=450, scale_pos_weight=1.2192991899946386, subsample=1.1017821866889772; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.9784713983296918, gamma=0.4106938691854815, lambda=0.03251618906013004, learning_rate=0.3675121991919777, max_depth=8, min_child_weight=3, n_estimators=450, scale_pos_weight=1.2192991899946386, subsample=1.1017821866889772; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.3503690745198484, gamma=0.2436957846447647, lambda=0.047520698902137226, learning_rate=0.43455272944062456, max_depth=6, min_child_weight=3, n_estimators=500, scale_pos_weight=1.591943801345569, subsample=1.403757721746478; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.3503690745198484, gamma=0.2436957846447647, lambda=0.047520698902137226, learning_rate=0.43455272944062456, max_depth=6, min_child_weight=3, n_estimators=500, scale_pos_weight=1.591943801345569, subsample=1.403757721746478; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.3503690745198484, gamma=0.2436957846447647, lambda=0.047520698902137226, learning_rate=0.43455272944062456, max_depth=6, min_child_weight=3, n_estimators=500, scale_pos_weight=1.591943801345569, subsample=1.403757721746478; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.3503690745198484, gamma=0.2436957846447647, lambda=0.047520698902137226, learning_rate=0.43455272944062456, max_depth=6, min_child_weight=3, n_estimators=500, scale_pos_weight=1.591943801345569, subsample=1.403757721746478; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9370947038545461, gamma=0.0007665354267796798, lambda=1.3423719182587912, learning_rate=0.209754969117116, max_depth=11, min_child_weight=1, n_estimators=650, scale_pos_weight=1.630814824778891, subsample=1.266485265106211; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9370947038545461, gamma=0.0007665354267796798, lambda=1.3423719182587912, learning_rate=0.209754969117116, max_depth=11, min_child_weight=1, n_estimators=650, scale_pos_weight=1.630814824778891, subsample=1.266485265106211; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9370947038545461, gamma=0.0007665354267796798, lambda=1.3423719182587912, learning_rate=0.209754969117116, max_depth=11, min_child_weight=1, n_estimators=650, scale_pos_weight=1.630814824778891, subsample=1.266485265106211; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9370947038545461, gamma=0.0007665354267796798, lambda=1.3423719182587912, learning_rate=0.209754969117116, max_depth=11, min_child_weight=1, n_estimators=650, scale_pos_weight=1.630814824778891, subsample=1.266485265106211; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.8316638849761524, gamma=0.45560418552731297, lambda=0.2538009328486277, learning_rate=0.36055720279199716, max_depth=11, min_child_weight=3, n_estimators=300, scale_pos_weight=2.665557007248126, subsample=1.4465014091924941; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.8316638849761524, gamma=0.45560418552731297, lambda=0.2538009328486277, learning_rate=0.36055720279199716, max_depth=11, min_child_weight=3, n_estimators=300, scale_pos_weight=2.665557007248126, subsample=1.4465014091924941; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.8316638849761524, gamma=0.45560418552731297, lambda=0.2538009328486277, learning_rate=0.36055720279199716, max_depth=11, min_child_weight=3, n_estimators=300, scale_pos_weight=2.665557007248126, subsample=1.4465014091924941; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.8316638849761524, gamma=0.45560418552731297, lambda=0.2538009328486277, learning_rate=0.36055720279199716, max_depth=11, min_child_weight=3, n_estimators=300, scale_pos_weight=2.665557007248126, subsample=1.4465014091924941; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.7186110441537783, gamma=0.1768959977805155, lambda=0.5154901499496924, learning_rate=0.2119509649046722, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=2.2657923328316842, subsample=0.7420868438938976; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.7186110441537783, gamma=0.1768959977805155, lambda=0.5154901499496924, learning_rate=0.2119509649046722, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=2.2657923328316842, subsample=0.7420868438938976; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.7186110441537783, gamma=0.1768959977805155, lambda=0.5154901499496924, learning_rate=0.2119509649046722, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=2.2657923328316842, subsample=0.7420868438938976; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.7186110441537783, gamma=0.1768959977805155, lambda=0.5154901499496924, learning_rate=0.2119509649046722, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=2.2657923328316842, subsample=0.7420868438938976; total time=   0.5s\n",
      "[CV] END alpha=10, colsample_bytree=0.6553567310867296, gamma=0.13635972990221507, lambda=1.0861765129678775, learning_rate=0.4103730509735151, max_depth=8, min_child_weight=1, n_estimators=700, scale_pos_weight=2.416170649721567, subsample=1.5628571064049737; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6553567310867296, gamma=0.13635972990221507, lambda=1.0861765129678775, learning_rate=0.4103730509735151, max_depth=8, min_child_weight=1, n_estimators=700, scale_pos_weight=2.416170649721567, subsample=1.5628571064049737; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6553567310867296, gamma=0.13635972990221507, lambda=1.0861765129678775, learning_rate=0.4103730509735151, max_depth=8, min_child_weight=1, n_estimators=700, scale_pos_weight=2.416170649721567, subsample=1.5628571064049737; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6553567310867296, gamma=0.13635972990221507, lambda=1.0861765129678775, learning_rate=0.4103730509735151, max_depth=8, min_child_weight=1, n_estimators=700, scale_pos_weight=2.416170649721567, subsample=1.5628571064049737; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.73368476729363, gamma=0.09215755009231369, lambda=0.3008954911647865, learning_rate=0.10549779011157466, max_depth=5, min_child_weight=1, n_estimators=600, scale_pos_weight=1.933202272731492, subsample=0.9278797896450033; total time=   0.5s\n",
      "[CV] END alpha=10, colsample_bytree=0.73368476729363, gamma=0.09215755009231369, lambda=0.3008954911647865, learning_rate=0.10549779011157466, max_depth=5, min_child_weight=1, n_estimators=600, scale_pos_weight=1.933202272731492, subsample=0.9278797896450033; total time=   0.5s\n",
      "[CV] END alpha=10, colsample_bytree=0.73368476729363, gamma=0.09215755009231369, lambda=0.3008954911647865, learning_rate=0.10549779011157466, max_depth=5, min_child_weight=1, n_estimators=600, scale_pos_weight=1.933202272731492, subsample=0.9278797896450033; total time=   0.4s\n",
      "[CV] END alpha=10, colsample_bytree=0.73368476729363, gamma=0.09215755009231369, lambda=0.3008954911647865, learning_rate=0.10549779011157466, max_depth=5, min_child_weight=1, n_estimators=600, scale_pos_weight=1.933202272731492, subsample=0.9278797896450033; total time=   0.4s\n",
      "[CV] END alpha=15, colsample_bytree=1.159604815055366, gamma=0.33296130707172655, lambda=0.15196978231864827, learning_rate=0.1319622374589573, max_depth=10, min_child_weight=3, n_estimators=250, scale_pos_weight=1.5588291651979458, subsample=1.0164835538515475; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.159604815055366, gamma=0.33296130707172655, lambda=0.15196978231864827, learning_rate=0.1319622374589573, max_depth=10, min_child_weight=3, n_estimators=250, scale_pos_weight=1.5588291651979458, subsample=1.0164835538515475; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.159604815055366, gamma=0.33296130707172655, lambda=0.15196978231864827, learning_rate=0.1319622374589573, max_depth=10, min_child_weight=3, n_estimators=250, scale_pos_weight=1.5588291651979458, subsample=1.0164835538515475; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.159604815055366, gamma=0.33296130707172655, lambda=0.15196978231864827, learning_rate=0.1319622374589573, max_depth=10, min_child_weight=3, n_estimators=250, scale_pos_weight=1.5588291651979458, subsample=1.0164835538515475; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7091874182379578, gamma=0.4778218288714652, lambda=0.6553556534163535, learning_rate=0.49338721083039716, max_depth=8, min_child_weight=1, n_estimators=400, scale_pos_weight=2.361105691834309, subsample=0.6909169598977306; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.7091874182379578, gamma=0.4778218288714652, lambda=0.6553556534163535, learning_rate=0.49338721083039716, max_depth=8, min_child_weight=1, n_estimators=400, scale_pos_weight=2.361105691834309, subsample=0.6909169598977306; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.7091874182379578, gamma=0.4778218288714652, lambda=0.6553556534163535, learning_rate=0.49338721083039716, max_depth=8, min_child_weight=1, n_estimators=400, scale_pos_weight=2.361105691834309, subsample=0.6909169598977306; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.7091874182379578, gamma=0.4778218288714652, lambda=0.6553556534163535, learning_rate=0.49338721083039716, max_depth=8, min_child_weight=1, n_estimators=400, scale_pos_weight=2.361105691834309, subsample=0.6909169598977306; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.5871178261934804, gamma=0.49017190393749194, lambda=0.9407449814485966, learning_rate=0.13506391723676275, max_depth=8, min_child_weight=1, n_estimators=350, scale_pos_weight=1.5677363279729137, subsample=0.9989705106810054; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.5871178261934804, gamma=0.49017190393749194, lambda=0.9407449814485966, learning_rate=0.13506391723676275, max_depth=8, min_child_weight=1, n_estimators=350, scale_pos_weight=1.5677363279729137, subsample=0.9989705106810054; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.5871178261934804, gamma=0.49017190393749194, lambda=0.9407449814485966, learning_rate=0.13506391723676275, max_depth=8, min_child_weight=1, n_estimators=350, scale_pos_weight=1.5677363279729137, subsample=0.9989705106810054; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.5871178261934804, gamma=0.49017190393749194, lambda=0.9407449814485966, learning_rate=0.13506391723676275, max_depth=8, min_child_weight=1, n_estimators=350, scale_pos_weight=1.5677363279729137, subsample=0.9989705106810054; total time=   0.1s\n",
      "[CV] END alpha=25, colsample_bytree=0.3892695433530487, gamma=0.05334949167879183, lambda=0.3242377631859332, learning_rate=0.3218616774236469, max_depth=5, min_child_weight=3, n_estimators=250, scale_pos_weight=2.097692967680034, subsample=0.7990893481633722; total time=   0.1s\n",
      "[CV] END alpha=25, colsample_bytree=0.3892695433530487, gamma=0.05334949167879183, lambda=0.3242377631859332, learning_rate=0.3218616774236469, max_depth=5, min_child_weight=3, n_estimators=250, scale_pos_weight=2.097692967680034, subsample=0.7990893481633722; total time=   0.1s\n",
      "[CV] END alpha=25, colsample_bytree=0.3892695433530487, gamma=0.05334949167879183, lambda=0.3242377631859332, learning_rate=0.3218616774236469, max_depth=5, min_child_weight=3, n_estimators=250, scale_pos_weight=2.097692967680034, subsample=0.7990893481633722; total time=   0.1s\n",
      "[CV] END alpha=25, colsample_bytree=0.3892695433530487, gamma=0.05334949167879183, lambda=0.3242377631859332, learning_rate=0.3218616774236469, max_depth=5, min_child_weight=3, n_estimators=250, scale_pos_weight=2.097692967680034, subsample=0.7990893481633722; total time=   0.1s\n",
      "[CV] END alpha=5, colsample_bytree=1.1740003669424752, gamma=0.16560279427241514, lambda=0.17474195266961, learning_rate=0.4942213679864393, max_depth=11, min_child_weight=1, n_estimators=300, scale_pos_weight=2.363629022081006, subsample=1.0057521481823244; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1740003669424752, gamma=0.16560279427241514, lambda=0.17474195266961, learning_rate=0.4942213679864393, max_depth=11, min_child_weight=1, n_estimators=300, scale_pos_weight=2.363629022081006, subsample=1.0057521481823244; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1740003669424752, gamma=0.16560279427241514, lambda=0.17474195266961, learning_rate=0.4942213679864393, max_depth=11, min_child_weight=1, n_estimators=300, scale_pos_weight=2.363629022081006, subsample=1.0057521481823244; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1740003669424752, gamma=0.16560279427241514, lambda=0.17474195266961, learning_rate=0.4942213679864393, max_depth=11, min_child_weight=1, n_estimators=300, scale_pos_weight=2.363629022081006, subsample=1.0057521481823244; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.41352280625070553, gamma=0.09679560788264724, lambda=0.8637313863915883, learning_rate=0.3862360316719716, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=1.0580366244068888, subsample=1.333148627629769; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.41352280625070553, gamma=0.09679560788264724, lambda=0.8637313863915883, learning_rate=0.3862360316719716, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=1.0580366244068888, subsample=1.333148627629769; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.41352280625070553, gamma=0.09679560788264724, lambda=0.8637313863915883, learning_rate=0.3862360316719716, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=1.0580366244068888, subsample=1.333148627629769; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.41352280625070553, gamma=0.09679560788264724, lambda=0.8637313863915883, learning_rate=0.3862360316719716, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=1.0580366244068888, subsample=1.333148627629769; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.37609695195457254, gamma=0.2360648003972679, lambda=0.5940390773274294, learning_rate=0.22661631526116555, max_depth=11, min_child_weight=3, n_estimators=700, scale_pos_weight=2.828683328265213, subsample=0.8598266181848874; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.37609695195457254, gamma=0.2360648003972679, lambda=0.5940390773274294, learning_rate=0.22661631526116555, max_depth=11, min_child_weight=3, n_estimators=700, scale_pos_weight=2.828683328265213, subsample=0.8598266181848874; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.37609695195457254, gamma=0.2360648003972679, lambda=0.5940390773274294, learning_rate=0.22661631526116555, max_depth=11, min_child_weight=3, n_estimators=700, scale_pos_weight=2.828683328265213, subsample=0.8598266181848874; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.37609695195457254, gamma=0.2360648003972679, lambda=0.5940390773274294, learning_rate=0.22661631526116555, max_depth=11, min_child_weight=3, n_estimators=700, scale_pos_weight=2.828683328265213, subsample=0.8598266181848874; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.33050778250244545, gamma=0.025528153557070665, lambda=1.0488489227156712, learning_rate=0.08490239309168128, max_depth=7, min_child_weight=1, n_estimators=300, scale_pos_weight=1.358420167776762, subsample=1.0628739113852597; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.33050778250244545, gamma=0.025528153557070665, lambda=1.0488489227156712, learning_rate=0.08490239309168128, max_depth=7, min_child_weight=1, n_estimators=300, scale_pos_weight=1.358420167776762, subsample=1.0628739113852597; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.33050778250244545, gamma=0.025528153557070665, lambda=1.0488489227156712, learning_rate=0.08490239309168128, max_depth=7, min_child_weight=1, n_estimators=300, scale_pos_weight=1.358420167776762, subsample=1.0628739113852597; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.33050778250244545, gamma=0.025528153557070665, lambda=1.0488489227156712, learning_rate=0.08490239309168128, max_depth=7, min_child_weight=1, n_estimators=300, scale_pos_weight=1.358420167776762, subsample=1.0628739113852597; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.768254287733295, gamma=0.29435147178614646, lambda=0.6862933491040972, learning_rate=0.24071901545236157, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=0.8471945808770363, subsample=0.6003783624472476; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.768254287733295, gamma=0.29435147178614646, lambda=0.6862933491040972, learning_rate=0.24071901545236157, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=0.8471945808770363, subsample=0.6003783624472476; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.768254287733295, gamma=0.29435147178614646, lambda=0.6862933491040972, learning_rate=0.24071901545236157, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=0.8471945808770363, subsample=0.6003783624472476; total time=   0.4s\n",
      "[CV] END alpha=5, colsample_bytree=0.768254287733295, gamma=0.29435147178614646, lambda=0.6862933491040972, learning_rate=0.24071901545236157, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=0.8471945808770363, subsample=0.6003783624472476; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.6095519779005052, gamma=0.3199105630300484, lambda=1.0540783600740422, learning_rate=0.1018847579273227, max_depth=11, min_child_weight=1, n_estimators=600, scale_pos_weight=1.0680186460815588, subsample=1.2965402394117314; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.6095519779005052, gamma=0.3199105630300484, lambda=1.0540783600740422, learning_rate=0.1018847579273227, max_depth=11, min_child_weight=1, n_estimators=600, scale_pos_weight=1.0680186460815588, subsample=1.2965402394117314; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.6095519779005052, gamma=0.3199105630300484, lambda=1.0540783600740422, learning_rate=0.1018847579273227, max_depth=11, min_child_weight=1, n_estimators=600, scale_pos_weight=1.0680186460815588, subsample=1.2965402394117314; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.6095519779005052, gamma=0.3199105630300484, lambda=1.0540783600740422, learning_rate=0.1018847579273227, max_depth=11, min_child_weight=1, n_estimators=600, scale_pos_weight=1.0680186460815588, subsample=1.2965402394117314; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6065334674671483, gamma=0.08043065042820347, lambda=0.5681695302423082, learning_rate=0.27638405234122426, max_depth=9, min_child_weight=1, n_estimators=200, scale_pos_weight=1.1595842533885115, subsample=0.7876127022393936; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.6065334674671483, gamma=0.08043065042820347, lambda=0.5681695302423082, learning_rate=0.27638405234122426, max_depth=9, min_child_weight=1, n_estimators=200, scale_pos_weight=1.1595842533885115, subsample=0.7876127022393936; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.6065334674671483, gamma=0.08043065042820347, lambda=0.5681695302423082, learning_rate=0.27638405234122426, max_depth=9, min_child_weight=1, n_estimators=200, scale_pos_weight=1.1595842533885115, subsample=0.7876127022393936; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.6065334674671483, gamma=0.08043065042820347, lambda=0.5681695302423082, learning_rate=0.27638405234122426, max_depth=9, min_child_weight=1, n_estimators=200, scale_pos_weight=1.1595842533885115, subsample=0.7876127022393936; total time=   0.2s\n",
      "[CV] END alpha=5, colsample_bytree=0.9293845173808377, gamma=0.24892339196970759, lambda=0.0856525475331778, learning_rate=0.378294720141826, max_depth=5, min_child_weight=3, n_estimators=250, scale_pos_weight=1.8317841585590062, subsample=1.0050731615219113; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.9293845173808377, gamma=0.24892339196970759, lambda=0.0856525475331778, learning_rate=0.378294720141826, max_depth=5, min_child_weight=3, n_estimators=250, scale_pos_weight=1.8317841585590062, subsample=1.0050731615219113; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.9293845173808377, gamma=0.24892339196970759, lambda=0.0856525475331778, learning_rate=0.378294720141826, max_depth=5, min_child_weight=3, n_estimators=250, scale_pos_weight=1.8317841585590062, subsample=1.0050731615219113; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.9293845173808377, gamma=0.24892339196970759, lambda=0.0856525475331778, learning_rate=0.378294720141826, max_depth=5, min_child_weight=3, n_estimators=250, scale_pos_weight=1.8317841585590062, subsample=1.0050731615219113; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0903235917935379, gamma=0.26461280611540056, lambda=1.2558953506846835, learning_rate=0.09260906161689052, max_depth=5, min_child_weight=3, n_estimators=750, scale_pos_weight=1.873754672182967, subsample=1.5051710202474275; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0903235917935379, gamma=0.26461280611540056, lambda=1.2558953506846835, learning_rate=0.09260906161689052, max_depth=5, min_child_weight=3, n_estimators=750, scale_pos_weight=1.873754672182967, subsample=1.5051710202474275; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0903235917935379, gamma=0.26461280611540056, lambda=1.2558953506846835, learning_rate=0.09260906161689052, max_depth=5, min_child_weight=3, n_estimators=750, scale_pos_weight=1.873754672182967, subsample=1.5051710202474275; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0903235917935379, gamma=0.26461280611540056, lambda=1.2558953506846835, learning_rate=0.09260906161689052, max_depth=5, min_child_weight=3, n_estimators=750, scale_pos_weight=1.873754672182967, subsample=1.5051710202474275; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.32425028259391225, gamma=0.471060657046929, lambda=0.5378053335934807, learning_rate=0.11563959660247818, max_depth=6, min_child_weight=3, n_estimators=550, scale_pos_weight=2.0687841790520727, subsample=0.8960490969347382; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.32425028259391225, gamma=0.471060657046929, lambda=0.5378053335934807, learning_rate=0.11563959660247818, max_depth=6, min_child_weight=3, n_estimators=550, scale_pos_weight=2.0687841790520727, subsample=0.8960490969347382; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.32425028259391225, gamma=0.471060657046929, lambda=0.5378053335934807, learning_rate=0.11563959660247818, max_depth=6, min_child_weight=3, n_estimators=550, scale_pos_weight=2.0687841790520727, subsample=0.8960490969347382; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.32425028259391225, gamma=0.471060657046929, lambda=0.5378053335934807, learning_rate=0.11563959660247818, max_depth=6, min_child_weight=3, n_estimators=550, scale_pos_weight=2.0687841790520727, subsample=0.8960490969347382; total time=   0.3s\n",
      "[CV] END alpha=15, colsample_bytree=1.1338447917488796, gamma=0.25279249507419, lambda=1.3829121964638031, learning_rate=0.0728644491989228, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=1.3549364430202775, subsample=0.8031811696740357; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1338447917488796, gamma=0.25279249507419, lambda=1.3829121964638031, learning_rate=0.0728644491989228, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=1.3549364430202775, subsample=0.8031811696740357; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1338447917488796, gamma=0.25279249507419, lambda=1.3829121964638031, learning_rate=0.0728644491989228, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=1.3549364430202775, subsample=0.8031811696740357; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1338447917488796, gamma=0.25279249507419, lambda=1.3829121964638031, learning_rate=0.0728644491989228, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=1.3549364430202775, subsample=0.8031811696740357; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4940173230023241, gamma=0.3808290840969857, lambda=0.1588199040368417, learning_rate=0.35028282840812913, max_depth=10, min_child_weight=3, n_estimators=500, scale_pos_weight=2.3355226833658866, subsample=1.4191755825571; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4940173230023241, gamma=0.3808290840969857, lambda=0.1588199040368417, learning_rate=0.35028282840812913, max_depth=10, min_child_weight=3, n_estimators=500, scale_pos_weight=2.3355226833658866, subsample=1.4191755825571; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4940173230023241, gamma=0.3808290840969857, lambda=0.1588199040368417, learning_rate=0.35028282840812913, max_depth=10, min_child_weight=3, n_estimators=500, scale_pos_weight=2.3355226833658866, subsample=1.4191755825571; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4940173230023241, gamma=0.3808290840969857, lambda=0.1588199040368417, learning_rate=0.35028282840812913, max_depth=10, min_child_weight=3, n_estimators=500, scale_pos_weight=2.3355226833658866, subsample=1.4191755825571; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.5148420934701654, gamma=0.4995202719523073, lambda=0.6028661912095332, learning_rate=0.05595629133213092, max_depth=11, min_child_weight=3, n_estimators=350, scale_pos_weight=2.3917568692802753, subsample=1.3877617954093857; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.5148420934701654, gamma=0.4995202719523073, lambda=0.6028661912095332, learning_rate=0.05595629133213092, max_depth=11, min_child_weight=3, n_estimators=350, scale_pos_weight=2.3917568692802753, subsample=1.3877617954093857; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.5148420934701654, gamma=0.4995202719523073, lambda=0.6028661912095332, learning_rate=0.05595629133213092, max_depth=11, min_child_weight=3, n_estimators=350, scale_pos_weight=2.3917568692802753, subsample=1.3877617954093857; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.5148420934701654, gamma=0.4995202719523073, lambda=0.6028661912095332, learning_rate=0.05595629133213092, max_depth=11, min_child_weight=3, n_estimators=350, scale_pos_weight=2.3917568692802753, subsample=1.3877617954093857; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.6099898594469808, gamma=0.05722960021746315, lambda=0.7818247997410323, learning_rate=0.12688656328510461, max_depth=5, min_child_weight=1, n_estimators=750, scale_pos_weight=2.1875247695243045, subsample=0.7224066658710371; total time=   0.6s\n",
      "[CV] END alpha=15, colsample_bytree=0.6099898594469808, gamma=0.05722960021746315, lambda=0.7818247997410323, learning_rate=0.12688656328510461, max_depth=5, min_child_weight=1, n_estimators=750, scale_pos_weight=2.1875247695243045, subsample=0.7224066658710371; total time=   0.6s\n",
      "[CV] END alpha=15, colsample_bytree=0.6099898594469808, gamma=0.05722960021746315, lambda=0.7818247997410323, learning_rate=0.12688656328510461, max_depth=5, min_child_weight=1, n_estimators=750, scale_pos_weight=2.1875247695243045, subsample=0.7224066658710371; total time=   0.6s\n",
      "[CV] END alpha=15, colsample_bytree=0.6099898594469808, gamma=0.05722960021746315, lambda=0.7818247997410323, learning_rate=0.12688656328510461, max_depth=5, min_child_weight=1, n_estimators=750, scale_pos_weight=2.1875247695243045, subsample=0.7224066658710371; total time=   0.6s\n",
      "[CV] END alpha=5, colsample_bytree=0.8320397589299506, gamma=0.10385273047883392, lambda=0.4418627263980505, learning_rate=0.1291607299914188, max_depth=5, min_child_weight=1, n_estimators=550, scale_pos_weight=1.6444556746838148, subsample=1.0183055359952053; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8320397589299506, gamma=0.10385273047883392, lambda=0.4418627263980505, learning_rate=0.1291607299914188, max_depth=5, min_child_weight=1, n_estimators=550, scale_pos_weight=1.6444556746838148, subsample=1.0183055359952053; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8320397589299506, gamma=0.10385273047883392, lambda=0.4418627263980505, learning_rate=0.1291607299914188, max_depth=5, min_child_weight=1, n_estimators=550, scale_pos_weight=1.6444556746838148, subsample=1.0183055359952053; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8320397589299506, gamma=0.10385273047883392, lambda=0.4418627263980505, learning_rate=0.1291607299914188, max_depth=5, min_child_weight=1, n_estimators=550, scale_pos_weight=1.6444556746838148, subsample=1.0183055359952053; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.8219342193166606, gamma=0.12285142799361254, lambda=0.7901937557165473, learning_rate=0.06431928071843084, max_depth=7, min_child_weight=1, n_estimators=600, scale_pos_weight=2.1337670612226463, subsample=1.014747584765478; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.8219342193166606, gamma=0.12285142799361254, lambda=0.7901937557165473, learning_rate=0.06431928071843084, max_depth=7, min_child_weight=1, n_estimators=600, scale_pos_weight=2.1337670612226463, subsample=1.014747584765478; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.8219342193166606, gamma=0.12285142799361254, lambda=0.7901937557165473, learning_rate=0.06431928071843084, max_depth=7, min_child_weight=1, n_estimators=600, scale_pos_weight=2.1337670612226463, subsample=1.014747584765478; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.8219342193166606, gamma=0.12285142799361254, lambda=0.7901937557165473, learning_rate=0.06431928071843084, max_depth=7, min_child_weight=1, n_estimators=600, scale_pos_weight=2.1337670612226463, subsample=1.014747584765478; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.20561192659614452, gamma=0.243461207912414, lambda=0.5130202213673218, learning_rate=0.012527404109960552, max_depth=5, min_child_weight=3, n_estimators=500, scale_pos_weight=1.9288326528065929, subsample=0.6140591935551438; total time=   0.4s\n",
      "[CV] END alpha=5, colsample_bytree=0.20561192659614452, gamma=0.243461207912414, lambda=0.5130202213673218, learning_rate=0.012527404109960552, max_depth=5, min_child_weight=3, n_estimators=500, scale_pos_weight=1.9288326528065929, subsample=0.6140591935551438; total time=   0.4s\n",
      "[CV] END alpha=5, colsample_bytree=0.20561192659614452, gamma=0.243461207912414, lambda=0.5130202213673218, learning_rate=0.012527404109960552, max_depth=5, min_child_weight=3, n_estimators=500, scale_pos_weight=1.9288326528065929, subsample=0.6140591935551438; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.20561192659614452, gamma=0.243461207912414, lambda=0.5130202213673218, learning_rate=0.012527404109960552, max_depth=5, min_child_weight=3, n_estimators=500, scale_pos_weight=1.9288326528065929, subsample=0.6140591935551438; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=1.0659490590219458, gamma=0.4656352438353563, lambda=0.19588399564254227, learning_rate=0.01761456621251633, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=0.9994957829015676, subsample=1.5861477170614733; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0659490590219458, gamma=0.4656352438353563, lambda=0.19588399564254227, learning_rate=0.01761456621251633, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=0.9994957829015676, subsample=1.5861477170614733; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0659490590219458, gamma=0.4656352438353563, lambda=0.19588399564254227, learning_rate=0.01761456621251633, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=0.9994957829015676, subsample=1.5861477170614733; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0659490590219458, gamma=0.4656352438353563, lambda=0.19588399564254227, learning_rate=0.01761456621251633, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=0.9994957829015676, subsample=1.5861477170614733; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.9135996165980784, gamma=0.06802732312614035, lambda=0.2846623720065532, learning_rate=0.49161696621541795, max_depth=10, min_child_weight=1, n_estimators=750, scale_pos_weight=0.906358448973117, subsample=1.5659467120178054; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.9135996165980784, gamma=0.06802732312614035, lambda=0.2846623720065532, learning_rate=0.49161696621541795, max_depth=10, min_child_weight=1, n_estimators=750, scale_pos_weight=0.906358448973117, subsample=1.5659467120178054; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.9135996165980784, gamma=0.06802732312614035, lambda=0.2846623720065532, learning_rate=0.49161696621541795, max_depth=10, min_child_weight=1, n_estimators=750, scale_pos_weight=0.906358448973117, subsample=1.5659467120178054; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.9135996165980784, gamma=0.06802732312614035, lambda=0.2846623720065532, learning_rate=0.49161696621541795, max_depth=10, min_child_weight=1, n_estimators=750, scale_pos_weight=0.906358448973117, subsample=1.5659467120178054; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5307943450301611, gamma=0.41351253012232336, lambda=0.6822945455305209, learning_rate=0.47602476147847733, max_depth=8, min_child_weight=3, n_estimators=600, scale_pos_weight=1.1490137891031345, subsample=1.4223048320356884; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5307943450301611, gamma=0.41351253012232336, lambda=0.6822945455305209, learning_rate=0.47602476147847733, max_depth=8, min_child_weight=3, n_estimators=600, scale_pos_weight=1.1490137891031345, subsample=1.4223048320356884; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5307943450301611, gamma=0.41351253012232336, lambda=0.6822945455305209, learning_rate=0.47602476147847733, max_depth=8, min_child_weight=3, n_estimators=600, scale_pos_weight=1.1490137891031345, subsample=1.4223048320356884; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5307943450301611, gamma=0.41351253012232336, lambda=0.6822945455305209, learning_rate=0.47602476147847733, max_depth=8, min_child_weight=3, n_estimators=600, scale_pos_weight=1.1490137891031345, subsample=1.4223048320356884; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.7128357808340351, gamma=0.10249859769184311, lambda=0.24634557627608816, learning_rate=0.4353163488221389, max_depth=9, min_child_weight=3, n_estimators=350, scale_pos_weight=1.6120404396880907, subsample=0.6048268039212413; total time=   0.4s\n",
      "[CV] END alpha=5, colsample_bytree=0.7128357808340351, gamma=0.10249859769184311, lambda=0.24634557627608816, learning_rate=0.4353163488221389, max_depth=9, min_child_weight=3, n_estimators=350, scale_pos_weight=1.6120404396880907, subsample=0.6048268039212413; total time=   0.4s\n",
      "[CV] END alpha=5, colsample_bytree=0.7128357808340351, gamma=0.10249859769184311, lambda=0.24634557627608816, learning_rate=0.4353163488221389, max_depth=9, min_child_weight=3, n_estimators=350, scale_pos_weight=1.6120404396880907, subsample=0.6048268039212413; total time=   0.4s\n",
      "[CV] END alpha=5, colsample_bytree=0.7128357808340351, gamma=0.10249859769184311, lambda=0.24634557627608816, learning_rate=0.4353163488221389, max_depth=9, min_child_weight=3, n_estimators=350, scale_pos_weight=1.6120404396880907, subsample=0.6048268039212413; total time=   0.4s\n",
      "[CV] END alpha=5, colsample_bytree=0.23505286360651084, gamma=0.006553381060337149, lambda=1.408519965100974, learning_rate=0.11431364899043743, max_depth=11, min_child_weight=1, n_estimators=700, scale_pos_weight=1.395552725087196, subsample=0.8940800632017395; total time=   1.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.23505286360651084, gamma=0.006553381060337149, lambda=1.408519965100974, learning_rate=0.11431364899043743, max_depth=11, min_child_weight=1, n_estimators=700, scale_pos_weight=1.395552725087196, subsample=0.8940800632017395; total time=   1.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.23505286360651084, gamma=0.006553381060337149, lambda=1.408519965100974, learning_rate=0.11431364899043743, max_depth=11, min_child_weight=1, n_estimators=700, scale_pos_weight=1.395552725087196, subsample=0.8940800632017395; total time=   1.1s\n",
      "[CV] END alpha=5, colsample_bytree=0.23505286360651084, gamma=0.006553381060337149, lambda=1.408519965100974, learning_rate=0.11431364899043743, max_depth=11, min_child_weight=1, n_estimators=700, scale_pos_weight=1.395552725087196, subsample=0.8940800632017395; total time=   1.1s\n",
      "[CV] END alpha=5, colsample_bytree=0.28608263118554916, gamma=0.3149376136044986, lambda=0.3034274414751391, learning_rate=0.39779948556028116, max_depth=9, min_child_weight=3, n_estimators=700, scale_pos_weight=0.804638831451109, subsample=1.5885665776323619; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.28608263118554916, gamma=0.3149376136044986, lambda=0.3034274414751391, learning_rate=0.39779948556028116, max_depth=9, min_child_weight=3, n_estimators=700, scale_pos_weight=0.804638831451109, subsample=1.5885665776323619; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.28608263118554916, gamma=0.3149376136044986, lambda=0.3034274414751391, learning_rate=0.39779948556028116, max_depth=9, min_child_weight=3, n_estimators=700, scale_pos_weight=0.804638831451109, subsample=1.5885665776323619; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.28608263118554916, gamma=0.3149376136044986, lambda=0.3034274414751391, learning_rate=0.39779948556028116, max_depth=9, min_child_weight=3, n_estimators=700, scale_pos_weight=0.804638831451109, subsample=1.5885665776323619; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4489766860063424, gamma=0.4767312996270089, lambda=0.32068155270944537, learning_rate=0.278175493780655, max_depth=5, min_child_weight=1, n_estimators=350, scale_pos_weight=1.5801869806799747, subsample=1.3399254247418702; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4489766860063424, gamma=0.4767312996270089, lambda=0.32068155270944537, learning_rate=0.278175493780655, max_depth=5, min_child_weight=1, n_estimators=350, scale_pos_weight=1.5801869806799747, subsample=1.3399254247418702; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4489766860063424, gamma=0.4767312996270089, lambda=0.32068155270944537, learning_rate=0.278175493780655, max_depth=5, min_child_weight=1, n_estimators=350, scale_pos_weight=1.5801869806799747, subsample=1.3399254247418702; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4489766860063424, gamma=0.4767312996270089, lambda=0.32068155270944537, learning_rate=0.278175493780655, max_depth=5, min_child_weight=1, n_estimators=350, scale_pos_weight=1.5801869806799747, subsample=1.3399254247418702; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.8362677319954734, gamma=0.37610312160365783, lambda=0.09403754135903492, learning_rate=0.3823426844125466, max_depth=5, min_child_weight=1, n_estimators=400, scale_pos_weight=1.884838375682467, subsample=1.3304181223327969; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.8362677319954734, gamma=0.37610312160365783, lambda=0.09403754135903492, learning_rate=0.3823426844125466, max_depth=5, min_child_weight=1, n_estimators=400, scale_pos_weight=1.884838375682467, subsample=1.3304181223327969; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.8362677319954734, gamma=0.37610312160365783, lambda=0.09403754135903492, learning_rate=0.3823426844125466, max_depth=5, min_child_weight=1, n_estimators=400, scale_pos_weight=1.884838375682467, subsample=1.3304181223327969; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.8362677319954734, gamma=0.37610312160365783, lambda=0.09403754135903492, learning_rate=0.3823426844125466, max_depth=5, min_child_weight=1, n_estimators=400, scale_pos_weight=1.884838375682467, subsample=1.3304181223327969; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7654464277333397, gamma=0.43464668617538155, lambda=0.926893906962345, learning_rate=0.25298062044330455, max_depth=8, min_child_weight=3, n_estimators=400, scale_pos_weight=1.8095986403427726, subsample=1.2762967427969274; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7654464277333397, gamma=0.43464668617538155, lambda=0.926893906962345, learning_rate=0.25298062044330455, max_depth=8, min_child_weight=3, n_estimators=400, scale_pos_weight=1.8095986403427726, subsample=1.2762967427969274; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7654464277333397, gamma=0.43464668617538155, lambda=0.926893906962345, learning_rate=0.25298062044330455, max_depth=8, min_child_weight=3, n_estimators=400, scale_pos_weight=1.8095986403427726, subsample=1.2762967427969274; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7654464277333397, gamma=0.43464668617538155, lambda=0.926893906962345, learning_rate=0.25298062044330455, max_depth=8, min_child_weight=3, n_estimators=400, scale_pos_weight=1.8095986403427726, subsample=1.2762967427969274; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9736193127928594, gamma=0.4513961888224828, lambda=0.4037544979968653, learning_rate=0.3276990107880134, max_depth=6, min_child_weight=3, n_estimators=750, scale_pos_weight=1.4121907024442801, subsample=1.1707382058570346; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9736193127928594, gamma=0.4513961888224828, lambda=0.4037544979968653, learning_rate=0.3276990107880134, max_depth=6, min_child_weight=3, n_estimators=750, scale_pos_weight=1.4121907024442801, subsample=1.1707382058570346; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9736193127928594, gamma=0.4513961888224828, lambda=0.4037544979968653, learning_rate=0.3276990107880134, max_depth=6, min_child_weight=3, n_estimators=750, scale_pos_weight=1.4121907024442801, subsample=1.1707382058570346; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9736193127928594, gamma=0.4513961888224828, lambda=0.4037544979968653, learning_rate=0.3276990107880134, max_depth=6, min_child_weight=3, n_estimators=750, scale_pos_weight=1.4121907024442801, subsample=1.1707382058570346; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.236952135358599, gamma=0.2951222316440027, lambda=1.1487098819331862, learning_rate=0.38265792012274263, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=2.828985772954783, subsample=1.3345546010747231; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.236952135358599, gamma=0.2951222316440027, lambda=1.1487098819331862, learning_rate=0.38265792012274263, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=2.828985772954783, subsample=1.3345546010747231; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.236952135358599, gamma=0.2951222316440027, lambda=1.1487098819331862, learning_rate=0.38265792012274263, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=2.828985772954783, subsample=1.3345546010747231; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.236952135358599, gamma=0.2951222316440027, lambda=1.1487098819331862, learning_rate=0.38265792012274263, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=2.828985772954783, subsample=1.3345546010747231; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1935614235435916, gamma=0.32663472114459297, lambda=1.141098234436868, learning_rate=0.3298371471423, max_depth=7, min_child_weight=3, n_estimators=300, scale_pos_weight=2.4698266043845702, subsample=0.7595337454842215; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1935614235435916, gamma=0.32663472114459297, lambda=1.141098234436868, learning_rate=0.3298371471423, max_depth=7, min_child_weight=3, n_estimators=300, scale_pos_weight=2.4698266043845702, subsample=0.7595337454842215; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1935614235435916, gamma=0.32663472114459297, lambda=1.141098234436868, learning_rate=0.3298371471423, max_depth=7, min_child_weight=3, n_estimators=300, scale_pos_weight=2.4698266043845702, subsample=0.7595337454842215; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1935614235435916, gamma=0.32663472114459297, lambda=1.141098234436868, learning_rate=0.3298371471423, max_depth=7, min_child_weight=3, n_estimators=300, scale_pos_weight=2.4698266043845702, subsample=0.7595337454842215; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.9775322919511973, gamma=0.13157737404844716, lambda=0.31162537429621684, learning_rate=0.11818490113000833, max_depth=11, min_child_weight=3, n_estimators=650, scale_pos_weight=2.1556730145581593, subsample=1.084906952274622; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.9775322919511973, gamma=0.13157737404844716, lambda=0.31162537429621684, learning_rate=0.11818490113000833, max_depth=11, min_child_weight=3, n_estimators=650, scale_pos_weight=2.1556730145581593, subsample=1.084906952274622; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.9775322919511973, gamma=0.13157737404844716, lambda=0.31162537429621684, learning_rate=0.11818490113000833, max_depth=11, min_child_weight=3, n_estimators=650, scale_pos_weight=2.1556730145581593, subsample=1.084906952274622; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.9775322919511973, gamma=0.13157737404844716, lambda=0.31162537429621684, learning_rate=0.11818490113000833, max_depth=11, min_child_weight=3, n_estimators=650, scale_pos_weight=2.1556730145581593, subsample=1.084906952274622; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9041990638709285, gamma=0.3805216286533168, lambda=0.013783275842025655, learning_rate=0.37745763529325127, max_depth=11, min_child_weight=1, n_estimators=700, scale_pos_weight=1.176764276959527, subsample=1.2627532047744734; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9041990638709285, gamma=0.3805216286533168, lambda=0.013783275842025655, learning_rate=0.37745763529325127, max_depth=11, min_child_weight=1, n_estimators=700, scale_pos_weight=1.176764276959527, subsample=1.2627532047744734; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9041990638709285, gamma=0.3805216286533168, lambda=0.013783275842025655, learning_rate=0.37745763529325127, max_depth=11, min_child_weight=1, n_estimators=700, scale_pos_weight=1.176764276959527, subsample=1.2627532047744734; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9041990638709285, gamma=0.3805216286533168, lambda=0.013783275842025655, learning_rate=0.37745763529325127, max_depth=11, min_child_weight=1, n_estimators=700, scale_pos_weight=1.176764276959527, subsample=1.2627532047744734; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.4095380318825766, gamma=0.4712224224523366, lambda=0.07498615855899354, learning_rate=0.42024721522500197, max_depth=8, min_child_weight=3, n_estimators=750, scale_pos_weight=1.3408879423280244, subsample=1.0365678574318051; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.4095380318825766, gamma=0.4712224224523366, lambda=0.07498615855899354, learning_rate=0.42024721522500197, max_depth=8, min_child_weight=3, n_estimators=750, scale_pos_weight=1.3408879423280244, subsample=1.0365678574318051; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.4095380318825766, gamma=0.4712224224523366, lambda=0.07498615855899354, learning_rate=0.42024721522500197, max_depth=8, min_child_weight=3, n_estimators=750, scale_pos_weight=1.3408879423280244, subsample=1.0365678574318051; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.4095380318825766, gamma=0.4712224224523366, lambda=0.07498615855899354, learning_rate=0.42024721522500197, max_depth=8, min_child_weight=3, n_estimators=750, scale_pos_weight=1.3408879423280244, subsample=1.0365678574318051; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.660545007573129, gamma=0.06931577002709022, lambda=0.41195800557740275, learning_rate=0.41824327179541176, max_depth=8, min_child_weight=3, n_estimators=650, scale_pos_weight=1.5623648775064147, subsample=1.2785864692729223; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.660545007573129, gamma=0.06931577002709022, lambda=0.41195800557740275, learning_rate=0.41824327179541176, max_depth=8, min_child_weight=3, n_estimators=650, scale_pos_weight=1.5623648775064147, subsample=1.2785864692729223; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.660545007573129, gamma=0.06931577002709022, lambda=0.41195800557740275, learning_rate=0.41824327179541176, max_depth=8, min_child_weight=3, n_estimators=650, scale_pos_weight=1.5623648775064147, subsample=1.2785864692729223; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.660545007573129, gamma=0.06931577002709022, lambda=0.41195800557740275, learning_rate=0.41824327179541176, max_depth=8, min_child_weight=3, n_estimators=650, scale_pos_weight=1.5623648775064147, subsample=1.2785864692729223; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.9557741107330004, gamma=0.04451324139683166, lambda=0.38706225264039645, learning_rate=0.1209185052780428, max_depth=10, min_child_weight=1, n_estimators=400, scale_pos_weight=2.237864451649868, subsample=0.8255666503204132; total time=   0.4s\n",
      "[CV] END alpha=25, colsample_bytree=0.9557741107330004, gamma=0.04451324139683166, lambda=0.38706225264039645, learning_rate=0.1209185052780428, max_depth=10, min_child_weight=1, n_estimators=400, scale_pos_weight=2.237864451649868, subsample=0.8255666503204132; total time=   0.4s\n",
      "[CV] END alpha=25, colsample_bytree=0.9557741107330004, gamma=0.04451324139683166, lambda=0.38706225264039645, learning_rate=0.1209185052780428, max_depth=10, min_child_weight=1, n_estimators=400, scale_pos_weight=2.237864451649868, subsample=0.8255666503204132; total time=   0.4s\n",
      "[CV] END alpha=25, colsample_bytree=0.9557741107330004, gamma=0.04451324139683166, lambda=0.38706225264039645, learning_rate=0.1209185052780428, max_depth=10, min_child_weight=1, n_estimators=400, scale_pos_weight=2.237864451649868, subsample=0.8255666503204132; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.3383810894563016, gamma=0.45911485504708854, lambda=0.3399156917502995, learning_rate=0.3096276477700678, max_depth=8, min_child_weight=1, n_estimators=500, scale_pos_weight=0.9055472395692907, subsample=1.5913474647811183; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.3383810894563016, gamma=0.45911485504708854, lambda=0.3399156917502995, learning_rate=0.3096276477700678, max_depth=8, min_child_weight=1, n_estimators=500, scale_pos_weight=0.9055472395692907, subsample=1.5913474647811183; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.3383810894563016, gamma=0.45911485504708854, lambda=0.3399156917502995, learning_rate=0.3096276477700678, max_depth=8, min_child_weight=1, n_estimators=500, scale_pos_weight=0.9055472395692907, subsample=1.5913474647811183; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.3383810894563016, gamma=0.45911485504708854, lambda=0.3399156917502995, learning_rate=0.3096276477700678, max_depth=8, min_child_weight=1, n_estimators=500, scale_pos_weight=0.9055472395692907, subsample=1.5913474647811183; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.2670171104258923, gamma=0.023053900027682428, lambda=1.3570485307773081, learning_rate=0.4920518255034347, max_depth=5, min_child_weight=1, n_estimators=400, scale_pos_weight=2.242540042248386, subsample=1.096059659968119; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.2670171104258923, gamma=0.023053900027682428, lambda=1.3570485307773081, learning_rate=0.4920518255034347, max_depth=5, min_child_weight=1, n_estimators=400, scale_pos_weight=2.242540042248386, subsample=1.096059659968119; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.2670171104258923, gamma=0.023053900027682428, lambda=1.3570485307773081, learning_rate=0.4920518255034347, max_depth=5, min_child_weight=1, n_estimators=400, scale_pos_weight=2.242540042248386, subsample=1.096059659968119; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.2670171104258923, gamma=0.023053900027682428, lambda=1.3570485307773081, learning_rate=0.4920518255034347, max_depth=5, min_child_weight=1, n_estimators=400, scale_pos_weight=2.242540042248386, subsample=1.096059659968119; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.007584756449582, gamma=0.17162857874293436, lambda=0.7412369112582777, learning_rate=0.21684305036326418, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=0.880054172614086, subsample=0.9903951101468178; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.007584756449582, gamma=0.17162857874293436, lambda=0.7412369112582777, learning_rate=0.21684305036326418, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=0.880054172614086, subsample=0.9903951101468178; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.007584756449582, gamma=0.17162857874293436, lambda=0.7412369112582777, learning_rate=0.21684305036326418, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=0.880054172614086, subsample=0.9903951101468178; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.007584756449582, gamma=0.17162857874293436, lambda=0.7412369112582777, learning_rate=0.21684305036326418, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=0.880054172614086, subsample=0.9903951101468178; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7336443062659033, gamma=0.3569967623966336, lambda=1.09312109019049, learning_rate=0.18705760810589334, max_depth=8, min_child_weight=3, n_estimators=750, scale_pos_weight=1.42298716754823, subsample=1.363792007067615; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7336443062659033, gamma=0.3569967623966336, lambda=1.09312109019049, learning_rate=0.18705760810589334, max_depth=8, min_child_weight=3, n_estimators=750, scale_pos_weight=1.42298716754823, subsample=1.363792007067615; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7336443062659033, gamma=0.3569967623966336, lambda=1.09312109019049, learning_rate=0.18705760810589334, max_depth=8, min_child_weight=3, n_estimators=750, scale_pos_weight=1.42298716754823, subsample=1.363792007067615; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7336443062659033, gamma=0.3569967623966336, lambda=1.09312109019049, learning_rate=0.18705760810589334, max_depth=8, min_child_weight=3, n_estimators=750, scale_pos_weight=1.42298716754823, subsample=1.363792007067615; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9767777515761205, gamma=0.3518524846739126, lambda=0.45803405021908467, learning_rate=0.27052749295133016, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=0.7898547420871195, subsample=1.1972960733489006; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9767777515761205, gamma=0.3518524846739126, lambda=0.45803405021908467, learning_rate=0.27052749295133016, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=0.7898547420871195, subsample=1.1972960733489006; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9767777515761205, gamma=0.3518524846739126, lambda=0.45803405021908467, learning_rate=0.27052749295133016, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=0.7898547420871195, subsample=1.1972960733489006; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9767777515761205, gamma=0.3518524846739126, lambda=0.45803405021908467, learning_rate=0.27052749295133016, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=0.7898547420871195, subsample=1.1972960733489006; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.7532727278677456, gamma=0.4423221295855498, lambda=0.03189415593048317, learning_rate=0.45316181666147093, max_depth=7, min_child_weight=3, n_estimators=650, scale_pos_weight=1.120595988237477, subsample=1.5157705686552787; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.7532727278677456, gamma=0.4423221295855498, lambda=0.03189415593048317, learning_rate=0.45316181666147093, max_depth=7, min_child_weight=3, n_estimators=650, scale_pos_weight=1.120595988237477, subsample=1.5157705686552787; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.7532727278677456, gamma=0.4423221295855498, lambda=0.03189415593048317, learning_rate=0.45316181666147093, max_depth=7, min_child_weight=3, n_estimators=650, scale_pos_weight=1.120595988237477, subsample=1.5157705686552787; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.7532727278677456, gamma=0.4423221295855498, lambda=0.03189415593048317, learning_rate=0.45316181666147093, max_depth=7, min_child_weight=3, n_estimators=650, scale_pos_weight=1.120595988237477, subsample=1.5157705686552787; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.4718250531764617, gamma=0.19654496798467924, lambda=0.5808062316962432, learning_rate=0.36451757310215627, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=0.7276147638375806, subsample=1.4966830070077524; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.4718250531764617, gamma=0.19654496798467924, lambda=0.5808062316962432, learning_rate=0.36451757310215627, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=0.7276147638375806, subsample=1.4966830070077524; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.4718250531764617, gamma=0.19654496798467924, lambda=0.5808062316962432, learning_rate=0.36451757310215627, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=0.7276147638375806, subsample=1.4966830070077524; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.4718250531764617, gamma=0.19654496798467924, lambda=0.5808062316962432, learning_rate=0.36451757310215627, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=0.7276147638375806, subsample=1.4966830070077524; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7468824871226274, gamma=0.37125284873485287, lambda=0.2202930653493405, learning_rate=0.39287585207032916, max_depth=8, min_child_weight=1, n_estimators=250, scale_pos_weight=2.107538904586284, subsample=1.190258424404; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7468824871226274, gamma=0.37125284873485287, lambda=0.2202930653493405, learning_rate=0.39287585207032916, max_depth=8, min_child_weight=1, n_estimators=250, scale_pos_weight=2.107538904586284, subsample=1.190258424404; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7468824871226274, gamma=0.37125284873485287, lambda=0.2202930653493405, learning_rate=0.39287585207032916, max_depth=8, min_child_weight=1, n_estimators=250, scale_pos_weight=2.107538904586284, subsample=1.190258424404; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7468824871226274, gamma=0.37125284873485287, lambda=0.2202930653493405, learning_rate=0.39287585207032916, max_depth=8, min_child_weight=1, n_estimators=250, scale_pos_weight=2.107538904586284, subsample=1.190258424404; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.7119638824502155, gamma=0.23249780134433146, lambda=0.009312673796470772, learning_rate=0.16620562411429773, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=2.0798714307175774, subsample=0.7228154390099227; total time=   0.4s\n",
      "[CV] END alpha=20, colsample_bytree=0.7119638824502155, gamma=0.23249780134433146, lambda=0.009312673796470772, learning_rate=0.16620562411429773, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=2.0798714307175774, subsample=0.7228154390099227; total time=   0.4s\n",
      "[CV] END alpha=20, colsample_bytree=0.7119638824502155, gamma=0.23249780134433146, lambda=0.009312673796470772, learning_rate=0.16620562411429773, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=2.0798714307175774, subsample=0.7228154390099227; total time=   0.4s\n",
      "[CV] END alpha=20, colsample_bytree=0.7119638824502155, gamma=0.23249780134433146, lambda=0.009312673796470772, learning_rate=0.16620562411429773, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=2.0798714307175774, subsample=0.7228154390099227; total time=   0.4s\n",
      "[CV] END alpha=25, colsample_bytree=0.2942410607555727, gamma=0.2329031895452212, lambda=0.9302681827515671, learning_rate=0.06116381869422848, max_depth=8, min_child_weight=1, n_estimators=650, scale_pos_weight=0.7549813776875459, subsample=0.7288073443121702; total time=   0.5s\n",
      "[CV] END alpha=25, colsample_bytree=0.2942410607555727, gamma=0.2329031895452212, lambda=0.9302681827515671, learning_rate=0.06116381869422848, max_depth=8, min_child_weight=1, n_estimators=650, scale_pos_weight=0.7549813776875459, subsample=0.7288073443121702; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.2942410607555727, gamma=0.2329031895452212, lambda=0.9302681827515671, learning_rate=0.06116381869422848, max_depth=8, min_child_weight=1, n_estimators=650, scale_pos_weight=0.7549813776875459, subsample=0.7288073443121702; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.2942410607555727, gamma=0.2329031895452212, lambda=0.9302681827515671, learning_rate=0.06116381869422848, max_depth=8, min_child_weight=1, n_estimators=650, scale_pos_weight=0.7549813776875459, subsample=0.7288073443121702; total time=   0.2s\n",
      "[CV] END alpha=5, colsample_bytree=0.460847649695691, gamma=0.3828361359149376, lambda=0.355060726955542, learning_rate=0.16894948021595252, max_depth=5, min_child_weight=3, n_estimators=600, scale_pos_weight=2.551771864093386, subsample=1.0802607120697783; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.460847649695691, gamma=0.3828361359149376, lambda=0.355060726955542, learning_rate=0.16894948021595252, max_depth=5, min_child_weight=3, n_estimators=600, scale_pos_weight=2.551771864093386, subsample=1.0802607120697783; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.460847649695691, gamma=0.3828361359149376, lambda=0.355060726955542, learning_rate=0.16894948021595252, max_depth=5, min_child_weight=3, n_estimators=600, scale_pos_weight=2.551771864093386, subsample=1.0802607120697783; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.460847649695691, gamma=0.3828361359149376, lambda=0.355060726955542, learning_rate=0.16894948021595252, max_depth=5, min_child_weight=3, n_estimators=600, scale_pos_weight=2.551771864093386, subsample=1.0802607120697783; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.096738248290004, gamma=0.3224839376759848, lambda=0.33244646075806034, learning_rate=0.2093117331352724, max_depth=11, min_child_weight=3, n_estimators=500, scale_pos_weight=1.0823990751881105, subsample=0.8111689603217483; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.096738248290004, gamma=0.3224839376759848, lambda=0.33244646075806034, learning_rate=0.2093117331352724, max_depth=11, min_child_weight=3, n_estimators=500, scale_pos_weight=1.0823990751881105, subsample=0.8111689603217483; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.096738248290004, gamma=0.3224839376759848, lambda=0.33244646075806034, learning_rate=0.2093117331352724, max_depth=11, min_child_weight=3, n_estimators=500, scale_pos_weight=1.0823990751881105, subsample=0.8111689603217483; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.096738248290004, gamma=0.3224839376759848, lambda=0.33244646075806034, learning_rate=0.2093117331352724, max_depth=11, min_child_weight=3, n_estimators=500, scale_pos_weight=1.0823990751881105, subsample=0.8111689603217483; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.0094262418882007, gamma=0.11472285938858723, lambda=1.3235163528571743, learning_rate=0.3013601546061414, max_depth=8, min_child_weight=3, n_estimators=300, scale_pos_weight=1.2414532799798574, subsample=0.7903627032294869; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.0094262418882007, gamma=0.11472285938858723, lambda=1.3235163528571743, learning_rate=0.3013601546061414, max_depth=8, min_child_weight=3, n_estimators=300, scale_pos_weight=1.2414532799798574, subsample=0.7903627032294869; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.0094262418882007, gamma=0.11472285938858723, lambda=1.3235163528571743, learning_rate=0.3013601546061414, max_depth=8, min_child_weight=3, n_estimators=300, scale_pos_weight=1.2414532799798574, subsample=0.7903627032294869; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.0094262418882007, gamma=0.11472285938858723, lambda=1.3235163528571743, learning_rate=0.3013601546061414, max_depth=8, min_child_weight=3, n_estimators=300, scale_pos_weight=1.2414532799798574, subsample=0.7903627032294869; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.614562241446369, gamma=0.2907378959267749, lambda=1.336203761830833, learning_rate=0.13524475318389861, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=1.0607641078347563, subsample=1.323155852365336; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.614562241446369, gamma=0.2907378959267749, lambda=1.336203761830833, learning_rate=0.13524475318389861, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=1.0607641078347563, subsample=1.323155852365336; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.614562241446369, gamma=0.2907378959267749, lambda=1.336203761830833, learning_rate=0.13524475318389861, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=1.0607641078347563, subsample=1.323155852365336; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.614562241446369, gamma=0.2907378959267749, lambda=1.336203761830833, learning_rate=0.13524475318389861, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=1.0607641078347563, subsample=1.323155852365336; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5748300739791916, gamma=0.02656187953678657, lambda=0.17233200890917988, learning_rate=0.10975106157879898, max_depth=5, min_child_weight=3, n_estimators=650, scale_pos_weight=2.766995665075652, subsample=1.5758822111138437; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5748300739791916, gamma=0.02656187953678657, lambda=0.17233200890917988, learning_rate=0.10975106157879898, max_depth=5, min_child_weight=3, n_estimators=650, scale_pos_weight=2.766995665075652, subsample=1.5758822111138437; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5748300739791916, gamma=0.02656187953678657, lambda=0.17233200890917988, learning_rate=0.10975106157879898, max_depth=5, min_child_weight=3, n_estimators=650, scale_pos_weight=2.766995665075652, subsample=1.5758822111138437; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5748300739791916, gamma=0.02656187953678657, lambda=0.17233200890917988, learning_rate=0.10975106157879898, max_depth=5, min_child_weight=3, n_estimators=650, scale_pos_weight=2.766995665075652, subsample=1.5758822111138437; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.865441211689884, gamma=0.357199087860165, lambda=1.1515483513158058, learning_rate=0.19934880029017948, max_depth=6, min_child_weight=3, n_estimators=350, scale_pos_weight=0.8851496883171938, subsample=1.2147086630843793; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.865441211689884, gamma=0.357199087860165, lambda=1.1515483513158058, learning_rate=0.19934880029017948, max_depth=6, min_child_weight=3, n_estimators=350, scale_pos_weight=0.8851496883171938, subsample=1.2147086630843793; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.865441211689884, gamma=0.357199087860165, lambda=1.1515483513158058, learning_rate=0.19934880029017948, max_depth=6, min_child_weight=3, n_estimators=350, scale_pos_weight=0.8851496883171938, subsample=1.2147086630843793; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.865441211689884, gamma=0.357199087860165, lambda=1.1515483513158058, learning_rate=0.19934880029017948, max_depth=6, min_child_weight=3, n_estimators=350, scale_pos_weight=0.8851496883171938, subsample=1.2147086630843793; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.6650981050621732, gamma=0.31999808007585606, lambda=0.8460462960472275, learning_rate=0.3204536652201809, max_depth=9, min_child_weight=1, n_estimators=600, scale_pos_weight=2.154365287252231, subsample=0.9415944369496101; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.6650981050621732, gamma=0.31999808007585606, lambda=0.8460462960472275, learning_rate=0.3204536652201809, max_depth=9, min_child_weight=1, n_estimators=600, scale_pos_weight=2.154365287252231, subsample=0.9415944369496101; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.6650981050621732, gamma=0.31999808007585606, lambda=0.8460462960472275, learning_rate=0.3204536652201809, max_depth=9, min_child_weight=1, n_estimators=600, scale_pos_weight=2.154365287252231, subsample=0.9415944369496101; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.6650981050621732, gamma=0.31999808007585606, lambda=0.8460462960472275, learning_rate=0.3204536652201809, max_depth=9, min_child_weight=1, n_estimators=600, scale_pos_weight=2.154365287252231, subsample=0.9415944369496101; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.34821688603980044, gamma=0.23285266727666915, lambda=1.2986894957110497, learning_rate=0.3336986630386363, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=2.815209694724662, subsample=0.8214178004980739; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.34821688603980044, gamma=0.23285266727666915, lambda=1.2986894957110497, learning_rate=0.3336986630386363, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=2.815209694724662, subsample=0.8214178004980739; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.34821688603980044, gamma=0.23285266727666915, lambda=1.2986894957110497, learning_rate=0.3336986630386363, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=2.815209694724662, subsample=0.8214178004980739; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.34821688603980044, gamma=0.23285266727666915, lambda=1.2986894957110497, learning_rate=0.3336986630386363, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=2.815209694724662, subsample=0.8214178004980739; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.8047576830304184, gamma=0.04242942531362104, lambda=0.17974535797610675, learning_rate=0.18041209305287054, max_depth=9, min_child_weight=1, n_estimators=550, scale_pos_weight=1.4526053877079343, subsample=1.0880560522067886; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.8047576830304184, gamma=0.04242942531362104, lambda=0.17974535797610675, learning_rate=0.18041209305287054, max_depth=9, min_child_weight=1, n_estimators=550, scale_pos_weight=1.4526053877079343, subsample=1.0880560522067886; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.8047576830304184, gamma=0.04242942531362104, lambda=0.17974535797610675, learning_rate=0.18041209305287054, max_depth=9, min_child_weight=1, n_estimators=550, scale_pos_weight=1.4526053877079343, subsample=1.0880560522067886; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.8047576830304184, gamma=0.04242942531362104, lambda=0.17974535797610675, learning_rate=0.18041209305287054, max_depth=9, min_child_weight=1, n_estimators=550, scale_pos_weight=1.4526053877079343, subsample=1.0880560522067886; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.6849138596102826, gamma=0.2101100848486625, lambda=0.23627171599808122, learning_rate=0.1904965004537797, max_depth=8, min_child_weight=1, n_estimators=300, scale_pos_weight=1.3353396835576543, subsample=0.8616874710364042; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.6849138596102826, gamma=0.2101100848486625, lambda=0.23627171599808122, learning_rate=0.1904965004537797, max_depth=8, min_child_weight=1, n_estimators=300, scale_pos_weight=1.3353396835576543, subsample=0.8616874710364042; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.6849138596102826, gamma=0.2101100848486625, lambda=0.23627171599808122, learning_rate=0.1904965004537797, max_depth=8, min_child_weight=1, n_estimators=300, scale_pos_weight=1.3353396835576543, subsample=0.8616874710364042; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.6849138596102826, gamma=0.2101100848486625, lambda=0.23627171599808122, learning_rate=0.1904965004537797, max_depth=8, min_child_weight=1, n_estimators=300, scale_pos_weight=1.3353396835576543, subsample=0.8616874710364042; total time=   0.2s\n",
      "[CV] END alpha=5, colsample_bytree=1.001450266470826, gamma=0.03410065846648813, lambda=1.0734695862814587, learning_rate=0.1946666782326551, max_depth=10, min_child_weight=1, n_estimators=250, scale_pos_weight=2.2694526753616495, subsample=1.5997475620142791; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.001450266470826, gamma=0.03410065846648813, lambda=1.0734695862814587, learning_rate=0.1946666782326551, max_depth=10, min_child_weight=1, n_estimators=250, scale_pos_weight=2.2694526753616495, subsample=1.5997475620142791; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.001450266470826, gamma=0.03410065846648813, lambda=1.0734695862814587, learning_rate=0.1946666782326551, max_depth=10, min_child_weight=1, n_estimators=250, scale_pos_weight=2.2694526753616495, subsample=1.5997475620142791; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.001450266470826, gamma=0.03410065846648813, lambda=1.0734695862814587, learning_rate=0.1946666782326551, max_depth=10, min_child_weight=1, n_estimators=250, scale_pos_weight=2.2694526753616495, subsample=1.5997475620142791; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5378800298965107, gamma=0.09540429916579068, lambda=0.7221072983843624, learning_rate=0.09839268519898074, max_depth=9, min_child_weight=3, n_estimators=450, scale_pos_weight=0.9328333463674748, subsample=1.0618533047644654; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5378800298965107, gamma=0.09540429916579068, lambda=0.7221072983843624, learning_rate=0.09839268519898074, max_depth=9, min_child_weight=3, n_estimators=450, scale_pos_weight=0.9328333463674748, subsample=1.0618533047644654; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5378800298965107, gamma=0.09540429916579068, lambda=0.7221072983843624, learning_rate=0.09839268519898074, max_depth=9, min_child_weight=3, n_estimators=450, scale_pos_weight=0.9328333463674748, subsample=1.0618533047644654; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5378800298965107, gamma=0.09540429916579068, lambda=0.7221072983843624, learning_rate=0.09839268519898074, max_depth=9, min_child_weight=3, n_estimators=450, scale_pos_weight=0.9328333463674748, subsample=1.0618533047644654; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7597552700540962, gamma=0.393322145137964, lambda=1.3438921051375872, learning_rate=0.2140897885173466, max_depth=6, min_child_weight=3, n_estimators=650, scale_pos_weight=1.1808200428421451, subsample=1.3238067319941815; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7597552700540962, gamma=0.393322145137964, lambda=1.3438921051375872, learning_rate=0.2140897885173466, max_depth=6, min_child_weight=3, n_estimators=650, scale_pos_weight=1.1808200428421451, subsample=1.3238067319941815; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7597552700540962, gamma=0.393322145137964, lambda=1.3438921051375872, learning_rate=0.2140897885173466, max_depth=6, min_child_weight=3, n_estimators=650, scale_pos_weight=1.1808200428421451, subsample=1.3238067319941815; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7597552700540962, gamma=0.393322145137964, lambda=1.3438921051375872, learning_rate=0.2140897885173466, max_depth=6, min_child_weight=3, n_estimators=650, scale_pos_weight=1.1808200428421451, subsample=1.3238067319941815; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1863829527774863, gamma=0.1078599446047645, lambda=0.15980032192391225, learning_rate=0.28734331346638564, max_depth=5, min_child_weight=1, n_estimators=250, scale_pos_weight=2.124098210389903, subsample=1.434746648676316; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1863829527774863, gamma=0.1078599446047645, lambda=0.15980032192391225, learning_rate=0.28734331346638564, max_depth=5, min_child_weight=1, n_estimators=250, scale_pos_weight=2.124098210389903, subsample=1.434746648676316; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1863829527774863, gamma=0.1078599446047645, lambda=0.15980032192391225, learning_rate=0.28734331346638564, max_depth=5, min_child_weight=1, n_estimators=250, scale_pos_weight=2.124098210389903, subsample=1.434746648676316; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1863829527774863, gamma=0.1078599446047645, lambda=0.15980032192391225, learning_rate=0.28734331346638564, max_depth=5, min_child_weight=1, n_estimators=250, scale_pos_weight=2.124098210389903, subsample=1.434746648676316; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6195547602351792, gamma=0.37299798075085455, lambda=0.9160456144645726, learning_rate=0.40062395023148095, max_depth=10, min_child_weight=1, n_estimators=350, scale_pos_weight=1.750621733881588, subsample=1.2145758778470337; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6195547602351792, gamma=0.37299798075085455, lambda=0.9160456144645726, learning_rate=0.40062395023148095, max_depth=10, min_child_weight=1, n_estimators=350, scale_pos_weight=1.750621733881588, subsample=1.2145758778470337; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6195547602351792, gamma=0.37299798075085455, lambda=0.9160456144645726, learning_rate=0.40062395023148095, max_depth=10, min_child_weight=1, n_estimators=350, scale_pos_weight=1.750621733881588, subsample=1.2145758778470337; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6195547602351792, gamma=0.37299798075085455, lambda=0.9160456144645726, learning_rate=0.40062395023148095, max_depth=10, min_child_weight=1, n_estimators=350, scale_pos_weight=1.750621733881588, subsample=1.2145758778470337; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.29421164239768477, gamma=0.1669167540146544, lambda=0.06425931914516197, learning_rate=0.058944758937209844, max_depth=5, min_child_weight=1, n_estimators=550, scale_pos_weight=1.1532501873611298, subsample=1.0817035145931007; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.29421164239768477, gamma=0.1669167540146544, lambda=0.06425931914516197, learning_rate=0.058944758937209844, max_depth=5, min_child_weight=1, n_estimators=550, scale_pos_weight=1.1532501873611298, subsample=1.0817035145931007; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.29421164239768477, gamma=0.1669167540146544, lambda=0.06425931914516197, learning_rate=0.058944758937209844, max_depth=5, min_child_weight=1, n_estimators=550, scale_pos_weight=1.1532501873611298, subsample=1.0817035145931007; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.29421164239768477, gamma=0.1669167540146544, lambda=0.06425931914516197, learning_rate=0.058944758937209844, max_depth=5, min_child_weight=1, n_estimators=550, scale_pos_weight=1.1532501873611298, subsample=1.0817035145931007; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.270489744840636, gamma=0.32576039668486856, lambda=1.493202364308244, learning_rate=0.09045378404315417, max_depth=7, min_child_weight=1, n_estimators=550, scale_pos_weight=1.7560157827078686, subsample=1.2982472739370996; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.270489744840636, gamma=0.32576039668486856, lambda=1.493202364308244, learning_rate=0.09045378404315417, max_depth=7, min_child_weight=1, n_estimators=550, scale_pos_weight=1.7560157827078686, subsample=1.2982472739370996; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.270489744840636, gamma=0.32576039668486856, lambda=1.493202364308244, learning_rate=0.09045378404315417, max_depth=7, min_child_weight=1, n_estimators=550, scale_pos_weight=1.7560157827078686, subsample=1.2982472739370996; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.270489744840636, gamma=0.32576039668486856, lambda=1.493202364308244, learning_rate=0.09045378404315417, max_depth=7, min_child_weight=1, n_estimators=550, scale_pos_weight=1.7560157827078686, subsample=1.2982472739370996; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5495814376899779, gamma=0.15427594770008662, lambda=1.205286411438798, learning_rate=0.06398086833944004, max_depth=7, min_child_weight=3, n_estimators=650, scale_pos_weight=0.7429687344278888, subsample=0.8650898789258118; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.5495814376899779, gamma=0.15427594770008662, lambda=1.205286411438798, learning_rate=0.06398086833944004, max_depth=7, min_child_weight=3, n_estimators=650, scale_pos_weight=0.7429687344278888, subsample=0.8650898789258118; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.5495814376899779, gamma=0.15427594770008662, lambda=1.205286411438798, learning_rate=0.06398086833944004, max_depth=7, min_child_weight=3, n_estimators=650, scale_pos_weight=0.7429687344278888, subsample=0.8650898789258118; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.5495814376899779, gamma=0.15427594770008662, lambda=1.205286411438798, learning_rate=0.06398086833944004, max_depth=7, min_child_weight=3, n_estimators=650, scale_pos_weight=0.7429687344278888, subsample=0.8650898789258118; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.6602120735600348, gamma=0.4211467561190537, lambda=0.20565089146113374, learning_rate=0.316755246658685, max_depth=5, min_child_weight=3, n_estimators=400, scale_pos_weight=2.2669414061902904, subsample=0.6566357805017103; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.6602120735600348, gamma=0.4211467561190537, lambda=0.20565089146113374, learning_rate=0.316755246658685, max_depth=5, min_child_weight=3, n_estimators=400, scale_pos_weight=2.2669414061902904, subsample=0.6566357805017103; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.6602120735600348, gamma=0.4211467561190537, lambda=0.20565089146113374, learning_rate=0.316755246658685, max_depth=5, min_child_weight=3, n_estimators=400, scale_pos_weight=2.2669414061902904, subsample=0.6566357805017103; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.6602120735600348, gamma=0.4211467561190537, lambda=0.20565089146113374, learning_rate=0.316755246658685, max_depth=5, min_child_weight=3, n_estimators=400, scale_pos_weight=2.2669414061902904, subsample=0.6566357805017103; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=0.33071561917365794, gamma=0.3192840057932279, lambda=0.5056027437545663, learning_rate=0.4159794540085923, max_depth=6, min_child_weight=3, n_estimators=400, scale_pos_weight=1.733381506192706, subsample=0.6678366076483144; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=0.33071561917365794, gamma=0.3192840057932279, lambda=0.5056027437545663, learning_rate=0.4159794540085923, max_depth=6, min_child_weight=3, n_estimators=400, scale_pos_weight=1.733381506192706, subsample=0.6678366076483144; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=0.33071561917365794, gamma=0.3192840057932279, lambda=0.5056027437545663, learning_rate=0.4159794540085923, max_depth=6, min_child_weight=3, n_estimators=400, scale_pos_weight=1.733381506192706, subsample=0.6678366076483144; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=0.33071561917365794, gamma=0.3192840057932279, lambda=0.5056027437545663, learning_rate=0.4159794540085923, max_depth=6, min_child_weight=3, n_estimators=400, scale_pos_weight=1.733381506192706, subsample=0.6678366076483144; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=0.28633688741541746, gamma=0.3660283301705934, lambda=0.8148939969211257, learning_rate=0.20682012780504844, max_depth=8, min_child_weight=3, n_estimators=750, scale_pos_weight=0.8444227358737117, subsample=0.9885459431273568; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.28633688741541746, gamma=0.3660283301705934, lambda=0.8148939969211257, learning_rate=0.20682012780504844, max_depth=8, min_child_weight=3, n_estimators=750, scale_pos_weight=0.8444227358737117, subsample=0.9885459431273568; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.28633688741541746, gamma=0.3660283301705934, lambda=0.8148939969211257, learning_rate=0.20682012780504844, max_depth=8, min_child_weight=3, n_estimators=750, scale_pos_weight=0.8444227358737117, subsample=0.9885459431273568; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.28633688741541746, gamma=0.3660283301705934, lambda=0.8148939969211257, learning_rate=0.20682012780504844, max_depth=8, min_child_weight=3, n_estimators=750, scale_pos_weight=0.8444227358737117, subsample=0.9885459431273568; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=1.053818593285972, gamma=0.07250411771469639, lambda=0.4868163335249344, learning_rate=0.2631271595840665, max_depth=8, min_child_weight=3, n_estimators=300, scale_pos_weight=2.3951702926234915, subsample=0.6871189163695461; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.053818593285972, gamma=0.07250411771469639, lambda=0.4868163335249344, learning_rate=0.2631271595840665, max_depth=8, min_child_weight=3, n_estimators=300, scale_pos_weight=2.3951702926234915, subsample=0.6871189163695461; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.053818593285972, gamma=0.07250411771469639, lambda=0.4868163335249344, learning_rate=0.2631271595840665, max_depth=8, min_child_weight=3, n_estimators=300, scale_pos_weight=2.3951702926234915, subsample=0.6871189163695461; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.053818593285972, gamma=0.07250411771469639, lambda=0.4868163335249344, learning_rate=0.2631271595840665, max_depth=8, min_child_weight=3, n_estimators=300, scale_pos_weight=2.3951702926234915, subsample=0.6871189163695461; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1577526330157557, gamma=0.39747821969048414, lambda=0.21909710258061493, learning_rate=0.31738758530660727, max_depth=10, min_child_weight=3, n_estimators=550, scale_pos_weight=1.5696154562398985, subsample=0.7217473289190238; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1577526330157557, gamma=0.39747821969048414, lambda=0.21909710258061493, learning_rate=0.31738758530660727, max_depth=10, min_child_weight=3, n_estimators=550, scale_pos_weight=1.5696154562398985, subsample=0.7217473289190238; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1577526330157557, gamma=0.39747821969048414, lambda=0.21909710258061493, learning_rate=0.31738758530660727, max_depth=10, min_child_weight=3, n_estimators=550, scale_pos_weight=1.5696154562398985, subsample=0.7217473289190238; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1577526330157557, gamma=0.39747821969048414, lambda=0.21909710258061493, learning_rate=0.31738758530660727, max_depth=10, min_child_weight=3, n_estimators=550, scale_pos_weight=1.5696154562398985, subsample=0.7217473289190238; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.9564645288789937, gamma=0.40158020387177185, lambda=1.3126030835584381, learning_rate=0.03217377486231931, max_depth=10, min_child_weight=1, n_estimators=600, scale_pos_weight=2.3575183358207923, subsample=0.6827087679784147; total time=   0.9s\n",
      "[CV] END alpha=25, colsample_bytree=0.9564645288789937, gamma=0.40158020387177185, lambda=1.3126030835584381, learning_rate=0.03217377486231931, max_depth=10, min_child_weight=1, n_estimators=600, scale_pos_weight=2.3575183358207923, subsample=0.6827087679784147; total time=   0.8s\n",
      "[CV] END alpha=25, colsample_bytree=0.9564645288789937, gamma=0.40158020387177185, lambda=1.3126030835584381, learning_rate=0.03217377486231931, max_depth=10, min_child_weight=1, n_estimators=600, scale_pos_weight=2.3575183358207923, subsample=0.6827087679784147; total time=   0.8s\n",
      "[CV] END alpha=25, colsample_bytree=0.9564645288789937, gamma=0.40158020387177185, lambda=1.3126030835584381, learning_rate=0.03217377486231931, max_depth=10, min_child_weight=1, n_estimators=600, scale_pos_weight=2.3575183358207923, subsample=0.6827087679784147; total time=   0.7s\n",
      "[CV] END alpha=5, colsample_bytree=0.9513212220908649, gamma=0.05125405153345458, lambda=0.4017359553782413, learning_rate=0.41830596150921967, max_depth=10, min_child_weight=3, n_estimators=600, scale_pos_weight=0.7774566851351323, subsample=1.2653608940635153; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.9513212220908649, gamma=0.05125405153345458, lambda=0.4017359553782413, learning_rate=0.41830596150921967, max_depth=10, min_child_weight=3, n_estimators=600, scale_pos_weight=0.7774566851351323, subsample=1.2653608940635153; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.9513212220908649, gamma=0.05125405153345458, lambda=0.4017359553782413, learning_rate=0.41830596150921967, max_depth=10, min_child_weight=3, n_estimators=600, scale_pos_weight=0.7774566851351323, subsample=1.2653608940635153; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.9513212220908649, gamma=0.05125405153345458, lambda=0.4017359553782413, learning_rate=0.41830596150921967, max_depth=10, min_child_weight=3, n_estimators=600, scale_pos_weight=0.7774566851351323, subsample=1.2653608940635153; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.20413963650394157, gamma=0.19777163693571553, lambda=1.4617985344152147, learning_rate=0.16152054171232816, max_depth=6, min_child_weight=1, n_estimators=350, scale_pos_weight=0.8277001591317064, subsample=1.3018785466827292; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.20413963650394157, gamma=0.19777163693571553, lambda=1.4617985344152147, learning_rate=0.16152054171232816, max_depth=6, min_child_weight=1, n_estimators=350, scale_pos_weight=0.8277001591317064, subsample=1.3018785466827292; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.20413963650394157, gamma=0.19777163693571553, lambda=1.4617985344152147, learning_rate=0.16152054171232816, max_depth=6, min_child_weight=1, n_estimators=350, scale_pos_weight=0.8277001591317064, subsample=1.3018785466827292; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.20413963650394157, gamma=0.19777163693571553, lambda=1.4617985344152147, learning_rate=0.16152054171232816, max_depth=6, min_child_weight=1, n_estimators=350, scale_pos_weight=0.8277001591317064, subsample=1.3018785466827292; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8949553197443587, gamma=0.20242622346835487, lambda=0.7536941089031975, learning_rate=0.1446269953302678, max_depth=5, min_child_weight=3, n_estimators=600, scale_pos_weight=1.1453835034833095, subsample=1.08473771346217; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8949553197443587, gamma=0.20242622346835487, lambda=0.7536941089031975, learning_rate=0.1446269953302678, max_depth=5, min_child_weight=3, n_estimators=600, scale_pos_weight=1.1453835034833095, subsample=1.08473771346217; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8949553197443587, gamma=0.20242622346835487, lambda=0.7536941089031975, learning_rate=0.1446269953302678, max_depth=5, min_child_weight=3, n_estimators=600, scale_pos_weight=1.1453835034833095, subsample=1.08473771346217; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8949553197443587, gamma=0.20242622346835487, lambda=0.7536941089031975, learning_rate=0.1446269953302678, max_depth=5, min_child_weight=3, n_estimators=600, scale_pos_weight=1.1453835034833095, subsample=1.08473771346217; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7284612515995763, gamma=0.38342550498665895, lambda=0.31234697905204395, learning_rate=0.3486411695745916, max_depth=6, min_child_weight=3, n_estimators=400, scale_pos_weight=0.9093755302577348, subsample=0.8869810431724559; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=0.7284612515995763, gamma=0.38342550498665895, lambda=0.31234697905204395, learning_rate=0.3486411695745916, max_depth=6, min_child_weight=3, n_estimators=400, scale_pos_weight=0.9093755302577348, subsample=0.8869810431724559; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=0.7284612515995763, gamma=0.38342550498665895, lambda=0.31234697905204395, learning_rate=0.3486411695745916, max_depth=6, min_child_weight=3, n_estimators=400, scale_pos_weight=0.9093755302577348, subsample=0.8869810431724559; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=0.7284612515995763, gamma=0.38342550498665895, lambda=0.31234697905204395, learning_rate=0.3486411695745916, max_depth=6, min_child_weight=3, n_estimators=400, scale_pos_weight=0.9093755302577348, subsample=0.8869810431724559; total time=   0.2s\n",
      "[CV] END alpha=15, colsample_bytree=0.649105901949842, gamma=0.2669853432548865, lambda=1.4547485906401922, learning_rate=0.21045044951391884, max_depth=5, min_child_weight=3, n_estimators=550, scale_pos_weight=0.725639760387331, subsample=0.9857853242202497; total time=   0.2s\n",
      "[CV] END alpha=15, colsample_bytree=0.649105901949842, gamma=0.2669853432548865, lambda=1.4547485906401922, learning_rate=0.21045044951391884, max_depth=5, min_child_weight=3, n_estimators=550, scale_pos_weight=0.725639760387331, subsample=0.9857853242202497; total time=   0.2s\n",
      "[CV] END alpha=15, colsample_bytree=0.649105901949842, gamma=0.2669853432548865, lambda=1.4547485906401922, learning_rate=0.21045044951391884, max_depth=5, min_child_weight=3, n_estimators=550, scale_pos_weight=0.725639760387331, subsample=0.9857853242202497; total time=   0.2s\n",
      "[CV] END alpha=15, colsample_bytree=0.649105901949842, gamma=0.2669853432548865, lambda=1.4547485906401922, learning_rate=0.21045044951391884, max_depth=5, min_child_weight=3, n_estimators=550, scale_pos_weight=0.725639760387331, subsample=0.9857853242202497; total time=   0.2s\n",
      "[CV] END alpha=5, colsample_bytree=1.0711644952254964, gamma=0.06358664497160743, lambda=0.9089661890984624, learning_rate=0.49893660677342494, max_depth=5, min_child_weight=1, n_estimators=500, scale_pos_weight=0.7203130068817608, subsample=0.9848150208893188; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0711644952254964, gamma=0.06358664497160743, lambda=0.9089661890984624, learning_rate=0.49893660677342494, max_depth=5, min_child_weight=1, n_estimators=500, scale_pos_weight=0.7203130068817608, subsample=0.9848150208893188; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0711644952254964, gamma=0.06358664497160743, lambda=0.9089661890984624, learning_rate=0.49893660677342494, max_depth=5, min_child_weight=1, n_estimators=500, scale_pos_weight=0.7203130068817608, subsample=0.9848150208893188; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0711644952254964, gamma=0.06358664497160743, lambda=0.9089661890984624, learning_rate=0.49893660677342494, max_depth=5, min_child_weight=1, n_estimators=500, scale_pos_weight=0.7203130068817608, subsample=0.9848150208893188; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.8323377547998179, gamma=0.4341567198560232, lambda=1.3686372952519343, learning_rate=0.42991855179744815, max_depth=11, min_child_weight=3, n_estimators=200, scale_pos_weight=0.900232307832947, subsample=0.8146154286375966; total time=   0.1s\n",
      "[CV] END alpha=25, colsample_bytree=0.8323377547998179, gamma=0.4341567198560232, lambda=1.3686372952519343, learning_rate=0.42991855179744815, max_depth=11, min_child_weight=3, n_estimators=200, scale_pos_weight=0.900232307832947, subsample=0.8146154286375966; total time=   0.1s\n",
      "[CV] END alpha=25, colsample_bytree=0.8323377547998179, gamma=0.4341567198560232, lambda=1.3686372952519343, learning_rate=0.42991855179744815, max_depth=11, min_child_weight=3, n_estimators=200, scale_pos_weight=0.900232307832947, subsample=0.8146154286375966; total time=   0.1s\n",
      "[CV] END alpha=25, colsample_bytree=0.8323377547998179, gamma=0.4341567198560232, lambda=1.3686372952519343, learning_rate=0.42991855179744815, max_depth=11, min_child_weight=3, n_estimators=200, scale_pos_weight=0.900232307832947, subsample=0.8146154286375966; total time=   0.1s\n",
      "[CV] END alpha=5, colsample_bytree=0.8265722978879004, gamma=0.003133460974816815, lambda=0.010669942338930538, learning_rate=0.4652483347720806, max_depth=11, min_child_weight=1, n_estimators=450, scale_pos_weight=2.0250638943031003, subsample=0.8503192914852941; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.8265722978879004, gamma=0.003133460974816815, lambda=0.010669942338930538, learning_rate=0.4652483347720806, max_depth=11, min_child_weight=1, n_estimators=450, scale_pos_weight=2.0250638943031003, subsample=0.8503192914852941; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.8265722978879004, gamma=0.003133460974816815, lambda=0.010669942338930538, learning_rate=0.4652483347720806, max_depth=11, min_child_weight=1, n_estimators=450, scale_pos_weight=2.0250638943031003, subsample=0.8503192914852941; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.8265722978879004, gamma=0.003133460974816815, lambda=0.010669942338930538, learning_rate=0.4652483347720806, max_depth=11, min_child_weight=1, n_estimators=450, scale_pos_weight=2.0250638943031003, subsample=0.8503192914852941; total time=   0.6s\n",
      "[CV] END alpha=10, colsample_bytree=0.6307054016249058, gamma=0.38556423656170485, lambda=0.691194884607605, learning_rate=0.3661723495437648, max_depth=8, min_child_weight=1, n_estimators=600, scale_pos_weight=1.095015590246086, subsample=1.11142678644016; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6307054016249058, gamma=0.38556423656170485, lambda=0.691194884607605, learning_rate=0.3661723495437648, max_depth=8, min_child_weight=1, n_estimators=600, scale_pos_weight=1.095015590246086, subsample=1.11142678644016; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6307054016249058, gamma=0.38556423656170485, lambda=0.691194884607605, learning_rate=0.3661723495437648, max_depth=8, min_child_weight=1, n_estimators=600, scale_pos_weight=1.095015590246086, subsample=1.11142678644016; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6307054016249058, gamma=0.38556423656170485, lambda=0.691194884607605, learning_rate=0.3661723495437648, max_depth=8, min_child_weight=1, n_estimators=600, scale_pos_weight=1.095015590246086, subsample=1.11142678644016; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.7437788967544778, gamma=0.1993166143264961, lambda=0.8806414863361507, learning_rate=0.4711194473810161, max_depth=8, min_child_weight=1, n_estimators=500, scale_pos_weight=1.7492735560666834, subsample=1.0580987176667804; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.7437788967544778, gamma=0.1993166143264961, lambda=0.8806414863361507, learning_rate=0.4711194473810161, max_depth=8, min_child_weight=1, n_estimators=500, scale_pos_weight=1.7492735560666834, subsample=1.0580987176667804; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.7437788967544778, gamma=0.1993166143264961, lambda=0.8806414863361507, learning_rate=0.4711194473810161, max_depth=8, min_child_weight=1, n_estimators=500, scale_pos_weight=1.7492735560666834, subsample=1.0580987176667804; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.7437788967544778, gamma=0.1993166143264961, lambda=0.8806414863361507, learning_rate=0.4711194473810161, max_depth=8, min_child_weight=1, n_estimators=500, scale_pos_weight=1.7492735560666834, subsample=1.0580987176667804; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5435597626878927, gamma=0.23971796876522777, lambda=0.6857944466957446, learning_rate=0.30810009677816486, max_depth=10, min_child_weight=3, n_estimators=600, scale_pos_weight=2.2319990871775084, subsample=1.5595921056388167; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5435597626878927, gamma=0.23971796876522777, lambda=0.6857944466957446, learning_rate=0.30810009677816486, max_depth=10, min_child_weight=3, n_estimators=600, scale_pos_weight=2.2319990871775084, subsample=1.5595921056388167; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5435597626878927, gamma=0.23971796876522777, lambda=0.6857944466957446, learning_rate=0.30810009677816486, max_depth=10, min_child_weight=3, n_estimators=600, scale_pos_weight=2.2319990871775084, subsample=1.5595921056388167; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5435597626878927, gamma=0.23971796876522777, lambda=0.6857944466957446, learning_rate=0.30810009677816486, max_depth=10, min_child_weight=3, n_estimators=600, scale_pos_weight=2.2319990871775084, subsample=1.5595921056388167; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.49241583145206486, gamma=0.013727144209054631, lambda=0.7721318985546335, learning_rate=0.252943032491091, max_depth=6, min_child_weight=3, n_estimators=300, scale_pos_weight=1.2157130150933866, subsample=1.117909938052616; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.49241583145206486, gamma=0.013727144209054631, lambda=0.7721318985546335, learning_rate=0.252943032491091, max_depth=6, min_child_weight=3, n_estimators=300, scale_pos_weight=1.2157130150933866, subsample=1.117909938052616; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.49241583145206486, gamma=0.013727144209054631, lambda=0.7721318985546335, learning_rate=0.252943032491091, max_depth=6, min_child_weight=3, n_estimators=300, scale_pos_weight=1.2157130150933866, subsample=1.117909938052616; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.49241583145206486, gamma=0.013727144209054631, lambda=0.7721318985546335, learning_rate=0.252943032491091, max_depth=6, min_child_weight=3, n_estimators=300, scale_pos_weight=1.2157130150933866, subsample=1.117909938052616; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.737460500972748, gamma=0.47536153290057076, lambda=0.17313691891127386, learning_rate=0.2657080564953079, max_depth=10, min_child_weight=1, n_estimators=700, scale_pos_weight=0.9414810170268318, subsample=0.7060718531858824; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.737460500972748, gamma=0.47536153290057076, lambda=0.17313691891127386, learning_rate=0.2657080564953079, max_depth=10, min_child_weight=1, n_estimators=700, scale_pos_weight=0.9414810170268318, subsample=0.7060718531858824; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.737460500972748, gamma=0.47536153290057076, lambda=0.17313691891127386, learning_rate=0.2657080564953079, max_depth=10, min_child_weight=1, n_estimators=700, scale_pos_weight=0.9414810170268318, subsample=0.7060718531858824; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.737460500972748, gamma=0.47536153290057076, lambda=0.17313691891127386, learning_rate=0.2657080564953079, max_depth=10, min_child_weight=1, n_estimators=700, scale_pos_weight=0.9414810170268318, subsample=0.7060718531858824; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.35259815289210344, gamma=0.07506125082063375, lambda=0.08124646743991176, learning_rate=0.3181539541751034, max_depth=6, min_child_weight=3, n_estimators=250, scale_pos_weight=2.603510178221572, subsample=1.2242416678710155; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.35259815289210344, gamma=0.07506125082063375, lambda=0.08124646743991176, learning_rate=0.3181539541751034, max_depth=6, min_child_weight=3, n_estimators=250, scale_pos_weight=2.603510178221572, subsample=1.2242416678710155; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.35259815289210344, gamma=0.07506125082063375, lambda=0.08124646743991176, learning_rate=0.3181539541751034, max_depth=6, min_child_weight=3, n_estimators=250, scale_pos_weight=2.603510178221572, subsample=1.2242416678710155; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.35259815289210344, gamma=0.07506125082063375, lambda=0.08124646743991176, learning_rate=0.3181539541751034, max_depth=6, min_child_weight=3, n_estimators=250, scale_pos_weight=2.603510178221572, subsample=1.2242416678710155; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.9852927001142333, gamma=0.25111765388031976, lambda=1.0035878116093158, learning_rate=0.42334071244387167, max_depth=8, min_child_weight=3, n_estimators=450, scale_pos_weight=1.079228123170464, subsample=1.5045046393851704; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.9852927001142333, gamma=0.25111765388031976, lambda=1.0035878116093158, learning_rate=0.42334071244387167, max_depth=8, min_child_weight=3, n_estimators=450, scale_pos_weight=1.079228123170464, subsample=1.5045046393851704; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.9852927001142333, gamma=0.25111765388031976, lambda=1.0035878116093158, learning_rate=0.42334071244387167, max_depth=8, min_child_weight=3, n_estimators=450, scale_pos_weight=1.079228123170464, subsample=1.5045046393851704; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.9852927001142333, gamma=0.25111765388031976, lambda=1.0035878116093158, learning_rate=0.42334071244387167, max_depth=8, min_child_weight=3, n_estimators=450, scale_pos_weight=1.079228123170464, subsample=1.5045046393851704; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0202181223385165, gamma=0.23458462172612526, lambda=0.979274312016295, learning_rate=0.24574141288824092, max_depth=11, min_child_weight=3, n_estimators=750, scale_pos_weight=1.3827025479505857, subsample=1.213516729153614; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0202181223385165, gamma=0.23458462172612526, lambda=0.979274312016295, learning_rate=0.24574141288824092, max_depth=11, min_child_weight=3, n_estimators=750, scale_pos_weight=1.3827025479505857, subsample=1.213516729153614; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0202181223385165, gamma=0.23458462172612526, lambda=0.979274312016295, learning_rate=0.24574141288824092, max_depth=11, min_child_weight=3, n_estimators=750, scale_pos_weight=1.3827025479505857, subsample=1.213516729153614; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0202181223385165, gamma=0.23458462172612526, lambda=0.979274312016295, learning_rate=0.24574141288824092, max_depth=11, min_child_weight=3, n_estimators=750, scale_pos_weight=1.3827025479505857, subsample=1.213516729153614; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.24582404830531407, gamma=0.018873261580386824, lambda=1.2654585763714041, learning_rate=0.4824303393714997, max_depth=11, min_child_weight=3, n_estimators=250, scale_pos_weight=1.1921325871420145, subsample=0.8635143131933034; total time=   0.3s\n",
      "[CV] END alpha=5, colsample_bytree=0.24582404830531407, gamma=0.018873261580386824, lambda=1.2654585763714041, learning_rate=0.4824303393714997, max_depth=11, min_child_weight=3, n_estimators=250, scale_pos_weight=1.1921325871420145, subsample=0.8635143131933034; total time=   0.3s\n",
      "[CV] END alpha=5, colsample_bytree=0.24582404830531407, gamma=0.018873261580386824, lambda=1.2654585763714041, learning_rate=0.4824303393714997, max_depth=11, min_child_weight=3, n_estimators=250, scale_pos_weight=1.1921325871420145, subsample=0.8635143131933034; total time=   0.7s\n",
      "[CV] END alpha=5, colsample_bytree=0.24582404830531407, gamma=0.018873261580386824, lambda=1.2654585763714041, learning_rate=0.4824303393714997, max_depth=11, min_child_weight=3, n_estimators=250, scale_pos_weight=1.1921325871420145, subsample=0.8635143131933034; total time=   1.4s\n",
      "[CV] END alpha=25, colsample_bytree=0.528142315349698, gamma=0.4415215411039628, lambda=1.4583967149607058, learning_rate=0.16027975793971255, max_depth=5, min_child_weight=3, n_estimators=650, scale_pos_weight=1.141869745089139, subsample=0.9598631004821228; total time=   0.6s\n",
      "[CV] END alpha=25, colsample_bytree=0.528142315349698, gamma=0.4415215411039628, lambda=1.4583967149607058, learning_rate=0.16027975793971255, max_depth=5, min_child_weight=3, n_estimators=650, scale_pos_weight=1.141869745089139, subsample=0.9598631004821228; total time=   0.6s\n",
      "[CV] END alpha=25, colsample_bytree=0.528142315349698, gamma=0.4415215411039628, lambda=1.4583967149607058, learning_rate=0.16027975793971255, max_depth=5, min_child_weight=3, n_estimators=650, scale_pos_weight=1.141869745089139, subsample=0.9598631004821228; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.528142315349698, gamma=0.4415215411039628, lambda=1.4583967149607058, learning_rate=0.16027975793971255, max_depth=5, min_child_weight=3, n_estimators=650, scale_pos_weight=1.141869745089139, subsample=0.9598631004821228; total time=   0.2s\n",
      "[CV] END alpha=15, colsample_bytree=0.645016735308017, gamma=0.3830086769799893, lambda=0.36351724425940485, learning_rate=0.42195661606843854, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=0.873457834046091, subsample=1.5701570261002014; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.645016735308017, gamma=0.3830086769799893, lambda=0.36351724425940485, learning_rate=0.42195661606843854, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=0.873457834046091, subsample=1.5701570261002014; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.645016735308017, gamma=0.3830086769799893, lambda=0.36351724425940485, learning_rate=0.42195661606843854, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=0.873457834046091, subsample=1.5701570261002014; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.645016735308017, gamma=0.3830086769799893, lambda=0.36351724425940485, learning_rate=0.42195661606843854, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=0.873457834046091, subsample=1.5701570261002014; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.8582178513043002, gamma=0.1124531913502152, lambda=0.4297572106967833, learning_rate=0.2697150743100002, max_depth=8, min_child_weight=1, n_estimators=650, scale_pos_weight=2.37878513191849, subsample=1.2942238412350964; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.8582178513043002, gamma=0.1124531913502152, lambda=0.4297572106967833, learning_rate=0.2697150743100002, max_depth=8, min_child_weight=1, n_estimators=650, scale_pos_weight=2.37878513191849, subsample=1.2942238412350964; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.8582178513043002, gamma=0.1124531913502152, lambda=0.4297572106967833, learning_rate=0.2697150743100002, max_depth=8, min_child_weight=1, n_estimators=650, scale_pos_weight=2.37878513191849, subsample=1.2942238412350964; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.8582178513043002, gamma=0.1124531913502152, lambda=0.4297572106967833, learning_rate=0.2697150743100002, max_depth=8, min_child_weight=1, n_estimators=650, scale_pos_weight=2.37878513191849, subsample=1.2942238412350964; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.8007871098674559, gamma=0.2591694581248407, lambda=0.8382835371089761, learning_rate=0.37203925797686066, max_depth=9, min_child_weight=3, n_estimators=250, scale_pos_weight=1.558847331078225, subsample=0.7282169352649926; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.8007871098674559, gamma=0.2591694581248407, lambda=0.8382835371089761, learning_rate=0.37203925797686066, max_depth=9, min_child_weight=3, n_estimators=250, scale_pos_weight=1.558847331078225, subsample=0.7282169352649926; total time=   0.7s\n",
      "[CV] END alpha=10, colsample_bytree=0.8007871098674559, gamma=0.2591694581248407, lambda=0.8382835371089761, learning_rate=0.37203925797686066, max_depth=9, min_child_weight=3, n_estimators=250, scale_pos_weight=1.558847331078225, subsample=0.7282169352649926; total time=   0.9s\n",
      "[CV] END alpha=10, colsample_bytree=0.8007871098674559, gamma=0.2591694581248407, lambda=0.8382835371089761, learning_rate=0.37203925797686066, max_depth=9, min_child_weight=3, n_estimators=250, scale_pos_weight=1.558847331078225, subsample=0.7282169352649926; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.8116345470750708, gamma=0.05246597266003894, lambda=0.6639172274529492, learning_rate=0.46511302549486244, max_depth=9, min_child_weight=3, n_estimators=300, scale_pos_weight=2.8014099113086637, subsample=0.8823384579347174; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.8116345470750708, gamma=0.05246597266003894, lambda=0.6639172274529492, learning_rate=0.46511302549486244, max_depth=9, min_child_weight=3, n_estimators=300, scale_pos_weight=2.8014099113086637, subsample=0.8823384579347174; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.8116345470750708, gamma=0.05246597266003894, lambda=0.6639172274529492, learning_rate=0.46511302549486244, max_depth=9, min_child_weight=3, n_estimators=300, scale_pos_weight=2.8014099113086637, subsample=0.8823384579347174; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.8116345470750708, gamma=0.05246597266003894, lambda=0.6639172274529492, learning_rate=0.46511302549486244, max_depth=9, min_child_weight=3, n_estimators=300, scale_pos_weight=2.8014099113086637, subsample=0.8823384579347174; total time=   0.2s\n",
      "[CV] END alpha=5, colsample_bytree=0.5595449244078778, gamma=0.05992743079559032, lambda=0.45861433853375044, learning_rate=0.059543933592966274, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=0.8884724022678413, subsample=1.2713033679610204; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.5595449244078778, gamma=0.05992743079559032, lambda=0.45861433853375044, learning_rate=0.059543933592966274, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=0.8884724022678413, subsample=1.2713033679610204; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.5595449244078778, gamma=0.05992743079559032, lambda=0.45861433853375044, learning_rate=0.059543933592966274, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=0.8884724022678413, subsample=1.2713033679610204; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.5595449244078778, gamma=0.05992743079559032, lambda=0.45861433853375044, learning_rate=0.059543933592966274, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=0.8884724022678413, subsample=1.2713033679610204; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.2586367873416134, gamma=0.17675585348261885, lambda=1.2204468254107392, learning_rate=0.30030155835546357, max_depth=9, min_child_weight=3, n_estimators=250, scale_pos_weight=2.41686772223962, subsample=0.7050411111500046; total time=   0.3s\n",
      "[CV] END alpha=5, colsample_bytree=0.2586367873416134, gamma=0.17675585348261885, lambda=1.2204468254107392, learning_rate=0.30030155835546357, max_depth=9, min_child_weight=3, n_estimators=250, scale_pos_weight=2.41686772223962, subsample=0.7050411111500046; total time=   0.3s\n",
      "[CV] END alpha=5, colsample_bytree=0.2586367873416134, gamma=0.17675585348261885, lambda=1.2204468254107392, learning_rate=0.30030155835546357, max_depth=9, min_child_weight=3, n_estimators=250, scale_pos_weight=2.41686772223962, subsample=0.7050411111500046; total time=   0.3s\n",
      "[CV] END alpha=5, colsample_bytree=0.2586367873416134, gamma=0.17675585348261885, lambda=1.2204468254107392, learning_rate=0.30030155835546357, max_depth=9, min_child_weight=3, n_estimators=250, scale_pos_weight=2.41686772223962, subsample=0.7050411111500046; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=1.0995512895260484, gamma=0.40613889902155875, lambda=0.8770994455790726, learning_rate=0.034750274988256995, max_depth=7, min_child_weight=1, n_estimators=400, scale_pos_weight=1.1493091540463605, subsample=1.1866077214116775; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0995512895260484, gamma=0.40613889902155875, lambda=0.8770994455790726, learning_rate=0.034750274988256995, max_depth=7, min_child_weight=1, n_estimators=400, scale_pos_weight=1.1493091540463605, subsample=1.1866077214116775; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0995512895260484, gamma=0.40613889902155875, lambda=0.8770994455790726, learning_rate=0.034750274988256995, max_depth=7, min_child_weight=1, n_estimators=400, scale_pos_weight=1.1493091540463605, subsample=1.1866077214116775; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0995512895260484, gamma=0.40613889902155875, lambda=0.8770994455790726, learning_rate=0.034750274988256995, max_depth=7, min_child_weight=1, n_estimators=400, scale_pos_weight=1.1493091540463605, subsample=1.1866077214116775; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.29023339113982943, gamma=0.2971824651331739, lambda=1.202040896536043, learning_rate=0.21704977594023195, max_depth=8, min_child_weight=3, n_estimators=200, scale_pos_weight=1.2153453997663592, subsample=0.6444263636508311; total time=   0.1s\n",
      "[CV] END alpha=20, colsample_bytree=0.29023339113982943, gamma=0.2971824651331739, lambda=1.202040896536043, learning_rate=0.21704977594023195, max_depth=8, min_child_weight=3, n_estimators=200, scale_pos_weight=1.2153453997663592, subsample=0.6444263636508311; total time=   0.1s\n",
      "[CV] END alpha=20, colsample_bytree=0.29023339113982943, gamma=0.2971824651331739, lambda=1.202040896536043, learning_rate=0.21704977594023195, max_depth=8, min_child_weight=3, n_estimators=200, scale_pos_weight=1.2153453997663592, subsample=0.6444263636508311; total time=   0.1s\n",
      "[CV] END alpha=20, colsample_bytree=0.29023339113982943, gamma=0.2971824651331739, lambda=1.202040896536043, learning_rate=0.21704977594023195, max_depth=8, min_child_weight=3, n_estimators=200, scale_pos_weight=1.2153453997663592, subsample=0.6444263636508311; total time=   0.1s\n",
      "[CV] END alpha=5, colsample_bytree=1.1756051218281265, gamma=0.059164792251889864, lambda=1.4196598732689591, learning_rate=0.044305051949351575, max_depth=11, min_child_weight=3, n_estimators=200, scale_pos_weight=0.8942640669945777, subsample=1.3548688109751925; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1756051218281265, gamma=0.059164792251889864, lambda=1.4196598732689591, learning_rate=0.044305051949351575, max_depth=11, min_child_weight=3, n_estimators=200, scale_pos_weight=0.8942640669945777, subsample=1.3548688109751925; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1756051218281265, gamma=0.059164792251889864, lambda=1.4196598732689591, learning_rate=0.044305051949351575, max_depth=11, min_child_weight=3, n_estimators=200, scale_pos_weight=0.8942640669945777, subsample=1.3548688109751925; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1756051218281265, gamma=0.059164792251889864, lambda=1.4196598732689591, learning_rate=0.044305051949351575, max_depth=11, min_child_weight=3, n_estimators=200, scale_pos_weight=0.8942640669945777, subsample=1.3548688109751925; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.6179962928878473, gamma=0.1378829254207078, lambda=0.34178205283804575, learning_rate=0.34306784454823713, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=1.8414597827318058, subsample=0.6516990930140434; total time=   0.4s\n",
      "[CV] END alpha=15, colsample_bytree=0.6179962928878473, gamma=0.1378829254207078, lambda=0.34178205283804575, learning_rate=0.34306784454823713, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=1.8414597827318058, subsample=0.6516990930140434; total time=   0.4s\n",
      "[CV] END alpha=15, colsample_bytree=0.6179962928878473, gamma=0.1378829254207078, lambda=0.34178205283804575, learning_rate=0.34306784454823713, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=1.8414597827318058, subsample=0.6516990930140434; total time=   0.4s\n",
      "[CV] END alpha=15, colsample_bytree=0.6179962928878473, gamma=0.1378829254207078, lambda=0.34178205283804575, learning_rate=0.34306784454823713, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=1.8414597827318058, subsample=0.6516990930140434; total time=   0.4s\n",
      "[CV] END alpha=25, colsample_bytree=0.36213807734893527, gamma=0.22443304944552195, lambda=0.06907378676693304, learning_rate=0.12557264007148594, max_depth=7, min_child_weight=1, n_estimators=200, scale_pos_weight=2.2092026263991804, subsample=0.9701159129015202; total time=   0.1s\n",
      "[CV] END alpha=25, colsample_bytree=0.36213807734893527, gamma=0.22443304944552195, lambda=0.06907378676693304, learning_rate=0.12557264007148594, max_depth=7, min_child_weight=1, n_estimators=200, scale_pos_weight=2.2092026263991804, subsample=0.9701159129015202; total time=   0.1s\n",
      "[CV] END alpha=25, colsample_bytree=0.36213807734893527, gamma=0.22443304944552195, lambda=0.06907378676693304, learning_rate=0.12557264007148594, max_depth=7, min_child_weight=1, n_estimators=200, scale_pos_weight=2.2092026263991804, subsample=0.9701159129015202; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.36213807734893527, gamma=0.22443304944552195, lambda=0.06907378676693304, learning_rate=0.12557264007148594, max_depth=7, min_child_weight=1, n_estimators=200, scale_pos_weight=2.2092026263991804, subsample=0.9701159129015202; total time=   0.1s\n",
      "[CV] END alpha=20, colsample_bytree=0.8603861386489289, gamma=0.2779054352829708, lambda=0.9044219059317589, learning_rate=0.2912201311959635, max_depth=10, min_child_weight=1, n_estimators=550, scale_pos_weight=0.7754445849317723, subsample=0.6752078123508874; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.8603861386489289, gamma=0.2779054352829708, lambda=0.9044219059317589, learning_rate=0.2912201311959635, max_depth=10, min_child_weight=1, n_estimators=550, scale_pos_weight=0.7754445849317723, subsample=0.6752078123508874; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.8603861386489289, gamma=0.2779054352829708, lambda=0.9044219059317589, learning_rate=0.2912201311959635, max_depth=10, min_child_weight=1, n_estimators=550, scale_pos_weight=0.7754445849317723, subsample=0.6752078123508874; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.8603861386489289, gamma=0.2779054352829708, lambda=0.9044219059317589, learning_rate=0.2912201311959635, max_depth=10, min_child_weight=1, n_estimators=550, scale_pos_weight=0.7754445849317723, subsample=0.6752078123508874; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.32414486466833353, gamma=0.4771217150249253, lambda=1.083647081529724, learning_rate=0.43495472855671624, max_depth=10, min_child_weight=3, n_estimators=300, scale_pos_weight=1.2613148260994467, subsample=0.9905597681522783; total time=   0.1s\n",
      "[CV] END alpha=20, colsample_bytree=0.32414486466833353, gamma=0.4771217150249253, lambda=1.083647081529724, learning_rate=0.43495472855671624, max_depth=10, min_child_weight=3, n_estimators=300, scale_pos_weight=1.2613148260994467, subsample=0.9905597681522783; total time=   0.1s\n",
      "[CV] END alpha=20, colsample_bytree=0.32414486466833353, gamma=0.4771217150249253, lambda=1.083647081529724, learning_rate=0.43495472855671624, max_depth=10, min_child_weight=3, n_estimators=300, scale_pos_weight=1.2613148260994467, subsample=0.9905597681522783; total time=   0.1s\n",
      "[CV] END alpha=20, colsample_bytree=0.32414486466833353, gamma=0.4771217150249253, lambda=1.083647081529724, learning_rate=0.43495472855671624, max_depth=10, min_child_weight=3, n_estimators=300, scale_pos_weight=1.2613148260994467, subsample=0.9905597681522783; total time=   0.1s\n",
      "[CV] END alpha=25, colsample_bytree=0.44776199524118504, gamma=0.2296953509161147, lambda=1.165170483183132, learning_rate=0.12236811337473112, max_depth=8, min_child_weight=1, n_estimators=400, scale_pos_weight=2.769111696430392, subsample=1.4036226504891296; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.44776199524118504, gamma=0.2296953509161147, lambda=1.165170483183132, learning_rate=0.12236811337473112, max_depth=8, min_child_weight=1, n_estimators=400, scale_pos_weight=2.769111696430392, subsample=1.4036226504891296; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.44776199524118504, gamma=0.2296953509161147, lambda=1.165170483183132, learning_rate=0.12236811337473112, max_depth=8, min_child_weight=1, n_estimators=400, scale_pos_weight=2.769111696430392, subsample=1.4036226504891296; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.44776199524118504, gamma=0.2296953509161147, lambda=1.165170483183132, learning_rate=0.12236811337473112, max_depth=8, min_child_weight=1, n_estimators=400, scale_pos_weight=2.769111696430392, subsample=1.4036226504891296; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5976311756683388, gamma=0.13525310289131903, lambda=0.6414802577481407, learning_rate=0.24522233636710122, max_depth=10, min_child_weight=1, n_estimators=300, scale_pos_weight=1.0917532756882298, subsample=1.280968661875593; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5976311756683388, gamma=0.13525310289131903, lambda=0.6414802577481407, learning_rate=0.24522233636710122, max_depth=10, min_child_weight=1, n_estimators=300, scale_pos_weight=1.0917532756882298, subsample=1.280968661875593; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5976311756683388, gamma=0.13525310289131903, lambda=0.6414802577481407, learning_rate=0.24522233636710122, max_depth=10, min_child_weight=1, n_estimators=300, scale_pos_weight=1.0917532756882298, subsample=1.280968661875593; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5976311756683388, gamma=0.13525310289131903, lambda=0.6414802577481407, learning_rate=0.24522233636710122, max_depth=10, min_child_weight=1, n_estimators=300, scale_pos_weight=1.0917532756882298, subsample=1.280968661875593; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9124099609374088, gamma=0.09469345704724397, lambda=0.13172928769388975, learning_rate=0.1351295881333759, max_depth=6, min_child_weight=3, n_estimators=250, scale_pos_weight=1.652344890107954, subsample=0.825966024296401; total time=   0.3s\n",
      "[CV] END alpha=15, colsample_bytree=0.9124099609374088, gamma=0.09469345704724397, lambda=0.13172928769388975, learning_rate=0.1351295881333759, max_depth=6, min_child_weight=3, n_estimators=250, scale_pos_weight=1.652344890107954, subsample=0.825966024296401; total time=   0.3s\n",
      "[CV] END alpha=15, colsample_bytree=0.9124099609374088, gamma=0.09469345704724397, lambda=0.13172928769388975, learning_rate=0.1351295881333759, max_depth=6, min_child_weight=3, n_estimators=250, scale_pos_weight=1.652344890107954, subsample=0.825966024296401; total time=   0.3s\n",
      "[CV] END alpha=15, colsample_bytree=0.9124099609374088, gamma=0.09469345704724397, lambda=0.13172928769388975, learning_rate=0.1351295881333759, max_depth=6, min_child_weight=3, n_estimators=250, scale_pos_weight=1.652344890107954, subsample=0.825966024296401; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.6784513565750212, gamma=0.2772623570122289, lambda=1.2083257016067472, learning_rate=0.1694503376517948, max_depth=10, min_child_weight=3, n_estimators=200, scale_pos_weight=0.8292029192679461, subsample=1.5150299808802385; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.6784513565750212, gamma=0.2772623570122289, lambda=1.2083257016067472, learning_rate=0.1694503376517948, max_depth=10, min_child_weight=3, n_estimators=200, scale_pos_weight=0.8292029192679461, subsample=1.5150299808802385; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.6784513565750212, gamma=0.2772623570122289, lambda=1.2083257016067472, learning_rate=0.1694503376517948, max_depth=10, min_child_weight=3, n_estimators=200, scale_pos_weight=0.8292029192679461, subsample=1.5150299808802385; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.6784513565750212, gamma=0.2772623570122289, lambda=1.2083257016067472, learning_rate=0.1694503376517948, max_depth=10, min_child_weight=3, n_estimators=200, scale_pos_weight=0.8292029192679461, subsample=1.5150299808802385; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.6943979797190039, gamma=0.46579210813838634, lambda=1.159176134304543, learning_rate=0.2765389128607253, max_depth=9, min_child_weight=1, n_estimators=450, scale_pos_weight=0.9761077641805705, subsample=1.4611329549751408; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.6943979797190039, gamma=0.46579210813838634, lambda=1.159176134304543, learning_rate=0.2765389128607253, max_depth=9, min_child_weight=1, n_estimators=450, scale_pos_weight=0.9761077641805705, subsample=1.4611329549751408; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.6943979797190039, gamma=0.46579210813838634, lambda=1.159176134304543, learning_rate=0.2765389128607253, max_depth=9, min_child_weight=1, n_estimators=450, scale_pos_weight=0.9761077641805705, subsample=1.4611329549751408; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.6943979797190039, gamma=0.46579210813838634, lambda=1.159176134304543, learning_rate=0.2765389128607253, max_depth=9, min_child_weight=1, n_estimators=450, scale_pos_weight=0.9761077641805705, subsample=1.4611329549751408; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.4737561747341054, gamma=0.33837475878476336, lambda=1.2828727600639236, learning_rate=0.04196594627279942, max_depth=5, min_child_weight=3, n_estimators=650, scale_pos_weight=0.9288260722481386, subsample=0.7721630529358384; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.4737561747341054, gamma=0.33837475878476336, lambda=1.2828727600639236, learning_rate=0.04196594627279942, max_depth=5, min_child_weight=3, n_estimators=650, scale_pos_weight=0.9288260722481386, subsample=0.7721630529358384; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.4737561747341054, gamma=0.33837475878476336, lambda=1.2828727600639236, learning_rate=0.04196594627279942, max_depth=5, min_child_weight=3, n_estimators=650, scale_pos_weight=0.9288260722481386, subsample=0.7721630529358384; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.4737561747341054, gamma=0.33837475878476336, lambda=1.2828727600639236, learning_rate=0.04196594627279942, max_depth=5, min_child_weight=3, n_estimators=650, scale_pos_weight=0.9288260722481386, subsample=0.7721630529358384; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=1.1015058950953216, gamma=0.21358491260624973, lambda=0.6052974831637539, learning_rate=0.0330756545949713, max_depth=6, min_child_weight=3, n_estimators=250, scale_pos_weight=2.334467433453415, subsample=1.1676048075557866; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1015058950953216, gamma=0.21358491260624973, lambda=0.6052974831637539, learning_rate=0.0330756545949713, max_depth=6, min_child_weight=3, n_estimators=250, scale_pos_weight=2.334467433453415, subsample=1.1676048075557866; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1015058950953216, gamma=0.21358491260624973, lambda=0.6052974831637539, learning_rate=0.0330756545949713, max_depth=6, min_child_weight=3, n_estimators=250, scale_pos_weight=2.334467433453415, subsample=1.1676048075557866; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1015058950953216, gamma=0.21358491260624973, lambda=0.6052974831637539, learning_rate=0.0330756545949713, max_depth=6, min_child_weight=3, n_estimators=250, scale_pos_weight=2.334467433453415, subsample=1.1676048075557866; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1917492286629134, gamma=0.2005960007667536, lambda=0.6879192988609732, learning_rate=0.23892191030842186, max_depth=8, min_child_weight=1, n_estimators=300, scale_pos_weight=2.4805168892655183, subsample=0.6952562960732076; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1917492286629134, gamma=0.2005960007667536, lambda=0.6879192988609732, learning_rate=0.23892191030842186, max_depth=8, min_child_weight=1, n_estimators=300, scale_pos_weight=2.4805168892655183, subsample=0.6952562960732076; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1917492286629134, gamma=0.2005960007667536, lambda=0.6879192988609732, learning_rate=0.23892191030842186, max_depth=8, min_child_weight=1, n_estimators=300, scale_pos_weight=2.4805168892655183, subsample=0.6952562960732076; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1917492286629134, gamma=0.2005960007667536, lambda=0.6879192988609732, learning_rate=0.23892191030842186, max_depth=8, min_child_weight=1, n_estimators=300, scale_pos_weight=2.4805168892655183, subsample=0.6952562960732076; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.42979588146713593, gamma=0.395060871769212, lambda=0.9621130018171152, learning_rate=0.2630003485699935, max_depth=9, min_child_weight=3, n_estimators=250, scale_pos_weight=1.2365657714653011, subsample=1.3996132770253036; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.42979588146713593, gamma=0.395060871769212, lambda=0.9621130018171152, learning_rate=0.2630003485699935, max_depth=9, min_child_weight=3, n_estimators=250, scale_pos_weight=1.2365657714653011, subsample=1.3996132770253036; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.42979588146713593, gamma=0.395060871769212, lambda=0.9621130018171152, learning_rate=0.2630003485699935, max_depth=9, min_child_weight=3, n_estimators=250, scale_pos_weight=1.2365657714653011, subsample=1.3996132770253036; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.42979588146713593, gamma=0.395060871769212, lambda=0.9621130018171152, learning_rate=0.2630003485699935, max_depth=9, min_child_weight=3, n_estimators=250, scale_pos_weight=1.2365657714653011, subsample=1.3996132770253036; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8858777830896394, gamma=0.47957160125028414, lambda=1.2339415635196438, learning_rate=0.35580961851003773, max_depth=9, min_child_weight=1, n_estimators=500, scale_pos_weight=1.929538910690865, subsample=1.4708110729010142; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8858777830896394, gamma=0.47957160125028414, lambda=1.2339415635196438, learning_rate=0.35580961851003773, max_depth=9, min_child_weight=1, n_estimators=500, scale_pos_weight=1.929538910690865, subsample=1.4708110729010142; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8858777830896394, gamma=0.47957160125028414, lambda=1.2339415635196438, learning_rate=0.35580961851003773, max_depth=9, min_child_weight=1, n_estimators=500, scale_pos_weight=1.929538910690865, subsample=1.4708110729010142; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8858777830896394, gamma=0.47957160125028414, lambda=1.2339415635196438, learning_rate=0.35580961851003773, max_depth=9, min_child_weight=1, n_estimators=500, scale_pos_weight=1.929538910690865, subsample=1.4708110729010142; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.5486186922297052, gamma=0.3373761523607733, lambda=0.7913090285228883, learning_rate=0.49488769523379983, max_depth=7, min_child_weight=1, n_estimators=450, scale_pos_weight=2.5953557880206617, subsample=0.7688057459789425; total time=   0.3s\n",
      "[CV] END alpha=5, colsample_bytree=0.5486186922297052, gamma=0.3373761523607733, lambda=0.7913090285228883, learning_rate=0.49488769523379983, max_depth=7, min_child_weight=1, n_estimators=450, scale_pos_weight=2.5953557880206617, subsample=0.7688057459789425; total time=   0.3s\n",
      "[CV] END alpha=5, colsample_bytree=0.5486186922297052, gamma=0.3373761523607733, lambda=0.7913090285228883, learning_rate=0.49488769523379983, max_depth=7, min_child_weight=1, n_estimators=450, scale_pos_weight=2.5953557880206617, subsample=0.7688057459789425; total time=   0.3s\n",
      "[CV] END alpha=5, colsample_bytree=0.5486186922297052, gamma=0.3373761523607733, lambda=0.7913090285228883, learning_rate=0.49488769523379983, max_depth=7, min_child_weight=1, n_estimators=450, scale_pos_weight=2.5953557880206617, subsample=0.7688057459789425; total time=   0.3s\n",
      "[CV] END alpha=5, colsample_bytree=0.7173789377245574, gamma=0.033489967207414706, lambda=1.0886881451452797, learning_rate=0.1161087991420857, max_depth=11, min_child_weight=3, n_estimators=600, scale_pos_weight=1.857862368965532, subsample=1.100231888213644; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.7173789377245574, gamma=0.033489967207414706, lambda=1.0886881451452797, learning_rate=0.1161087991420857, max_depth=11, min_child_weight=3, n_estimators=600, scale_pos_weight=1.857862368965532, subsample=1.100231888213644; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.7173789377245574, gamma=0.033489967207414706, lambda=1.0886881451452797, learning_rate=0.1161087991420857, max_depth=11, min_child_weight=3, n_estimators=600, scale_pos_weight=1.857862368965532, subsample=1.100231888213644; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.7173789377245574, gamma=0.033489967207414706, lambda=1.0886881451452797, learning_rate=0.1161087991420857, max_depth=11, min_child_weight=3, n_estimators=600, scale_pos_weight=1.857862368965532, subsample=1.100231888213644; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.5194596091773682, gamma=0.12427144992277595, lambda=0.8386956972188552, learning_rate=0.11152976230448867, max_depth=8, min_child_weight=3, n_estimators=700, scale_pos_weight=0.8524884721117487, subsample=1.3526272568098712; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.5194596091773682, gamma=0.12427144992277595, lambda=0.8386956972188552, learning_rate=0.11152976230448867, max_depth=8, min_child_weight=3, n_estimators=700, scale_pos_weight=0.8524884721117487, subsample=1.3526272568098712; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.5194596091773682, gamma=0.12427144992277595, lambda=0.8386956972188552, learning_rate=0.11152976230448867, max_depth=8, min_child_weight=3, n_estimators=700, scale_pos_weight=0.8524884721117487, subsample=1.3526272568098712; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.5194596091773682, gamma=0.12427144992277595, lambda=0.8386956972188552, learning_rate=0.11152976230448867, max_depth=8, min_child_weight=3, n_estimators=700, scale_pos_weight=0.8524884721117487, subsample=1.3526272568098712; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4599807745745211, gamma=0.2876448846585061, lambda=0.23663999226523202, learning_rate=0.32821522261163044, max_depth=6, min_child_weight=3, n_estimators=400, scale_pos_weight=1.4945424288612033, subsample=1.4470756727751586; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4599807745745211, gamma=0.2876448846585061, lambda=0.23663999226523202, learning_rate=0.32821522261163044, max_depth=6, min_child_weight=3, n_estimators=400, scale_pos_weight=1.4945424288612033, subsample=1.4470756727751586; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4599807745745211, gamma=0.2876448846585061, lambda=0.23663999226523202, learning_rate=0.32821522261163044, max_depth=6, min_child_weight=3, n_estimators=400, scale_pos_weight=1.4945424288612033, subsample=1.4470756727751586; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4599807745745211, gamma=0.2876448846585061, lambda=0.23663999226523202, learning_rate=0.32821522261163044, max_depth=6, min_child_weight=3, n_estimators=400, scale_pos_weight=1.4945424288612033, subsample=1.4470756727751586; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.8110176189904374, gamma=0.1420916233050315, lambda=1.410764547195897, learning_rate=0.45963597060349337, max_depth=10, min_child_weight=1, n_estimators=700, scale_pos_weight=1.9205150898853527, subsample=1.059935541061395; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.8110176189904374, gamma=0.1420916233050315, lambda=1.410764547195897, learning_rate=0.45963597060349337, max_depth=10, min_child_weight=1, n_estimators=700, scale_pos_weight=1.9205150898853527, subsample=1.059935541061395; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.8110176189904374, gamma=0.1420916233050315, lambda=1.410764547195897, learning_rate=0.45963597060349337, max_depth=10, min_child_weight=1, n_estimators=700, scale_pos_weight=1.9205150898853527, subsample=1.059935541061395; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.8110176189904374, gamma=0.1420916233050315, lambda=1.410764547195897, learning_rate=0.45963597060349337, max_depth=10, min_child_weight=1, n_estimators=700, scale_pos_weight=1.9205150898853527, subsample=1.059935541061395; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.0757121032412083, gamma=0.4546823547118015, lambda=0.7237267439291728, learning_rate=0.22325886189513844, max_depth=10, min_child_weight=1, n_estimators=250, scale_pos_weight=1.4785693506010502, subsample=0.6821018033664985; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.0757121032412083, gamma=0.4546823547118015, lambda=0.7237267439291728, learning_rate=0.22325886189513844, max_depth=10, min_child_weight=1, n_estimators=250, scale_pos_weight=1.4785693506010502, subsample=0.6821018033664985; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.0757121032412083, gamma=0.4546823547118015, lambda=0.7237267439291728, learning_rate=0.22325886189513844, max_depth=10, min_child_weight=1, n_estimators=250, scale_pos_weight=1.4785693506010502, subsample=0.6821018033664985; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.0757121032412083, gamma=0.4546823547118015, lambda=0.7237267439291728, learning_rate=0.22325886189513844, max_depth=10, min_child_weight=1, n_estimators=250, scale_pos_weight=1.4785693506010502, subsample=0.6821018033664985; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.9368337366183241, gamma=0.06480288139935692, lambda=0.2611519050149422, learning_rate=0.2529357010862871, max_depth=6, min_child_weight=1, n_estimators=250, scale_pos_weight=2.3795827076981055, subsample=1.151635224966878; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.9368337366183241, gamma=0.06480288139935692, lambda=0.2611519050149422, learning_rate=0.2529357010862871, max_depth=6, min_child_weight=1, n_estimators=250, scale_pos_weight=2.3795827076981055, subsample=1.151635224966878; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.9368337366183241, gamma=0.06480288139935692, lambda=0.2611519050149422, learning_rate=0.2529357010862871, max_depth=6, min_child_weight=1, n_estimators=250, scale_pos_weight=2.3795827076981055, subsample=1.151635224966878; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.9368337366183241, gamma=0.06480288139935692, lambda=0.2611519050149422, learning_rate=0.2529357010862871, max_depth=6, min_child_weight=1, n_estimators=250, scale_pos_weight=2.3795827076981055, subsample=1.151635224966878; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9126284846410675, gamma=0.34143164577484153, lambda=0.6055817312551943, learning_rate=0.10610186933277059, max_depth=11, min_child_weight=1, n_estimators=500, scale_pos_weight=1.301211010669206, subsample=1.5959047448119026; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9126284846410675, gamma=0.34143164577484153, lambda=0.6055817312551943, learning_rate=0.10610186933277059, max_depth=11, min_child_weight=1, n_estimators=500, scale_pos_weight=1.301211010669206, subsample=1.5959047448119026; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9126284846410675, gamma=0.34143164577484153, lambda=0.6055817312551943, learning_rate=0.10610186933277059, max_depth=11, min_child_weight=1, n_estimators=500, scale_pos_weight=1.301211010669206, subsample=1.5959047448119026; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9126284846410675, gamma=0.34143164577484153, lambda=0.6055817312551943, learning_rate=0.10610186933277059, max_depth=11, min_child_weight=1, n_estimators=500, scale_pos_weight=1.301211010669206, subsample=1.5959047448119026; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.4267966617692907, gamma=0.10532062586683605, lambda=0.24344558938242816, learning_rate=0.3538645206543868, max_depth=7, min_child_weight=1, n_estimators=250, scale_pos_weight=1.2629449332137082, subsample=1.596504082369065; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.4267966617692907, gamma=0.10532062586683605, lambda=0.24344558938242816, learning_rate=0.3538645206543868, max_depth=7, min_child_weight=1, n_estimators=250, scale_pos_weight=1.2629449332137082, subsample=1.596504082369065; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.4267966617692907, gamma=0.10532062586683605, lambda=0.24344558938242816, learning_rate=0.3538645206543868, max_depth=7, min_child_weight=1, n_estimators=250, scale_pos_weight=1.2629449332137082, subsample=1.596504082369065; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.4267966617692907, gamma=0.10532062586683605, lambda=0.24344558938242816, learning_rate=0.3538645206543868, max_depth=7, min_child_weight=1, n_estimators=250, scale_pos_weight=1.2629449332137082, subsample=1.596504082369065; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7941843140752138, gamma=0.4366355468460733, lambda=1.0702564738081242, learning_rate=0.22087996369406265, max_depth=9, min_child_weight=1, n_estimators=500, scale_pos_weight=1.6080686635236365, subsample=1.2100419273808025; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7941843140752138, gamma=0.4366355468460733, lambda=1.0702564738081242, learning_rate=0.22087996369406265, max_depth=9, min_child_weight=1, n_estimators=500, scale_pos_weight=1.6080686635236365, subsample=1.2100419273808025; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7941843140752138, gamma=0.4366355468460733, lambda=1.0702564738081242, learning_rate=0.22087996369406265, max_depth=9, min_child_weight=1, n_estimators=500, scale_pos_weight=1.6080686635236365, subsample=1.2100419273808025; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7941843140752138, gamma=0.4366355468460733, lambda=1.0702564738081242, learning_rate=0.22087996369406265, max_depth=9, min_child_weight=1, n_estimators=500, scale_pos_weight=1.6080686635236365, subsample=1.2100419273808025; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7361718381588176, gamma=0.3578134809111126, lambda=0.23416786856003913, learning_rate=0.42638040967064184, max_depth=11, min_child_weight=3, n_estimators=500, scale_pos_weight=1.0412716773343544, subsample=1.127139989265868; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7361718381588176, gamma=0.3578134809111126, lambda=0.23416786856003913, learning_rate=0.42638040967064184, max_depth=11, min_child_weight=3, n_estimators=500, scale_pos_weight=1.0412716773343544, subsample=1.127139989265868; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7361718381588176, gamma=0.3578134809111126, lambda=0.23416786856003913, learning_rate=0.42638040967064184, max_depth=11, min_child_weight=3, n_estimators=500, scale_pos_weight=1.0412716773343544, subsample=1.127139989265868; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7361718381588176, gamma=0.3578134809111126, lambda=0.23416786856003913, learning_rate=0.42638040967064184, max_depth=11, min_child_weight=3, n_estimators=500, scale_pos_weight=1.0412716773343544, subsample=1.127139989265868; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.962616080567485, gamma=0.23794774502447452, lambda=0.24863179972694943, learning_rate=0.4976973123559826, max_depth=8, min_child_weight=3, n_estimators=600, scale_pos_weight=0.9962455622763053, subsample=0.8969798058979622; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.962616080567485, gamma=0.23794774502447452, lambda=0.24863179972694943, learning_rate=0.4976973123559826, max_depth=8, min_child_weight=3, n_estimators=600, scale_pos_weight=0.9962455622763053, subsample=0.8969798058979622; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.962616080567485, gamma=0.23794774502447452, lambda=0.24863179972694943, learning_rate=0.4976973123559826, max_depth=8, min_child_weight=3, n_estimators=600, scale_pos_weight=0.9962455622763053, subsample=0.8969798058979622; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.962616080567485, gamma=0.23794774502447452, lambda=0.24863179972694943, learning_rate=0.4976973123559826, max_depth=8, min_child_weight=3, n_estimators=600, scale_pos_weight=0.9962455622763053, subsample=0.8969798058979622; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=1.1498885294830155, gamma=0.44678591173979854, lambda=1.0890255962454347, learning_rate=0.18695163945045545, max_depth=7, min_child_weight=3, n_estimators=250, scale_pos_weight=2.759243527944135, subsample=1.3428688774785438; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1498885294830155, gamma=0.44678591173979854, lambda=1.0890255962454347, learning_rate=0.18695163945045545, max_depth=7, min_child_weight=3, n_estimators=250, scale_pos_weight=2.759243527944135, subsample=1.3428688774785438; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1498885294830155, gamma=0.44678591173979854, lambda=1.0890255962454347, learning_rate=0.18695163945045545, max_depth=7, min_child_weight=3, n_estimators=250, scale_pos_weight=2.759243527944135, subsample=1.3428688774785438; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1498885294830155, gamma=0.44678591173979854, lambda=1.0890255962454347, learning_rate=0.18695163945045545, max_depth=7, min_child_weight=3, n_estimators=250, scale_pos_weight=2.759243527944135, subsample=1.3428688774785438; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.25706321668455717, gamma=0.06350420943145363, lambda=0.7511382809426439, learning_rate=0.26894168681631636, max_depth=11, min_child_weight=1, n_estimators=550, scale_pos_weight=2.4346064906591787, subsample=1.4504200931734819; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.25706321668455717, gamma=0.06350420943145363, lambda=0.7511382809426439, learning_rate=0.26894168681631636, max_depth=11, min_child_weight=1, n_estimators=550, scale_pos_weight=2.4346064906591787, subsample=1.4504200931734819; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.25706321668455717, gamma=0.06350420943145363, lambda=0.7511382809426439, learning_rate=0.26894168681631636, max_depth=11, min_child_weight=1, n_estimators=550, scale_pos_weight=2.4346064906591787, subsample=1.4504200931734819; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.25706321668455717, gamma=0.06350420943145363, lambda=0.7511382809426439, learning_rate=0.26894168681631636, max_depth=11, min_child_weight=1, n_estimators=550, scale_pos_weight=2.4346064906591787, subsample=1.4504200931734819; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0217812018336385, gamma=0.26918110143484464, lambda=0.22001132301682957, learning_rate=0.0895366200718594, max_depth=8, min_child_weight=1, n_estimators=750, scale_pos_weight=1.4447418721839238, subsample=1.3841910380031706; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0217812018336385, gamma=0.26918110143484464, lambda=0.22001132301682957, learning_rate=0.0895366200718594, max_depth=8, min_child_weight=1, n_estimators=750, scale_pos_weight=1.4447418721839238, subsample=1.3841910380031706; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0217812018336385, gamma=0.26918110143484464, lambda=0.22001132301682957, learning_rate=0.0895366200718594, max_depth=8, min_child_weight=1, n_estimators=750, scale_pos_weight=1.4447418721839238, subsample=1.3841910380031706; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0217812018336385, gamma=0.26918110143484464, lambda=0.22001132301682957, learning_rate=0.0895366200718594, max_depth=8, min_child_weight=1, n_estimators=750, scale_pos_weight=1.4447418721839238, subsample=1.3841910380031706; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.7470443463862977, gamma=0.18375101799750326, lambda=0.6694111086507538, learning_rate=0.2753571403838432, max_depth=9, min_child_weight=1, n_estimators=550, scale_pos_weight=1.634012136441553, subsample=0.7836977390908633; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.7470443463862977, gamma=0.18375101799750326, lambda=0.6694111086507538, learning_rate=0.2753571403838432, max_depth=9, min_child_weight=1, n_estimators=550, scale_pos_weight=1.634012136441553, subsample=0.7836977390908633; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.7470443463862977, gamma=0.18375101799750326, lambda=0.6694111086507538, learning_rate=0.2753571403838432, max_depth=9, min_child_weight=1, n_estimators=550, scale_pos_weight=1.634012136441553, subsample=0.7836977390908633; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.7470443463862977, gamma=0.18375101799750326, lambda=0.6694111086507538, learning_rate=0.2753571403838432, max_depth=9, min_child_weight=1, n_estimators=550, scale_pos_weight=1.634012136441553, subsample=0.7836977390908633; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.6730716044910976, gamma=0.18413099023763607, lambda=1.446606024142922, learning_rate=0.2671814676784654, max_depth=9, min_child_weight=3, n_estimators=300, scale_pos_weight=2.4283144025007344, subsample=1.4482026899376192; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.6730716044910976, gamma=0.18413099023763607, lambda=1.446606024142922, learning_rate=0.2671814676784654, max_depth=9, min_child_weight=3, n_estimators=300, scale_pos_weight=2.4283144025007344, subsample=1.4482026899376192; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.6730716044910976, gamma=0.18413099023763607, lambda=1.446606024142922, learning_rate=0.2671814676784654, max_depth=9, min_child_weight=3, n_estimators=300, scale_pos_weight=2.4283144025007344, subsample=1.4482026899376192; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.6730716044910976, gamma=0.18413099023763607, lambda=1.446606024142922, learning_rate=0.2671814676784654, max_depth=9, min_child_weight=3, n_estimators=300, scale_pos_weight=2.4283144025007344, subsample=1.4482026899376192; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.4780312820332156, gamma=0.10524498509664809, lambda=1.3298589008021604, learning_rate=0.40089725148065614, max_depth=6, min_child_weight=1, n_estimators=650, scale_pos_weight=2.7104600423515013, subsample=1.592014758179578; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.4780312820332156, gamma=0.10524498509664809, lambda=1.3298589008021604, learning_rate=0.40089725148065614, max_depth=6, min_child_weight=1, n_estimators=650, scale_pos_weight=2.7104600423515013, subsample=1.592014758179578; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.4780312820332156, gamma=0.10524498509664809, lambda=1.3298589008021604, learning_rate=0.40089725148065614, max_depth=6, min_child_weight=1, n_estimators=650, scale_pos_weight=2.7104600423515013, subsample=1.592014758179578; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.4780312820332156, gamma=0.10524498509664809, lambda=1.3298589008021604, learning_rate=0.40089725148065614, max_depth=6, min_child_weight=1, n_estimators=650, scale_pos_weight=2.7104600423515013, subsample=1.592014758179578; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5447556651924577, gamma=0.28102734086028247, lambda=0.5650453385680166, learning_rate=0.2380000496954876, max_depth=9, min_child_weight=1, n_estimators=350, scale_pos_weight=2.2189878759465858, subsample=0.9771859752415399; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.5447556651924577, gamma=0.28102734086028247, lambda=0.5650453385680166, learning_rate=0.2380000496954876, max_depth=9, min_child_weight=1, n_estimators=350, scale_pos_weight=2.2189878759465858, subsample=0.9771859752415399; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.5447556651924577, gamma=0.28102734086028247, lambda=0.5650453385680166, learning_rate=0.2380000496954876, max_depth=9, min_child_weight=1, n_estimators=350, scale_pos_weight=2.2189878759465858, subsample=0.9771859752415399; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.5447556651924577, gamma=0.28102734086028247, lambda=0.5650453385680166, learning_rate=0.2380000496954876, max_depth=9, min_child_weight=1, n_estimators=350, scale_pos_weight=2.2189878759465858, subsample=0.9771859752415399; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=0.4572457129230986, gamma=0.09753146478602054, lambda=1.3186873523533935, learning_rate=0.15027910707512993, max_depth=8, min_child_weight=1, n_estimators=350, scale_pos_weight=2.2341227698009796, subsample=1.354525877847832; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4572457129230986, gamma=0.09753146478602054, lambda=1.3186873523533935, learning_rate=0.15027910707512993, max_depth=8, min_child_weight=1, n_estimators=350, scale_pos_weight=2.2341227698009796, subsample=1.354525877847832; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4572457129230986, gamma=0.09753146478602054, lambda=1.3186873523533935, learning_rate=0.15027910707512993, max_depth=8, min_child_weight=1, n_estimators=350, scale_pos_weight=2.2341227698009796, subsample=1.354525877847832; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4572457129230986, gamma=0.09753146478602054, lambda=1.3186873523533935, learning_rate=0.15027910707512993, max_depth=8, min_child_weight=1, n_estimators=350, scale_pos_weight=2.2341227698009796, subsample=1.354525877847832; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0097547242955467, gamma=0.31600034084801837, lambda=0.8673706212354823, learning_rate=0.09917066680164775, max_depth=8, min_child_weight=3, n_estimators=700, scale_pos_weight=1.016021848791401, subsample=0.6582892796825196; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0097547242955467, gamma=0.31600034084801837, lambda=0.8673706212354823, learning_rate=0.09917066680164775, max_depth=8, min_child_weight=3, n_estimators=700, scale_pos_weight=1.016021848791401, subsample=0.6582892796825196; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0097547242955467, gamma=0.31600034084801837, lambda=0.8673706212354823, learning_rate=0.09917066680164775, max_depth=8, min_child_weight=3, n_estimators=700, scale_pos_weight=1.016021848791401, subsample=0.6582892796825196; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0097547242955467, gamma=0.31600034084801837, lambda=0.8673706212354823, learning_rate=0.09917066680164775, max_depth=8, min_child_weight=3, n_estimators=700, scale_pos_weight=1.016021848791401, subsample=0.6582892796825196; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8709428576355207, gamma=0.04342639309443019, lambda=0.3947353677002403, learning_rate=0.34542971106162496, max_depth=9, min_child_weight=3, n_estimators=400, scale_pos_weight=2.4305065750388, subsample=1.5932477105832978; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8709428576355207, gamma=0.04342639309443019, lambda=0.3947353677002403, learning_rate=0.34542971106162496, max_depth=9, min_child_weight=3, n_estimators=400, scale_pos_weight=2.4305065750388, subsample=1.5932477105832978; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8709428576355207, gamma=0.04342639309443019, lambda=0.3947353677002403, learning_rate=0.34542971106162496, max_depth=9, min_child_weight=3, n_estimators=400, scale_pos_weight=2.4305065750388, subsample=1.5932477105832978; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8709428576355207, gamma=0.04342639309443019, lambda=0.3947353677002403, learning_rate=0.34542971106162496, max_depth=9, min_child_weight=3, n_estimators=400, scale_pos_weight=2.4305065750388, subsample=1.5932477105832978; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.32697886477840393, gamma=0.41905992571625245, lambda=0.9760371862806201, learning_rate=0.4273751085460776, max_depth=5, min_child_weight=1, n_estimators=350, scale_pos_weight=1.6229581982981591, subsample=1.3837112187401444; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.32697886477840393, gamma=0.41905992571625245, lambda=0.9760371862806201, learning_rate=0.4273751085460776, max_depth=5, min_child_weight=1, n_estimators=350, scale_pos_weight=1.6229581982981591, subsample=1.3837112187401444; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.32697886477840393, gamma=0.41905992571625245, lambda=0.9760371862806201, learning_rate=0.4273751085460776, max_depth=5, min_child_weight=1, n_estimators=350, scale_pos_weight=1.6229581982981591, subsample=1.3837112187401444; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.32697886477840393, gamma=0.41905992571625245, lambda=0.9760371862806201, learning_rate=0.4273751085460776, max_depth=5, min_child_weight=1, n_estimators=350, scale_pos_weight=1.6229581982981591, subsample=1.3837112187401444; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.2856383635573037, gamma=0.4239962075977897, lambda=0.7475434009329265, learning_rate=0.14060926375071037, max_depth=9, min_child_weight=3, n_estimators=300, scale_pos_weight=2.197526668809922, subsample=0.8078440229425157; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.2856383635573037, gamma=0.4239962075977897, lambda=0.7475434009329265, learning_rate=0.14060926375071037, max_depth=9, min_child_weight=3, n_estimators=300, scale_pos_weight=2.197526668809922, subsample=0.8078440229425157; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.2856383635573037, gamma=0.4239962075977897, lambda=0.7475434009329265, learning_rate=0.14060926375071037, max_depth=9, min_child_weight=3, n_estimators=300, scale_pos_weight=2.197526668809922, subsample=0.8078440229425157; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.2856383635573037, gamma=0.4239962075977897, lambda=0.7475434009329265, learning_rate=0.14060926375071037, max_depth=9, min_child_weight=3, n_estimators=300, scale_pos_weight=2.197526668809922, subsample=0.8078440229425157; total time=   1.1s\n",
      "[CV] END alpha=15, colsample_bytree=0.75435460149106, gamma=0.38300572565740904, lambda=1.499581126254074, learning_rate=0.3216313590206975, max_depth=7, min_child_weight=1, n_estimators=450, scale_pos_weight=1.3529694670575978, subsample=1.2912433260291643; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.75435460149106, gamma=0.38300572565740904, lambda=1.499581126254074, learning_rate=0.3216313590206975, max_depth=7, min_child_weight=1, n_estimators=450, scale_pos_weight=1.3529694670575978, subsample=1.2912433260291643; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.75435460149106, gamma=0.38300572565740904, lambda=1.499581126254074, learning_rate=0.3216313590206975, max_depth=7, min_child_weight=1, n_estimators=450, scale_pos_weight=1.3529694670575978, subsample=1.2912433260291643; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.75435460149106, gamma=0.38300572565740904, lambda=1.499581126254074, learning_rate=0.3216313590206975, max_depth=7, min_child_weight=1, n_estimators=450, scale_pos_weight=1.3529694670575978, subsample=1.2912433260291643; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.5149611439804587, gamma=0.01624401839059897, lambda=0.5795743987481456, learning_rate=0.019209433717722595, max_depth=9, min_child_weight=3, n_estimators=450, scale_pos_weight=1.311820970132818, subsample=1.4869389361547354; total time=   0.1s\n",
      "[CV] END alpha=5, colsample_bytree=0.5149611439804587, gamma=0.01624401839059897, lambda=0.5795743987481456, learning_rate=0.019209433717722595, max_depth=9, min_child_weight=3, n_estimators=450, scale_pos_weight=1.311820970132818, subsample=1.4869389361547354; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.5149611439804587, gamma=0.01624401839059897, lambda=0.5795743987481456, learning_rate=0.019209433717722595, max_depth=9, min_child_weight=3, n_estimators=450, scale_pos_weight=1.311820970132818, subsample=1.4869389361547354; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.5149611439804587, gamma=0.01624401839059897, lambda=0.5795743987481456, learning_rate=0.019209433717722595, max_depth=9, min_child_weight=3, n_estimators=450, scale_pos_weight=1.311820970132818, subsample=1.4869389361547354; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0949186890728941, gamma=0.15426902982570628, lambda=1.4089255427487113, learning_rate=0.48002592435435487, max_depth=6, min_child_weight=1, n_estimators=650, scale_pos_weight=0.7353933050381988, subsample=0.9998375109621188; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0949186890728941, gamma=0.15426902982570628, lambda=1.4089255427487113, learning_rate=0.48002592435435487, max_depth=6, min_child_weight=1, n_estimators=650, scale_pos_weight=0.7353933050381988, subsample=0.9998375109621188; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0949186890728941, gamma=0.15426902982570628, lambda=1.4089255427487113, learning_rate=0.48002592435435487, max_depth=6, min_child_weight=1, n_estimators=650, scale_pos_weight=0.7353933050381988, subsample=0.9998375109621188; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0949186890728941, gamma=0.15426902982570628, lambda=1.4089255427487113, learning_rate=0.48002592435435487, max_depth=6, min_child_weight=1, n_estimators=650, scale_pos_weight=0.7353933050381988, subsample=0.9998375109621188; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1966902736741671, gamma=0.19691282884497885, lambda=0.5499955396399763, learning_rate=0.21212257001410234, max_depth=9, min_child_weight=3, n_estimators=700, scale_pos_weight=1.0636716884026516, subsample=1.1498866331239843; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1966902736741671, gamma=0.19691282884497885, lambda=0.5499955396399763, learning_rate=0.21212257001410234, max_depth=9, min_child_weight=3, n_estimators=700, scale_pos_weight=1.0636716884026516, subsample=1.1498866331239843; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1966902736741671, gamma=0.19691282884497885, lambda=0.5499955396399763, learning_rate=0.21212257001410234, max_depth=9, min_child_weight=3, n_estimators=700, scale_pos_weight=1.0636716884026516, subsample=1.1498866331239843; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1966902736741671, gamma=0.19691282884497885, lambda=0.5499955396399763, learning_rate=0.21212257001410234, max_depth=9, min_child_weight=3, n_estimators=700, scale_pos_weight=1.0636716884026516, subsample=1.1498866331239843; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1025195649875907, gamma=0.2481706105593135, lambda=0.31833269612175213, learning_rate=0.19774303840327173, max_depth=7, min_child_weight=1, n_estimators=350, scale_pos_weight=2.691574002920525, subsample=1.0739022075706643; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1025195649875907, gamma=0.2481706105593135, lambda=0.31833269612175213, learning_rate=0.19774303840327173, max_depth=7, min_child_weight=1, n_estimators=350, scale_pos_weight=2.691574002920525, subsample=1.0739022075706643; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1025195649875907, gamma=0.2481706105593135, lambda=0.31833269612175213, learning_rate=0.19774303840327173, max_depth=7, min_child_weight=1, n_estimators=350, scale_pos_weight=2.691574002920525, subsample=1.0739022075706643; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1025195649875907, gamma=0.2481706105593135, lambda=0.31833269612175213, learning_rate=0.19774303840327173, max_depth=7, min_child_weight=1, n_estimators=350, scale_pos_weight=2.691574002920525, subsample=1.0739022075706643; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.6370092235926395, gamma=0.21778601882094967, lambda=1.1152882763524579, learning_rate=0.267136379709828, max_depth=7, min_child_weight=3, n_estimators=300, scale_pos_weight=1.1778787511856983, subsample=1.0914820064460993; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.6370092235926395, gamma=0.21778601882094967, lambda=1.1152882763524579, learning_rate=0.267136379709828, max_depth=7, min_child_weight=3, n_estimators=300, scale_pos_weight=1.1778787511856983, subsample=1.0914820064460993; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.6370092235926395, gamma=0.21778601882094967, lambda=1.1152882763524579, learning_rate=0.267136379709828, max_depth=7, min_child_weight=3, n_estimators=300, scale_pos_weight=1.1778787511856983, subsample=1.0914820064460993; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.6370092235926395, gamma=0.21778601882094967, lambda=1.1152882763524579, learning_rate=0.267136379709828, max_depth=7, min_child_weight=3, n_estimators=300, scale_pos_weight=1.1778787511856983, subsample=1.0914820064460993; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0682813590795504, gamma=0.27633424557704367, lambda=0.4089486887514595, learning_rate=0.3991591316368377, max_depth=6, min_child_weight=1, n_estimators=700, scale_pos_weight=0.9006247261184785, subsample=1.1246452643205997; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0682813590795504, gamma=0.27633424557704367, lambda=0.4089486887514595, learning_rate=0.3991591316368377, max_depth=6, min_child_weight=1, n_estimators=700, scale_pos_weight=0.9006247261184785, subsample=1.1246452643205997; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0682813590795504, gamma=0.27633424557704367, lambda=0.4089486887514595, learning_rate=0.3991591316368377, max_depth=6, min_child_weight=1, n_estimators=700, scale_pos_weight=0.9006247261184785, subsample=1.1246452643205997; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0682813590795504, gamma=0.27633424557704367, lambda=0.4089486887514595, learning_rate=0.3991591316368377, max_depth=6, min_child_weight=1, n_estimators=700, scale_pos_weight=0.9006247261184785, subsample=1.1246452643205997; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.9518048800687255, gamma=0.153446524554965, lambda=0.5060375220659985, learning_rate=0.2838065581910521, max_depth=10, min_child_weight=3, n_estimators=400, scale_pos_weight=1.3182449636000961, subsample=0.9019274292859983; total time=   0.4s\n",
      "[CV] END alpha=5, colsample_bytree=0.9518048800687255, gamma=0.153446524554965, lambda=0.5060375220659985, learning_rate=0.2838065581910521, max_depth=10, min_child_weight=3, n_estimators=400, scale_pos_weight=1.3182449636000961, subsample=0.9019274292859983; total time=   0.4s\n",
      "[CV] END alpha=5, colsample_bytree=0.9518048800687255, gamma=0.153446524554965, lambda=0.5060375220659985, learning_rate=0.2838065581910521, max_depth=10, min_child_weight=3, n_estimators=400, scale_pos_weight=1.3182449636000961, subsample=0.9019274292859983; total time=   0.4s\n",
      "[CV] END alpha=5, colsample_bytree=0.9518048800687255, gamma=0.153446524554965, lambda=0.5060375220659985, learning_rate=0.2838065581910521, max_depth=10, min_child_weight=3, n_estimators=400, scale_pos_weight=1.3182449636000961, subsample=0.9019274292859983; total time=   0.4s\n",
      "[CV] END alpha=25, colsample_bytree=0.42339949961044093, gamma=0.3502157744985184, lambda=1.3892192043789435, learning_rate=0.21334185050725613, max_depth=5, min_child_weight=3, n_estimators=300, scale_pos_weight=1.1748967483973323, subsample=0.8808607881029907; total time=   0.1s\n",
      "[CV] END alpha=25, colsample_bytree=0.42339949961044093, gamma=0.3502157744985184, lambda=1.3892192043789435, learning_rate=0.21334185050725613, max_depth=5, min_child_weight=3, n_estimators=300, scale_pos_weight=1.1748967483973323, subsample=0.8808607881029907; total time=   0.1s\n",
      "[CV] END alpha=25, colsample_bytree=0.42339949961044093, gamma=0.3502157744985184, lambda=1.3892192043789435, learning_rate=0.21334185050725613, max_depth=5, min_child_weight=3, n_estimators=300, scale_pos_weight=1.1748967483973323, subsample=0.8808607881029907; total time=   0.1s\n",
      "[CV] END alpha=25, colsample_bytree=0.42339949961044093, gamma=0.3502157744985184, lambda=1.3892192043789435, learning_rate=0.21334185050725613, max_depth=5, min_child_weight=3, n_estimators=300, scale_pos_weight=1.1748967483973323, subsample=0.8808607881029907; total time=   0.1s\n",
      "[CV] END alpha=10, colsample_bytree=0.20700329161265923, gamma=0.3236585839216486, lambda=0.6507054773979939, learning_rate=0.4700514303869255, max_depth=8, min_child_weight=1, n_estimators=400, scale_pos_weight=1.63052722914638, subsample=1.127915955631999; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.20700329161265923, gamma=0.3236585839216486, lambda=0.6507054773979939, learning_rate=0.4700514303869255, max_depth=8, min_child_weight=1, n_estimators=400, scale_pos_weight=1.63052722914638, subsample=1.127915955631999; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.20700329161265923, gamma=0.3236585839216486, lambda=0.6507054773979939, learning_rate=0.4700514303869255, max_depth=8, min_child_weight=1, n_estimators=400, scale_pos_weight=1.63052722914638, subsample=1.127915955631999; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.20700329161265923, gamma=0.3236585839216486, lambda=0.6507054773979939, learning_rate=0.4700514303869255, max_depth=8, min_child_weight=1, n_estimators=400, scale_pos_weight=1.63052722914638, subsample=1.127915955631999; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1931890113307357, gamma=0.1560826676023993, lambda=0.9144497132230763, learning_rate=0.08287696302824003, max_depth=5, min_child_weight=1, n_estimators=650, scale_pos_weight=2.157971260812461, subsample=1.4301001097521828; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1931890113307357, gamma=0.1560826676023993, lambda=0.9144497132230763, learning_rate=0.08287696302824003, max_depth=5, min_child_weight=1, n_estimators=650, scale_pos_weight=2.157971260812461, subsample=1.4301001097521828; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1931890113307357, gamma=0.1560826676023993, lambda=0.9144497132230763, learning_rate=0.08287696302824003, max_depth=5, min_child_weight=1, n_estimators=650, scale_pos_weight=2.157971260812461, subsample=1.4301001097521828; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1931890113307357, gamma=0.1560826676023993, lambda=0.9144497132230763, learning_rate=0.08287696302824003, max_depth=5, min_child_weight=1, n_estimators=650, scale_pos_weight=2.157971260812461, subsample=1.4301001097521828; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.2923547334184456, gamma=0.4833105404176803, lambda=0.13681769002223848, learning_rate=0.2448624367374796, max_depth=6, min_child_weight=1, n_estimators=350, scale_pos_weight=1.374474134608509, subsample=1.3823901640157716; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.2923547334184456, gamma=0.4833105404176803, lambda=0.13681769002223848, learning_rate=0.2448624367374796, max_depth=6, min_child_weight=1, n_estimators=350, scale_pos_weight=1.374474134608509, subsample=1.3823901640157716; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.2923547334184456, gamma=0.4833105404176803, lambda=0.13681769002223848, learning_rate=0.2448624367374796, max_depth=6, min_child_weight=1, n_estimators=350, scale_pos_weight=1.374474134608509, subsample=1.3823901640157716; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.2923547334184456, gamma=0.4833105404176803, lambda=0.13681769002223848, learning_rate=0.2448624367374796, max_depth=6, min_child_weight=1, n_estimators=350, scale_pos_weight=1.374474134608509, subsample=1.3823901640157716; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1989962748712042, gamma=0.29129717901441593, lambda=0.7972797635523179, learning_rate=0.23988833656788433, max_depth=9, min_child_weight=1, n_estimators=250, scale_pos_weight=2.4785167212947914, subsample=0.7173843804041139; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1989962748712042, gamma=0.29129717901441593, lambda=0.7972797635523179, learning_rate=0.23988833656788433, max_depth=9, min_child_weight=1, n_estimators=250, scale_pos_weight=2.4785167212947914, subsample=0.7173843804041139; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1989962748712042, gamma=0.29129717901441593, lambda=0.7972797635523179, learning_rate=0.23988833656788433, max_depth=9, min_child_weight=1, n_estimators=250, scale_pos_weight=2.4785167212947914, subsample=0.7173843804041139; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1989962748712042, gamma=0.29129717901441593, lambda=0.7972797635523179, learning_rate=0.23988833656788433, max_depth=9, min_child_weight=1, n_estimators=250, scale_pos_weight=2.4785167212947914, subsample=0.7173843804041139; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.6811303585531785, gamma=0.19900729491777203, lambda=0.8264791416171556, learning_rate=0.32331022033318685, max_depth=6, min_child_weight=3, n_estimators=600, scale_pos_weight=1.716039615702866, subsample=1.3193062723170106; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.6811303585531785, gamma=0.19900729491777203, lambda=0.8264791416171556, learning_rate=0.32331022033318685, max_depth=6, min_child_weight=3, n_estimators=600, scale_pos_weight=1.716039615702866, subsample=1.3193062723170106; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.6811303585531785, gamma=0.19900729491777203, lambda=0.8264791416171556, learning_rate=0.32331022033318685, max_depth=6, min_child_weight=3, n_estimators=600, scale_pos_weight=1.716039615702866, subsample=1.3193062723170106; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.6811303585531785, gamma=0.19900729491777203, lambda=0.8264791416171556, learning_rate=0.32331022033318685, max_depth=6, min_child_weight=3, n_estimators=600, scale_pos_weight=1.716039615702866, subsample=1.3193062723170106; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7291325720093533, gamma=0.4934566970586351, lambda=0.008201965545786394, learning_rate=0.17389147992050713, max_depth=5, min_child_weight=1, n_estimators=750, scale_pos_weight=1.784857396045721, subsample=1.524894763947343; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7291325720093533, gamma=0.4934566970586351, lambda=0.008201965545786394, learning_rate=0.17389147992050713, max_depth=5, min_child_weight=1, n_estimators=750, scale_pos_weight=1.784857396045721, subsample=1.524894763947343; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7291325720093533, gamma=0.4934566970586351, lambda=0.008201965545786394, learning_rate=0.17389147992050713, max_depth=5, min_child_weight=1, n_estimators=750, scale_pos_weight=1.784857396045721, subsample=1.524894763947343; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7291325720093533, gamma=0.4934566970586351, lambda=0.008201965545786394, learning_rate=0.17389147992050713, max_depth=5, min_child_weight=1, n_estimators=750, scale_pos_weight=1.784857396045721, subsample=1.524894763947343; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5908791457672888, gamma=0.14504747207916918, lambda=1.172824990055787, learning_rate=0.21728914462502635, max_depth=10, min_child_weight=3, n_estimators=350, scale_pos_weight=1.1429256856640926, subsample=1.0465093869140683; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5908791457672888, gamma=0.14504747207916918, lambda=1.172824990055787, learning_rate=0.21728914462502635, max_depth=10, min_child_weight=3, n_estimators=350, scale_pos_weight=1.1429256856640926, subsample=1.0465093869140683; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5908791457672888, gamma=0.14504747207916918, lambda=1.172824990055787, learning_rate=0.21728914462502635, max_depth=10, min_child_weight=3, n_estimators=350, scale_pos_weight=1.1429256856640926, subsample=1.0465093869140683; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5908791457672888, gamma=0.14504747207916918, lambda=1.172824990055787, learning_rate=0.21728914462502635, max_depth=10, min_child_weight=3, n_estimators=350, scale_pos_weight=1.1429256856640926, subsample=1.0465093869140683; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.8524194793323681, gamma=0.11203780198080765, lambda=1.0825036786067208, learning_rate=0.20051524566304285, max_depth=9, min_child_weight=1, n_estimators=750, scale_pos_weight=2.616121349536579, subsample=1.2952184419245163; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.8524194793323681, gamma=0.11203780198080765, lambda=1.0825036786067208, learning_rate=0.20051524566304285, max_depth=9, min_child_weight=1, n_estimators=750, scale_pos_weight=2.616121349536579, subsample=1.2952184419245163; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.8524194793323681, gamma=0.11203780198080765, lambda=1.0825036786067208, learning_rate=0.20051524566304285, max_depth=9, min_child_weight=1, n_estimators=750, scale_pos_weight=2.616121349536579, subsample=1.2952184419245163; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.8524194793323681, gamma=0.11203780198080765, lambda=1.0825036786067208, learning_rate=0.20051524566304285, max_depth=9, min_child_weight=1, n_estimators=750, scale_pos_weight=2.616121349536579, subsample=1.2952184419245163; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5775815314349904, gamma=0.09770264938311435, lambda=0.7998082812288032, learning_rate=0.1371215851900524, max_depth=6, min_child_weight=1, n_estimators=250, scale_pos_weight=2.3913508658231564, subsample=1.0321432952732716; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5775815314349904, gamma=0.09770264938311435, lambda=0.7998082812288032, learning_rate=0.1371215851900524, max_depth=6, min_child_weight=1, n_estimators=250, scale_pos_weight=2.3913508658231564, subsample=1.0321432952732716; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5775815314349904, gamma=0.09770264938311435, lambda=0.7998082812288032, learning_rate=0.1371215851900524, max_depth=6, min_child_weight=1, n_estimators=250, scale_pos_weight=2.3913508658231564, subsample=1.0321432952732716; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5775815314349904, gamma=0.09770264938311435, lambda=0.7998082812288032, learning_rate=0.1371215851900524, max_depth=6, min_child_weight=1, n_estimators=250, scale_pos_weight=2.3913508658231564, subsample=1.0321432952732716; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5896390383192409, gamma=0.4222195453231403, lambda=1.2722274488532856, learning_rate=0.46158862789648203, max_depth=11, min_child_weight=3, n_estimators=550, scale_pos_weight=2.2446138377821887, subsample=0.6974138447335018; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.5896390383192409, gamma=0.4222195453231403, lambda=1.2722274488532856, learning_rate=0.46158862789648203, max_depth=11, min_child_weight=3, n_estimators=550, scale_pos_weight=2.2446138377821887, subsample=0.6974138447335018; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.5896390383192409, gamma=0.4222195453231403, lambda=1.2722274488532856, learning_rate=0.46158862789648203, max_depth=11, min_child_weight=3, n_estimators=550, scale_pos_weight=2.2446138377821887, subsample=0.6974138447335018; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.5896390383192409, gamma=0.4222195453231403, lambda=1.2722274488532856, learning_rate=0.46158862789648203, max_depth=11, min_child_weight=3, n_estimators=550, scale_pos_weight=2.2446138377821887, subsample=0.6974138447335018; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.31613876301274196, gamma=0.19907406002178218, lambda=0.8836780006635714, learning_rate=0.2552409302623095, max_depth=5, min_child_weight=3, n_estimators=700, scale_pos_weight=1.660613767132114, subsample=0.7686232865296271; total time=   0.4s\n",
      "[CV] END alpha=10, colsample_bytree=0.31613876301274196, gamma=0.19907406002178218, lambda=0.8836780006635714, learning_rate=0.2552409302623095, max_depth=5, min_child_weight=3, n_estimators=700, scale_pos_weight=1.660613767132114, subsample=0.7686232865296271; total time=   0.4s\n",
      "[CV] END alpha=10, colsample_bytree=0.31613876301274196, gamma=0.19907406002178218, lambda=0.8836780006635714, learning_rate=0.2552409302623095, max_depth=5, min_child_weight=3, n_estimators=700, scale_pos_weight=1.660613767132114, subsample=0.7686232865296271; total time=   0.4s\n",
      "[CV] END alpha=10, colsample_bytree=0.31613876301274196, gamma=0.19907406002178218, lambda=0.8836780006635714, learning_rate=0.2552409302623095, max_depth=5, min_child_weight=3, n_estimators=700, scale_pos_weight=1.660613767132114, subsample=0.7686232865296271; total time=   0.4s\n",
      "[CV] END alpha=25, colsample_bytree=1.122085003331687, gamma=0.21591772783524238, lambda=0.9032915671593962, learning_rate=0.4797471843076336, max_depth=10, min_child_weight=3, n_estimators=700, scale_pos_weight=1.3633660301333177, subsample=1.5253977821205633; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.122085003331687, gamma=0.21591772783524238, lambda=0.9032915671593962, learning_rate=0.4797471843076336, max_depth=10, min_child_weight=3, n_estimators=700, scale_pos_weight=1.3633660301333177, subsample=1.5253977821205633; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.122085003331687, gamma=0.21591772783524238, lambda=0.9032915671593962, learning_rate=0.4797471843076336, max_depth=10, min_child_weight=3, n_estimators=700, scale_pos_weight=1.3633660301333177, subsample=1.5253977821205633; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.122085003331687, gamma=0.21591772783524238, lambda=0.9032915671593962, learning_rate=0.4797471843076336, max_depth=10, min_child_weight=3, n_estimators=700, scale_pos_weight=1.3633660301333177, subsample=1.5253977821205633; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.6690222967751902, gamma=0.1236417446208457, lambda=1.0914161139324352, learning_rate=0.42653312886686945, max_depth=5, min_child_weight=3, n_estimators=750, scale_pos_weight=2.3609163048840696, subsample=0.8680056330593456; total time=   0.4s\n",
      "[CV] END alpha=15, colsample_bytree=0.6690222967751902, gamma=0.1236417446208457, lambda=1.0914161139324352, learning_rate=0.42653312886686945, max_depth=5, min_child_weight=3, n_estimators=750, scale_pos_weight=2.3609163048840696, subsample=0.8680056330593456; total time=   0.4s\n",
      "[CV] END alpha=15, colsample_bytree=0.6690222967751902, gamma=0.1236417446208457, lambda=1.0914161139324352, learning_rate=0.42653312886686945, max_depth=5, min_child_weight=3, n_estimators=750, scale_pos_weight=2.3609163048840696, subsample=0.8680056330593456; total time=   0.4s\n",
      "[CV] END alpha=15, colsample_bytree=0.6690222967751902, gamma=0.1236417446208457, lambda=1.0914161139324352, learning_rate=0.42653312886686945, max_depth=5, min_child_weight=3, n_estimators=750, scale_pos_weight=2.3609163048840696, subsample=0.8680056330593456; total time=   0.4s\n",
      "[CV] END alpha=5, colsample_bytree=0.23109899651374205, gamma=0.18665231584587477, lambda=1.493959494639886, learning_rate=0.07495968822510439, max_depth=6, min_child_weight=3, n_estimators=500, scale_pos_weight=1.6541337221446182, subsample=1.3655660528751048; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.23109899651374205, gamma=0.18665231584587477, lambda=1.493959494639886, learning_rate=0.07495968822510439, max_depth=6, min_child_weight=3, n_estimators=500, scale_pos_weight=1.6541337221446182, subsample=1.3655660528751048; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.23109899651374205, gamma=0.18665231584587477, lambda=1.493959494639886, learning_rate=0.07495968822510439, max_depth=6, min_child_weight=3, n_estimators=500, scale_pos_weight=1.6541337221446182, subsample=1.3655660528751048; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.23109899651374205, gamma=0.18665231584587477, lambda=1.493959494639886, learning_rate=0.07495968822510439, max_depth=6, min_child_weight=3, n_estimators=500, scale_pos_weight=1.6541337221446182, subsample=1.3655660528751048; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.4489217990862096, gamma=0.23002835299120572, lambda=0.7548945805452828, learning_rate=0.4426835592666863, max_depth=9, min_child_weight=1, n_estimators=550, scale_pos_weight=1.8874905569100429, subsample=0.98827032496707; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.4489217990862096, gamma=0.23002835299120572, lambda=0.7548945805452828, learning_rate=0.4426835592666863, max_depth=9, min_child_weight=1, n_estimators=550, scale_pos_weight=1.8874905569100429, subsample=0.98827032496707; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.4489217990862096, gamma=0.23002835299120572, lambda=0.7548945805452828, learning_rate=0.4426835592666863, max_depth=9, min_child_weight=1, n_estimators=550, scale_pos_weight=1.8874905569100429, subsample=0.98827032496707; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.4489217990862096, gamma=0.23002835299120572, lambda=0.7548945805452828, learning_rate=0.4426835592666863, max_depth=9, min_child_weight=1, n_estimators=550, scale_pos_weight=1.8874905569100429, subsample=0.98827032496707; total time=   0.2s\n",
      "[CV] END alpha=5, colsample_bytree=0.8642936780777373, gamma=0.1695711241261511, lambda=0.28856156663437466, learning_rate=0.48824398146039905, max_depth=8, min_child_weight=3, n_estimators=700, scale_pos_weight=2.5928972704459046, subsample=1.082574143177392; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8642936780777373, gamma=0.1695711241261511, lambda=0.28856156663437466, learning_rate=0.48824398146039905, max_depth=8, min_child_weight=3, n_estimators=700, scale_pos_weight=2.5928972704459046, subsample=1.082574143177392; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8642936780777373, gamma=0.1695711241261511, lambda=0.28856156663437466, learning_rate=0.48824398146039905, max_depth=8, min_child_weight=3, n_estimators=700, scale_pos_weight=2.5928972704459046, subsample=1.082574143177392; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8642936780777373, gamma=0.1695711241261511, lambda=0.28856156663437466, learning_rate=0.48824398146039905, max_depth=8, min_child_weight=3, n_estimators=700, scale_pos_weight=2.5928972704459046, subsample=1.082574143177392; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.2532821613740815, gamma=0.03559809911264633, lambda=0.8827283133734249, learning_rate=0.3776450942481497, max_depth=10, min_child_weight=3, n_estimators=250, scale_pos_weight=0.7345801671137117, subsample=0.9742578322771194; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=0.2532821613740815, gamma=0.03559809911264633, lambda=0.8827283133734249, learning_rate=0.3776450942481497, max_depth=10, min_child_weight=3, n_estimators=250, scale_pos_weight=0.7345801671137117, subsample=0.9742578322771194; total time=   0.1s\n",
      "[CV] END alpha=10, colsample_bytree=0.2532821613740815, gamma=0.03559809911264633, lambda=0.8827283133734249, learning_rate=0.3776450942481497, max_depth=10, min_child_weight=3, n_estimators=250, scale_pos_weight=0.7345801671137117, subsample=0.9742578322771194; total time=   0.1s\n",
      "[CV] END alpha=10, colsample_bytree=0.2532821613740815, gamma=0.03559809911264633, lambda=0.8827283133734249, learning_rate=0.3776450942481497, max_depth=10, min_child_weight=3, n_estimators=250, scale_pos_weight=0.7345801671137117, subsample=0.9742578322771194; total time=   0.1s\n",
      "[CV] END alpha=10, colsample_bytree=0.8459064240146519, gamma=0.4644966716882595, lambda=0.0786691717783437, learning_rate=0.29631202639382764, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=2.8195567583112924, subsample=1.3697144027660388; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.8459064240146519, gamma=0.4644966716882595, lambda=0.0786691717783437, learning_rate=0.29631202639382764, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=2.8195567583112924, subsample=1.3697144027660388; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.8459064240146519, gamma=0.4644966716882595, lambda=0.0786691717783437, learning_rate=0.29631202639382764, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=2.8195567583112924, subsample=1.3697144027660388; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.8459064240146519, gamma=0.4644966716882595, lambda=0.0786691717783437, learning_rate=0.29631202639382764, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=2.8195567583112924, subsample=1.3697144027660388; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.0945756492899956, gamma=0.4502451406844214, lambda=0.5623544174181183, learning_rate=0.37266048614955466, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=2.093413733844323, subsample=0.7436455794235328; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.0945756492899956, gamma=0.4502451406844214, lambda=0.5623544174181183, learning_rate=0.37266048614955466, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=2.093413733844323, subsample=0.7436455794235328; total time=   0.1s\n",
      "[CV] END alpha=25, colsample_bytree=1.0945756492899956, gamma=0.4502451406844214, lambda=0.5623544174181183, learning_rate=0.37266048614955466, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=2.093413733844323, subsample=0.7436455794235328; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.0945756492899956, gamma=0.4502451406844214, lambda=0.5623544174181183, learning_rate=0.37266048614955466, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=2.093413733844323, subsample=0.7436455794235328; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.167720275943738, gamma=0.20759856052488918, lambda=1.442081012972075, learning_rate=0.2511802061872295, max_depth=5, min_child_weight=1, n_estimators=350, scale_pos_weight=2.2422707604735788, subsample=1.5852112853909772; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.167720275943738, gamma=0.20759856052488918, lambda=1.442081012972075, learning_rate=0.2511802061872295, max_depth=5, min_child_weight=1, n_estimators=350, scale_pos_weight=2.2422707604735788, subsample=1.5852112853909772; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.167720275943738, gamma=0.20759856052488918, lambda=1.442081012972075, learning_rate=0.2511802061872295, max_depth=5, min_child_weight=1, n_estimators=350, scale_pos_weight=2.2422707604735788, subsample=1.5852112853909772; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.167720275943738, gamma=0.20759856052488918, lambda=1.442081012972075, learning_rate=0.2511802061872295, max_depth=5, min_child_weight=1, n_estimators=350, scale_pos_weight=2.2422707604735788, subsample=1.5852112853909772; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.6625389937699173, gamma=0.4152706662946483, lambda=0.6896926228893326, learning_rate=0.4497481045556048, max_depth=5, min_child_weight=1, n_estimators=400, scale_pos_weight=2.4341525862819284, subsample=0.7775867400518629; total time=   0.4s\n",
      "[CV] END alpha=5, colsample_bytree=0.6625389937699173, gamma=0.4152706662946483, lambda=0.6896926228893326, learning_rate=0.4497481045556048, max_depth=5, min_child_weight=1, n_estimators=400, scale_pos_weight=2.4341525862819284, subsample=0.7775867400518629; total time=   0.2s\n",
      "[CV] END alpha=5, colsample_bytree=0.6625389937699173, gamma=0.4152706662946483, lambda=0.6896926228893326, learning_rate=0.4497481045556048, max_depth=5, min_child_weight=1, n_estimators=400, scale_pos_weight=2.4341525862819284, subsample=0.7775867400518629; total time=   0.3s\n",
      "[CV] END alpha=5, colsample_bytree=0.6625389937699173, gamma=0.4152706662946483, lambda=0.6896926228893326, learning_rate=0.4497481045556048, max_depth=5, min_child_weight=1, n_estimators=400, scale_pos_weight=2.4341525862819284, subsample=0.7775867400518629; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.3500539306789669, gamma=0.05153290803787175, lambda=0.3430219798740707, learning_rate=0.24848299065729507, max_depth=6, min_child_weight=3, n_estimators=300, scale_pos_weight=1.789084698317278, subsample=1.5552720907030602; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.3500539306789669, gamma=0.05153290803787175, lambda=0.3430219798740707, learning_rate=0.24848299065729507, max_depth=6, min_child_weight=3, n_estimators=300, scale_pos_weight=1.789084698317278, subsample=1.5552720907030602; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.3500539306789669, gamma=0.05153290803787175, lambda=0.3430219798740707, learning_rate=0.24848299065729507, max_depth=6, min_child_weight=3, n_estimators=300, scale_pos_weight=1.789084698317278, subsample=1.5552720907030602; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.3500539306789669, gamma=0.05153290803787175, lambda=0.3430219798740707, learning_rate=0.24848299065729507, max_depth=6, min_child_weight=3, n_estimators=300, scale_pos_weight=1.789084698317278, subsample=1.5552720907030602; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1508826719587402, gamma=0.2273011563517744, lambda=0.7075777504599605, learning_rate=0.29612654697982815, max_depth=6, min_child_weight=3, n_estimators=450, scale_pos_weight=1.2158108682934623, subsample=0.9299610260513032; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1508826719587402, gamma=0.2273011563517744, lambda=0.7075777504599605, learning_rate=0.29612654697982815, max_depth=6, min_child_weight=3, n_estimators=450, scale_pos_weight=1.2158108682934623, subsample=0.9299610260513032; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1508826719587402, gamma=0.2273011563517744, lambda=0.7075777504599605, learning_rate=0.29612654697982815, max_depth=6, min_child_weight=3, n_estimators=450, scale_pos_weight=1.2158108682934623, subsample=0.9299610260513032; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1508826719587402, gamma=0.2273011563517744, lambda=0.7075777504599605, learning_rate=0.29612654697982815, max_depth=6, min_child_weight=3, n_estimators=450, scale_pos_weight=1.2158108682934623, subsample=0.9299610260513032; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5686225939924987, gamma=0.09036770644016928, lambda=1.0830199627240003, learning_rate=0.39991125694942736, max_depth=7, min_child_weight=3, n_estimators=250, scale_pos_weight=2.3939380839352222, subsample=0.8063380103407469; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.5686225939924987, gamma=0.09036770644016928, lambda=1.0830199627240003, learning_rate=0.39991125694942736, max_depth=7, min_child_weight=3, n_estimators=250, scale_pos_weight=2.3939380839352222, subsample=0.8063380103407469; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.5686225939924987, gamma=0.09036770644016928, lambda=1.0830199627240003, learning_rate=0.39991125694942736, max_depth=7, min_child_weight=3, n_estimators=250, scale_pos_weight=2.3939380839352222, subsample=0.8063380103407469; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.5686225939924987, gamma=0.09036770644016928, lambda=1.0830199627240003, learning_rate=0.39991125694942736, max_depth=7, min_child_weight=3, n_estimators=250, scale_pos_weight=2.3939380839352222, subsample=0.8063380103407469; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.2451856308572607, gamma=0.015736130827798567, lambda=1.0829838881651477, learning_rate=0.10190000110424473, max_depth=6, min_child_weight=3, n_estimators=200, scale_pos_weight=2.171922662486875, subsample=1.345285430626047; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.2451856308572607, gamma=0.015736130827798567, lambda=1.0829838881651477, learning_rate=0.10190000110424473, max_depth=6, min_child_weight=3, n_estimators=200, scale_pos_weight=2.171922662486875, subsample=1.345285430626047; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.2451856308572607, gamma=0.015736130827798567, lambda=1.0829838881651477, learning_rate=0.10190000110424473, max_depth=6, min_child_weight=3, n_estimators=200, scale_pos_weight=2.171922662486875, subsample=1.345285430626047; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.2451856308572607, gamma=0.015736130827798567, lambda=1.0829838881651477, learning_rate=0.10190000110424473, max_depth=6, min_child_weight=3, n_estimators=200, scale_pos_weight=2.171922662486875, subsample=1.345285430626047; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.6591648513519093, gamma=0.47910750426320237, lambda=0.8657605685828954, learning_rate=0.20640681012533596, max_depth=10, min_child_weight=3, n_estimators=700, scale_pos_weight=1.8224286845425113, subsample=0.7626056239215913; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.6591648513519093, gamma=0.47910750426320237, lambda=0.8657605685828954, learning_rate=0.20640681012533596, max_depth=10, min_child_weight=3, n_estimators=700, scale_pos_weight=1.8224286845425113, subsample=0.7626056239215913; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.6591648513519093, gamma=0.47910750426320237, lambda=0.8657605685828954, learning_rate=0.20640681012533596, max_depth=10, min_child_weight=3, n_estimators=700, scale_pos_weight=1.8224286845425113, subsample=0.7626056239215913; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.6591648513519093, gamma=0.47910750426320237, lambda=0.8657605685828954, learning_rate=0.20640681012533596, max_depth=10, min_child_weight=3, n_estimators=700, scale_pos_weight=1.8224286845425113, subsample=0.7626056239215913; total time=   0.6s\n",
      "[CV] END alpha=5, colsample_bytree=0.6633077640042337, gamma=0.29923309511584384, lambda=0.18600454791174453, learning_rate=0.11847541966180496, max_depth=7, min_child_weight=3, n_estimators=600, scale_pos_weight=1.551717796564064, subsample=1.3612554466724207; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.6633077640042337, gamma=0.29923309511584384, lambda=0.18600454791174453, learning_rate=0.11847541966180496, max_depth=7, min_child_weight=3, n_estimators=600, scale_pos_weight=1.551717796564064, subsample=1.3612554466724207; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.6633077640042337, gamma=0.29923309511584384, lambda=0.18600454791174453, learning_rate=0.11847541966180496, max_depth=7, min_child_weight=3, n_estimators=600, scale_pos_weight=1.551717796564064, subsample=1.3612554466724207; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.6633077640042337, gamma=0.29923309511584384, lambda=0.18600454791174453, learning_rate=0.11847541966180496, max_depth=7, min_child_weight=3, n_estimators=600, scale_pos_weight=1.551717796564064, subsample=1.3612554466724207; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5209764192438493, gamma=0.3528719037840758, lambda=1.4878139081761752, learning_rate=0.10518553469209373, max_depth=11, min_child_weight=3, n_estimators=250, scale_pos_weight=2.198993267589513, subsample=0.9423196400824383; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.5209764192438493, gamma=0.3528719037840758, lambda=1.4878139081761752, learning_rate=0.10518553469209373, max_depth=11, min_child_weight=3, n_estimators=250, scale_pos_weight=2.198993267589513, subsample=0.9423196400824383; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.5209764192438493, gamma=0.3528719037840758, lambda=1.4878139081761752, learning_rate=0.10518553469209373, max_depth=11, min_child_weight=3, n_estimators=250, scale_pos_weight=2.198993267589513, subsample=0.9423196400824383; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.5209764192438493, gamma=0.3528719037840758, lambda=1.4878139081761752, learning_rate=0.10518553469209373, max_depth=11, min_child_weight=3, n_estimators=250, scale_pos_weight=2.198993267589513, subsample=0.9423196400824383; total time=   0.2s\n",
      "[CV] END alpha=5, colsample_bytree=0.30574116597723516, gamma=0.09289129866522255, lambda=0.38427244622261325, learning_rate=0.2234523053719895, max_depth=10, min_child_weight=1, n_estimators=350, scale_pos_weight=2.5033323302110393, subsample=0.7188584855485612; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.30574116597723516, gamma=0.09289129866522255, lambda=0.38427244622261325, learning_rate=0.2234523053719895, max_depth=10, min_child_weight=1, n_estimators=350, scale_pos_weight=2.5033323302110393, subsample=0.7188584855485612; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.30574116597723516, gamma=0.09289129866522255, lambda=0.38427244622261325, learning_rate=0.2234523053719895, max_depth=10, min_child_weight=1, n_estimators=350, scale_pos_weight=2.5033323302110393, subsample=0.7188584855485612; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.30574116597723516, gamma=0.09289129866522255, lambda=0.38427244622261325, learning_rate=0.2234523053719895, max_depth=10, min_child_weight=1, n_estimators=350, scale_pos_weight=2.5033323302110393, subsample=0.7188584855485612; total time=   0.5s\n",
      "[CV] END alpha=20, colsample_bytree=1.1755351373342637, gamma=0.46586475567390956, lambda=1.0166559923223315, learning_rate=0.23042701730266946, max_depth=10, min_child_weight=3, n_estimators=550, scale_pos_weight=1.3349767947057831, subsample=0.798136151588801; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1755351373342637, gamma=0.46586475567390956, lambda=1.0166559923223315, learning_rate=0.23042701730266946, max_depth=10, min_child_weight=3, n_estimators=550, scale_pos_weight=1.3349767947057831, subsample=0.798136151588801; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1755351373342637, gamma=0.46586475567390956, lambda=1.0166559923223315, learning_rate=0.23042701730266946, max_depth=10, min_child_weight=3, n_estimators=550, scale_pos_weight=1.3349767947057831, subsample=0.798136151588801; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1755351373342637, gamma=0.46586475567390956, lambda=1.0166559923223315, learning_rate=0.23042701730266946, max_depth=10, min_child_weight=3, n_estimators=550, scale_pos_weight=1.3349767947057831, subsample=0.798136151588801; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.43934628320285124, gamma=0.4865864169432066, lambda=1.1393556250750152, learning_rate=0.04801923532557505, max_depth=7, min_child_weight=1, n_estimators=550, scale_pos_weight=2.0605193845935723, subsample=1.3527347839765533; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.43934628320285124, gamma=0.4865864169432066, lambda=1.1393556250750152, learning_rate=0.04801923532557505, max_depth=7, min_child_weight=1, n_estimators=550, scale_pos_weight=2.0605193845935723, subsample=1.3527347839765533; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.43934628320285124, gamma=0.4865864169432066, lambda=1.1393556250750152, learning_rate=0.04801923532557505, max_depth=7, min_child_weight=1, n_estimators=550, scale_pos_weight=2.0605193845935723, subsample=1.3527347839765533; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.43934628320285124, gamma=0.4865864169432066, lambda=1.1393556250750152, learning_rate=0.04801923532557505, max_depth=7, min_child_weight=1, n_estimators=550, scale_pos_weight=2.0605193845935723, subsample=1.3527347839765533; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5416664762992105, gamma=0.28798504538209097, lambda=0.48169270486708515, learning_rate=0.29526672902091544, max_depth=5, min_child_weight=3, n_estimators=550, scale_pos_weight=1.1551695427003101, subsample=1.3836986335150632; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5416664762992105, gamma=0.28798504538209097, lambda=0.48169270486708515, learning_rate=0.29526672902091544, max_depth=5, min_child_weight=3, n_estimators=550, scale_pos_weight=1.1551695427003101, subsample=1.3836986335150632; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5416664762992105, gamma=0.28798504538209097, lambda=0.48169270486708515, learning_rate=0.29526672902091544, max_depth=5, min_child_weight=3, n_estimators=550, scale_pos_weight=1.1551695427003101, subsample=1.3836986335150632; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5416664762992105, gamma=0.28798504538209097, lambda=0.48169270486708515, learning_rate=0.29526672902091544, max_depth=5, min_child_weight=3, n_estimators=550, scale_pos_weight=1.1551695427003101, subsample=1.3836986335150632; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.49403472073539173, gamma=0.37423642122888967, lambda=0.2694904922182544, learning_rate=0.23685255085514184, max_depth=8, min_child_weight=3, n_estimators=600, scale_pos_weight=2.802809769580773, subsample=1.3450565756988648; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.49403472073539173, gamma=0.37423642122888967, lambda=0.2694904922182544, learning_rate=0.23685255085514184, max_depth=8, min_child_weight=3, n_estimators=600, scale_pos_weight=2.802809769580773, subsample=1.3450565756988648; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.49403472073539173, gamma=0.37423642122888967, lambda=0.2694904922182544, learning_rate=0.23685255085514184, max_depth=8, min_child_weight=3, n_estimators=600, scale_pos_weight=2.802809769580773, subsample=1.3450565756988648; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.49403472073539173, gamma=0.37423642122888967, lambda=0.2694904922182544, learning_rate=0.23685255085514184, max_depth=8, min_child_weight=3, n_estimators=600, scale_pos_weight=2.802809769580773, subsample=1.3450565756988648; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7110951676452721, gamma=0.06190519065771388, lambda=1.302412500619433, learning_rate=0.23150931341529574, max_depth=11, min_child_weight=1, n_estimators=350, scale_pos_weight=1.890102619621524, subsample=0.7743630238157008; total time=   0.5s\n",
      "[CV] END alpha=10, colsample_bytree=0.7110951676452721, gamma=0.06190519065771388, lambda=1.302412500619433, learning_rate=0.23150931341529574, max_depth=11, min_child_weight=1, n_estimators=350, scale_pos_weight=1.890102619621524, subsample=0.7743630238157008; total time=   0.5s\n",
      "[CV] END alpha=10, colsample_bytree=0.7110951676452721, gamma=0.06190519065771388, lambda=1.302412500619433, learning_rate=0.23150931341529574, max_depth=11, min_child_weight=1, n_estimators=350, scale_pos_weight=1.890102619621524, subsample=0.7743630238157008; total time=   0.5s\n",
      "[CV] END alpha=10, colsample_bytree=0.7110951676452721, gamma=0.06190519065771388, lambda=1.302412500619433, learning_rate=0.23150931341529574, max_depth=11, min_child_weight=1, n_estimators=350, scale_pos_weight=1.890102619621524, subsample=0.7743630238157008; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.41425816038344915, gamma=0.09457173784332357, lambda=0.666831405603552, learning_rate=0.08173730023999547, max_depth=5, min_child_weight=3, n_estimators=200, scale_pos_weight=2.4369982496068623, subsample=1.0632999093417195; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.41425816038344915, gamma=0.09457173784332357, lambda=0.666831405603552, learning_rate=0.08173730023999547, max_depth=5, min_child_weight=3, n_estimators=200, scale_pos_weight=2.4369982496068623, subsample=1.0632999093417195; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.41425816038344915, gamma=0.09457173784332357, lambda=0.666831405603552, learning_rate=0.08173730023999547, max_depth=5, min_child_weight=3, n_estimators=200, scale_pos_weight=2.4369982496068623, subsample=1.0632999093417195; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.41425816038344915, gamma=0.09457173784332357, lambda=0.666831405603552, learning_rate=0.08173730023999547, max_depth=5, min_child_weight=3, n_estimators=200, scale_pos_weight=2.4369982496068623, subsample=1.0632999093417195; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.3218652792840114, gamma=0.33135556179469644, lambda=0.012175485605697978, learning_rate=0.3880361908612048, max_depth=10, min_child_weight=3, n_estimators=650, scale_pos_weight=1.5746669193177825, subsample=1.1882191690616941; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.3218652792840114, gamma=0.33135556179469644, lambda=0.012175485605697978, learning_rate=0.3880361908612048, max_depth=10, min_child_weight=3, n_estimators=650, scale_pos_weight=1.5746669193177825, subsample=1.1882191690616941; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.3218652792840114, gamma=0.33135556179469644, lambda=0.012175485605697978, learning_rate=0.3880361908612048, max_depth=10, min_child_weight=3, n_estimators=650, scale_pos_weight=1.5746669193177825, subsample=1.1882191690616941; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.3218652792840114, gamma=0.33135556179469644, lambda=0.012175485605697978, learning_rate=0.3880361908612048, max_depth=10, min_child_weight=3, n_estimators=650, scale_pos_weight=1.5746669193177825, subsample=1.1882191690616941; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8038944725469781, gamma=0.14038474412072677, lambda=0.008769018845567134, learning_rate=0.5018138653374691, max_depth=7, min_child_weight=1, n_estimators=250, scale_pos_weight=1.8732561120268338, subsample=0.8325769364824005; total time=   0.2s\n",
      "[CV] END alpha=5, colsample_bytree=0.8038944725469781, gamma=0.14038474412072677, lambda=0.008769018845567134, learning_rate=0.5018138653374691, max_depth=7, min_child_weight=1, n_estimators=250, scale_pos_weight=1.8732561120268338, subsample=0.8325769364824005; total time=   0.2s\n",
      "[CV] END alpha=5, colsample_bytree=0.8038944725469781, gamma=0.14038474412072677, lambda=0.008769018845567134, learning_rate=0.5018138653374691, max_depth=7, min_child_weight=1, n_estimators=250, scale_pos_weight=1.8732561120268338, subsample=0.8325769364824005; total time=   0.2s\n",
      "[CV] END alpha=5, colsample_bytree=0.8038944725469781, gamma=0.14038474412072677, lambda=0.008769018845567134, learning_rate=0.5018138653374691, max_depth=7, min_child_weight=1, n_estimators=250, scale_pos_weight=1.8732561120268338, subsample=0.8325769364824005; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.6127346152943256, gamma=0.3885089302166592, lambda=0.9543058399250627, learning_rate=0.10182231802457724, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=1.7746895796386726, subsample=1.0401616867307064; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6127346152943256, gamma=0.3885089302166592, lambda=0.9543058399250627, learning_rate=0.10182231802457724, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=1.7746895796386726, subsample=1.0401616867307064; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6127346152943256, gamma=0.3885089302166592, lambda=0.9543058399250627, learning_rate=0.10182231802457724, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=1.7746895796386726, subsample=1.0401616867307064; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6127346152943256, gamma=0.3885089302166592, lambda=0.9543058399250627, learning_rate=0.10182231802457724, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=1.7746895796386726, subsample=1.0401616867307064; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1815274395362096, gamma=0.15024478092794635, lambda=0.8532199692705048, learning_rate=0.11067110036579685, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=1.9923181873245717, subsample=1.0560261716472459; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1815274395362096, gamma=0.15024478092794635, lambda=0.8532199692705048, learning_rate=0.11067110036579685, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=1.9923181873245717, subsample=1.0560261716472459; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1815274395362096, gamma=0.15024478092794635, lambda=0.8532199692705048, learning_rate=0.11067110036579685, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=1.9923181873245717, subsample=1.0560261716472459; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1815274395362096, gamma=0.15024478092794635, lambda=0.8532199692705048, learning_rate=0.11067110036579685, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=1.9923181873245717, subsample=1.0560261716472459; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.7788608345978889, gamma=0.003689077584985545, lambda=1.1225063737544674, learning_rate=0.07865993811619808, max_depth=7, min_child_weight=1, n_estimators=200, scale_pos_weight=2.7069015769809948, subsample=0.9208050579582614; total time=   0.5s\n",
      "[CV] END alpha=20, colsample_bytree=0.7788608345978889, gamma=0.003689077584985545, lambda=1.1225063737544674, learning_rate=0.07865993811619808, max_depth=7, min_child_weight=1, n_estimators=200, scale_pos_weight=2.7069015769809948, subsample=0.9208050579582614; total time=   0.4s\n",
      "[CV] END alpha=20, colsample_bytree=0.7788608345978889, gamma=0.003689077584985545, lambda=1.1225063737544674, learning_rate=0.07865993811619808, max_depth=7, min_child_weight=1, n_estimators=200, scale_pos_weight=2.7069015769809948, subsample=0.9208050579582614; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.7788608345978889, gamma=0.003689077584985545, lambda=1.1225063737544674, learning_rate=0.07865993811619808, max_depth=7, min_child_weight=1, n_estimators=200, scale_pos_weight=2.7069015769809948, subsample=0.9208050579582614; total time=   0.3s\n",
      "[CV] END alpha=5, colsample_bytree=0.2598337434009525, gamma=0.3234279139286491, lambda=0.1178352618132808, learning_rate=0.03493848337125376, max_depth=7, min_child_weight=3, n_estimators=350, scale_pos_weight=2.6663581989336675, subsample=0.9803622049065887; total time=   0.6s\n",
      "[CV] END alpha=5, colsample_bytree=0.2598337434009525, gamma=0.3234279139286491, lambda=0.1178352618132808, learning_rate=0.03493848337125376, max_depth=7, min_child_weight=3, n_estimators=350, scale_pos_weight=2.6663581989336675, subsample=0.9803622049065887; total time=   0.6s\n",
      "[CV] END alpha=5, colsample_bytree=0.2598337434009525, gamma=0.3234279139286491, lambda=0.1178352618132808, learning_rate=0.03493848337125376, max_depth=7, min_child_weight=3, n_estimators=350, scale_pos_weight=2.6663581989336675, subsample=0.9803622049065887; total time=   0.6s\n",
      "[CV] END alpha=5, colsample_bytree=0.2598337434009525, gamma=0.3234279139286491, lambda=0.1178352618132808, learning_rate=0.03493848337125376, max_depth=7, min_child_weight=3, n_estimators=350, scale_pos_weight=2.6663581989336675, subsample=0.9803622049065887; total time=   0.6s\n",
      "[CV] END alpha=25, colsample_bytree=0.8489847017157504, gamma=0.07859160299164553, lambda=1.1916359312274747, learning_rate=0.3229754550386157, max_depth=11, min_child_weight=1, n_estimators=750, scale_pos_weight=1.5764623166816412, subsample=1.0278593571252554; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.8489847017157504, gamma=0.07859160299164553, lambda=1.1916359312274747, learning_rate=0.3229754550386157, max_depth=11, min_child_weight=1, n_estimators=750, scale_pos_weight=1.5764623166816412, subsample=1.0278593571252554; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.8489847017157504, gamma=0.07859160299164553, lambda=1.1916359312274747, learning_rate=0.3229754550386157, max_depth=11, min_child_weight=1, n_estimators=750, scale_pos_weight=1.5764623166816412, subsample=1.0278593571252554; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.8489847017157504, gamma=0.07859160299164553, lambda=1.1916359312274747, learning_rate=0.3229754550386157, max_depth=11, min_child_weight=1, n_estimators=750, scale_pos_weight=1.5764623166816412, subsample=1.0278593571252554; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.23661710346340298, gamma=0.271189831972765, lambda=0.4525001964279064, learning_rate=0.41139180678708087, max_depth=11, min_child_weight=1, n_estimators=650, scale_pos_weight=1.6332071218675628, subsample=1.114758420477759; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.23661710346340298, gamma=0.271189831972765, lambda=0.4525001964279064, learning_rate=0.41139180678708087, max_depth=11, min_child_weight=1, n_estimators=650, scale_pos_weight=1.6332071218675628, subsample=1.114758420477759; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.23661710346340298, gamma=0.271189831972765, lambda=0.4525001964279064, learning_rate=0.41139180678708087, max_depth=11, min_child_weight=1, n_estimators=650, scale_pos_weight=1.6332071218675628, subsample=1.114758420477759; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.23661710346340298, gamma=0.271189831972765, lambda=0.4525001964279064, learning_rate=0.41139180678708087, max_depth=11, min_child_weight=1, n_estimators=650, scale_pos_weight=1.6332071218675628, subsample=1.114758420477759; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.3705269388659422, gamma=0.08319416544382813, lambda=0.5626146909630771, learning_rate=0.08932381376990799, max_depth=6, min_child_weight=1, n_estimators=650, scale_pos_weight=1.0851300838738946, subsample=1.4159454031279926; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.3705269388659422, gamma=0.08319416544382813, lambda=0.5626146909630771, learning_rate=0.08932381376990799, max_depth=6, min_child_weight=1, n_estimators=650, scale_pos_weight=1.0851300838738946, subsample=1.4159454031279926; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.3705269388659422, gamma=0.08319416544382813, lambda=0.5626146909630771, learning_rate=0.08932381376990799, max_depth=6, min_child_weight=1, n_estimators=650, scale_pos_weight=1.0851300838738946, subsample=1.4159454031279926; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.3705269388659422, gamma=0.08319416544382813, lambda=0.5626146909630771, learning_rate=0.08932381376990799, max_depth=6, min_child_weight=1, n_estimators=650, scale_pos_weight=1.0851300838738946, subsample=1.4159454031279926; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.3817437265339964, gamma=0.32999074782977983, lambda=0.8357760576859854, learning_rate=0.4482335020656407, max_depth=5, min_child_weight=1, n_estimators=650, scale_pos_weight=0.8193237189459198, subsample=1.4897012232128937; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.3817437265339964, gamma=0.32999074782977983, lambda=0.8357760576859854, learning_rate=0.4482335020656407, max_depth=5, min_child_weight=1, n_estimators=650, scale_pos_weight=0.8193237189459198, subsample=1.4897012232128937; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.3817437265339964, gamma=0.32999074782977983, lambda=0.8357760576859854, learning_rate=0.4482335020656407, max_depth=5, min_child_weight=1, n_estimators=650, scale_pos_weight=0.8193237189459198, subsample=1.4897012232128937; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.3817437265339964, gamma=0.32999074782977983, lambda=0.8357760576859854, learning_rate=0.4482335020656407, max_depth=5, min_child_weight=1, n_estimators=650, scale_pos_weight=0.8193237189459198, subsample=1.4897012232128937; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.3644920749388581, gamma=0.07704627416158955, lambda=0.006492746778470226, learning_rate=0.1527177587138286, max_depth=5, min_child_weight=3, n_estimators=700, scale_pos_weight=1.3338374106882491, subsample=1.5138878981898767; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.3644920749388581, gamma=0.07704627416158955, lambda=0.006492746778470226, learning_rate=0.1527177587138286, max_depth=5, min_child_weight=3, n_estimators=700, scale_pos_weight=1.3338374106882491, subsample=1.5138878981898767; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.3644920749388581, gamma=0.07704627416158955, lambda=0.006492746778470226, learning_rate=0.1527177587138286, max_depth=5, min_child_weight=3, n_estimators=700, scale_pos_weight=1.3338374106882491, subsample=1.5138878981898767; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.3644920749388581, gamma=0.07704627416158955, lambda=0.006492746778470226, learning_rate=0.1527177587138286, max_depth=5, min_child_weight=3, n_estimators=700, scale_pos_weight=1.3338374106882491, subsample=1.5138878981898767; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8266276049193331, gamma=0.061216255407074927, lambda=1.2117616823639343, learning_rate=0.25516524719356243, max_depth=9, min_child_weight=3, n_estimators=300, scale_pos_weight=1.9803713971203984, subsample=1.5534241844129024; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8266276049193331, gamma=0.061216255407074927, lambda=1.2117616823639343, learning_rate=0.25516524719356243, max_depth=9, min_child_weight=3, n_estimators=300, scale_pos_weight=1.9803713971203984, subsample=1.5534241844129024; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8266276049193331, gamma=0.061216255407074927, lambda=1.2117616823639343, learning_rate=0.25516524719356243, max_depth=9, min_child_weight=3, n_estimators=300, scale_pos_weight=1.9803713971203984, subsample=1.5534241844129024; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8266276049193331, gamma=0.061216255407074927, lambda=1.2117616823639343, learning_rate=0.25516524719356243, max_depth=9, min_child_weight=3, n_estimators=300, scale_pos_weight=1.9803713971203984, subsample=1.5534241844129024; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5676337824464424, gamma=0.19488364612046577, lambda=1.4911091115986872, learning_rate=0.4745463354005161, max_depth=8, min_child_weight=3, n_estimators=300, scale_pos_weight=1.1077269228681907, subsample=1.518248001910047; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5676337824464424, gamma=0.19488364612046577, lambda=1.4911091115986872, learning_rate=0.4745463354005161, max_depth=8, min_child_weight=3, n_estimators=300, scale_pos_weight=1.1077269228681907, subsample=1.518248001910047; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5676337824464424, gamma=0.19488364612046577, lambda=1.4911091115986872, learning_rate=0.4745463354005161, max_depth=8, min_child_weight=3, n_estimators=300, scale_pos_weight=1.1077269228681907, subsample=1.518248001910047; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5676337824464424, gamma=0.19488364612046577, lambda=1.4911091115986872, learning_rate=0.4745463354005161, max_depth=8, min_child_weight=3, n_estimators=300, scale_pos_weight=1.1077269228681907, subsample=1.518248001910047; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.9805615162394268, gamma=0.15794474672328052, lambda=0.0970473947332155, learning_rate=0.3034090422689642, max_depth=11, min_child_weight=1, n_estimators=350, scale_pos_weight=2.759582859074296, subsample=0.8234085183743759; total time=   0.4s\n",
      "[CV] END alpha=10, colsample_bytree=0.9805615162394268, gamma=0.15794474672328052, lambda=0.0970473947332155, learning_rate=0.3034090422689642, max_depth=11, min_child_weight=1, n_estimators=350, scale_pos_weight=2.759582859074296, subsample=0.8234085183743759; total time=   0.4s\n",
      "[CV] END alpha=10, colsample_bytree=0.9805615162394268, gamma=0.15794474672328052, lambda=0.0970473947332155, learning_rate=0.3034090422689642, max_depth=11, min_child_weight=1, n_estimators=350, scale_pos_weight=2.759582859074296, subsample=0.8234085183743759; total time=   0.5s\n",
      "[CV] END alpha=10, colsample_bytree=0.9805615162394268, gamma=0.15794474672328052, lambda=0.0970473947332155, learning_rate=0.3034090422689642, max_depth=11, min_child_weight=1, n_estimators=350, scale_pos_weight=2.759582859074296, subsample=0.8234085183743759; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.5869717830977945, gamma=0.4378508657407534, lambda=0.05473330201618698, learning_rate=0.03683752801715089, max_depth=6, min_child_weight=3, n_estimators=750, scale_pos_weight=2.6355551610551076, subsample=1.4149140638197122; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5869717830977945, gamma=0.4378508657407534, lambda=0.05473330201618698, learning_rate=0.03683752801715089, max_depth=6, min_child_weight=3, n_estimators=750, scale_pos_weight=2.6355551610551076, subsample=1.4149140638197122; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5869717830977945, gamma=0.4378508657407534, lambda=0.05473330201618698, learning_rate=0.03683752801715089, max_depth=6, min_child_weight=3, n_estimators=750, scale_pos_weight=2.6355551610551076, subsample=1.4149140638197122; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5869717830977945, gamma=0.4378508657407534, lambda=0.05473330201618698, learning_rate=0.03683752801715089, max_depth=6, min_child_weight=3, n_estimators=750, scale_pos_weight=2.6355551610551076, subsample=1.4149140638197122; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.42150286279710464, gamma=0.10542989855198603, lambda=0.7537296445756103, learning_rate=0.36673337793446303, max_depth=6, min_child_weight=1, n_estimators=300, scale_pos_weight=1.0840458343802046, subsample=1.2897360074190773; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.42150286279710464, gamma=0.10542989855198603, lambda=0.7537296445756103, learning_rate=0.36673337793446303, max_depth=6, min_child_weight=1, n_estimators=300, scale_pos_weight=1.0840458343802046, subsample=1.2897360074190773; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.42150286279710464, gamma=0.10542989855198603, lambda=0.7537296445756103, learning_rate=0.36673337793446303, max_depth=6, min_child_weight=1, n_estimators=300, scale_pos_weight=1.0840458343802046, subsample=1.2897360074190773; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.42150286279710464, gamma=0.10542989855198603, lambda=0.7537296445756103, learning_rate=0.36673337793446303, max_depth=6, min_child_weight=1, n_estimators=300, scale_pos_weight=1.0840458343802046, subsample=1.2897360074190773; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1445710023143185, gamma=0.2058047238079751, lambda=0.925255530789667, learning_rate=0.47036268485144345, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=2.437256616940375, subsample=0.7719991564905554; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1445710023143185, gamma=0.2058047238079751, lambda=0.925255530789667, learning_rate=0.47036268485144345, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=2.437256616940375, subsample=0.7719991564905554; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1445710023143185, gamma=0.2058047238079751, lambda=0.925255530789667, learning_rate=0.47036268485144345, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=2.437256616940375, subsample=0.7719991564905554; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1445710023143185, gamma=0.2058047238079751, lambda=0.925255530789667, learning_rate=0.47036268485144345, max_depth=10, min_child_weight=1, n_estimators=450, scale_pos_weight=2.437256616940375, subsample=0.7719991564905554; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.2675053735563175, gamma=0.4286483017608358, lambda=1.0745347382566512, learning_rate=0.5090682441775393, max_depth=10, min_child_weight=1, n_estimators=650, scale_pos_weight=2.36425073040628, subsample=1.5299419655987998; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.2675053735563175, gamma=0.4286483017608358, lambda=1.0745347382566512, learning_rate=0.5090682441775393, max_depth=10, min_child_weight=1, n_estimators=650, scale_pos_weight=2.36425073040628, subsample=1.5299419655987998; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.2675053735563175, gamma=0.4286483017608358, lambda=1.0745347382566512, learning_rate=0.5090682441775393, max_depth=10, min_child_weight=1, n_estimators=650, scale_pos_weight=2.36425073040628, subsample=1.5299419655987998; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.2675053735563175, gamma=0.4286483017608358, lambda=1.0745347382566512, learning_rate=0.5090682441775393, max_depth=10, min_child_weight=1, n_estimators=650, scale_pos_weight=2.36425073040628, subsample=1.5299419655987998; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.650027600191819, gamma=0.09107707388662012, lambda=0.930106865032958, learning_rate=0.2546976162428815, max_depth=5, min_child_weight=3, n_estimators=200, scale_pos_weight=1.36541906946416, subsample=0.7936182708456723; total time=   0.2s\n",
      "[CV] END alpha=15, colsample_bytree=0.650027600191819, gamma=0.09107707388662012, lambda=0.930106865032958, learning_rate=0.2546976162428815, max_depth=5, min_child_weight=3, n_estimators=200, scale_pos_weight=1.36541906946416, subsample=0.7936182708456723; total time=   0.2s\n",
      "[CV] END alpha=15, colsample_bytree=0.650027600191819, gamma=0.09107707388662012, lambda=0.930106865032958, learning_rate=0.2546976162428815, max_depth=5, min_child_weight=3, n_estimators=200, scale_pos_weight=1.36541906946416, subsample=0.7936182708456723; total time=   0.2s\n",
      "[CV] END alpha=15, colsample_bytree=0.650027600191819, gamma=0.09107707388662012, lambda=0.930106865032958, learning_rate=0.2546976162428815, max_depth=5, min_child_weight=3, n_estimators=200, scale_pos_weight=1.36541906946416, subsample=0.7936182708456723; total time=   0.1s\n",
      "[CV] END alpha=5, colsample_bytree=0.5120735215389873, gamma=0.3792893019925162, lambda=0.8150143734740521, learning_rate=0.3981303882465561, max_depth=11, min_child_weight=3, n_estimators=600, scale_pos_weight=1.4973298824411394, subsample=1.0139435759152962; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.5120735215389873, gamma=0.3792893019925162, lambda=0.8150143734740521, learning_rate=0.3981303882465561, max_depth=11, min_child_weight=3, n_estimators=600, scale_pos_weight=1.4973298824411394, subsample=1.0139435759152962; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.5120735215389873, gamma=0.3792893019925162, lambda=0.8150143734740521, learning_rate=0.3981303882465561, max_depth=11, min_child_weight=3, n_estimators=600, scale_pos_weight=1.4973298824411394, subsample=1.0139435759152962; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.5120735215389873, gamma=0.3792893019925162, lambda=0.8150143734740521, learning_rate=0.3981303882465561, max_depth=11, min_child_weight=3, n_estimators=600, scale_pos_weight=1.4973298824411394, subsample=1.0139435759152962; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8087994898839417, gamma=0.3579734838053709, lambda=0.007943972927446252, learning_rate=0.2282117364075898, max_depth=5, min_child_weight=3, n_estimators=250, scale_pos_weight=0.8206972634866937, subsample=1.0462545163991994; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8087994898839417, gamma=0.3579734838053709, lambda=0.007943972927446252, learning_rate=0.2282117364075898, max_depth=5, min_child_weight=3, n_estimators=250, scale_pos_weight=0.8206972634866937, subsample=1.0462545163991994; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8087994898839417, gamma=0.3579734838053709, lambda=0.007943972927446252, learning_rate=0.2282117364075898, max_depth=5, min_child_weight=3, n_estimators=250, scale_pos_weight=0.8206972634866937, subsample=1.0462545163991994; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8087994898839417, gamma=0.3579734838053709, lambda=0.007943972927446252, learning_rate=0.2282117364075898, max_depth=5, min_child_weight=3, n_estimators=250, scale_pos_weight=0.8206972634866937, subsample=1.0462545163991994; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.20918272561140866, gamma=0.09191409811249784, lambda=0.9899579052521703, learning_rate=0.23685080948547016, max_depth=11, min_child_weight=1, n_estimators=700, scale_pos_weight=0.8487398066057674, subsample=1.2634230245702; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.20918272561140866, gamma=0.09191409811249784, lambda=0.9899579052521703, learning_rate=0.23685080948547016, max_depth=11, min_child_weight=1, n_estimators=700, scale_pos_weight=0.8487398066057674, subsample=1.2634230245702; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.20918272561140866, gamma=0.09191409811249784, lambda=0.9899579052521703, learning_rate=0.23685080948547016, max_depth=11, min_child_weight=1, n_estimators=700, scale_pos_weight=0.8487398066057674, subsample=1.2634230245702; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.20918272561140866, gamma=0.09191409811249784, lambda=0.9899579052521703, learning_rate=0.23685080948547016, max_depth=11, min_child_weight=1, n_estimators=700, scale_pos_weight=0.8487398066057674, subsample=1.2634230245702; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.6290553909251306, gamma=0.33941274968811663, lambda=0.6054547756523302, learning_rate=0.07587379420664146, max_depth=9, min_child_weight=3, n_estimators=600, scale_pos_weight=1.1586799869584181, subsample=0.6775002748158448; total time=   0.8s\n",
      "[CV] END alpha=5, colsample_bytree=0.6290553909251306, gamma=0.33941274968811663, lambda=0.6054547756523302, learning_rate=0.07587379420664146, max_depth=9, min_child_weight=3, n_estimators=600, scale_pos_weight=1.1586799869584181, subsample=0.6775002748158448; total time=   0.7s\n",
      "[CV] END alpha=5, colsample_bytree=0.6290553909251306, gamma=0.33941274968811663, lambda=0.6054547756523302, learning_rate=0.07587379420664146, max_depth=9, min_child_weight=3, n_estimators=600, scale_pos_weight=1.1586799869584181, subsample=0.6775002748158448; total time=   0.8s\n",
      "[CV] END alpha=5, colsample_bytree=0.6290553909251306, gamma=0.33941274968811663, lambda=0.6054547756523302, learning_rate=0.07587379420664146, max_depth=9, min_child_weight=3, n_estimators=600, scale_pos_weight=1.1586799869584181, subsample=0.6775002748158448; total time=   0.8s\n",
      "[CV] END alpha=25, colsample_bytree=0.9842427631580188, gamma=0.3566033279675927, lambda=0.07003732815125979, learning_rate=0.03512177795085147, max_depth=6, min_child_weight=3, n_estimators=350, scale_pos_weight=2.752632780706752, subsample=1.4718245466274622; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.9842427631580188, gamma=0.3566033279675927, lambda=0.07003732815125979, learning_rate=0.03512177795085147, max_depth=6, min_child_weight=3, n_estimators=350, scale_pos_weight=2.752632780706752, subsample=1.4718245466274622; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.9842427631580188, gamma=0.3566033279675927, lambda=0.07003732815125979, learning_rate=0.03512177795085147, max_depth=6, min_child_weight=3, n_estimators=350, scale_pos_weight=2.752632780706752, subsample=1.4718245466274622; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.9842427631580188, gamma=0.3566033279675927, lambda=0.07003732815125979, learning_rate=0.03512177795085147, max_depth=6, min_child_weight=3, n_estimators=350, scale_pos_weight=2.752632780706752, subsample=1.4718245466274622; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.6227458543503255, gamma=0.03647838366701811, lambda=0.9516284999810574, learning_rate=0.35174278556605587, max_depth=11, min_child_weight=3, n_estimators=650, scale_pos_weight=1.3000265856427662, subsample=0.881743561968087; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.6227458543503255, gamma=0.03647838366701811, lambda=0.9516284999810574, learning_rate=0.35174278556605587, max_depth=11, min_child_weight=3, n_estimators=650, scale_pos_weight=1.3000265856427662, subsample=0.881743561968087; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.6227458543503255, gamma=0.03647838366701811, lambda=0.9516284999810574, learning_rate=0.35174278556605587, max_depth=11, min_child_weight=3, n_estimators=650, scale_pos_weight=1.3000265856427662, subsample=0.881743561968087; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.6227458543503255, gamma=0.03647838366701811, lambda=0.9516284999810574, learning_rate=0.35174278556605587, max_depth=11, min_child_weight=3, n_estimators=650, scale_pos_weight=1.3000265856427662, subsample=0.881743561968087; total time=   0.6s\n",
      "[CV] END alpha=20, colsample_bytree=0.4058943770469408, gamma=0.398844546858808, lambda=0.9946422946036408, learning_rate=0.0914800167910128, max_depth=9, min_child_weight=3, n_estimators=500, scale_pos_weight=1.419829831073716, subsample=0.6720058936270984; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.4058943770469408, gamma=0.398844546858808, lambda=0.9946422946036408, learning_rate=0.0914800167910128, max_depth=9, min_child_weight=3, n_estimators=500, scale_pos_weight=1.419829831073716, subsample=0.6720058936270984; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.4058943770469408, gamma=0.398844546858808, lambda=0.9946422946036408, learning_rate=0.0914800167910128, max_depth=9, min_child_weight=3, n_estimators=500, scale_pos_weight=1.419829831073716, subsample=0.6720058936270984; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.4058943770469408, gamma=0.398844546858808, lambda=0.9946422946036408, learning_rate=0.0914800167910128, max_depth=9, min_child_weight=3, n_estimators=500, scale_pos_weight=1.419829831073716, subsample=0.6720058936270984; total time=   0.3s\n",
      "[CV] END alpha=15, colsample_bytree=1.0936184368683488, gamma=0.3992016690874948, lambda=1.4044985606386604, learning_rate=0.369625805189222, max_depth=5, min_child_weight=1, n_estimators=400, scale_pos_weight=1.5164826046975342, subsample=0.9818687929703306; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0936184368683488, gamma=0.3992016690874948, lambda=1.4044985606386604, learning_rate=0.369625805189222, max_depth=5, min_child_weight=1, n_estimators=400, scale_pos_weight=1.5164826046975342, subsample=0.9818687929703306; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0936184368683488, gamma=0.3992016690874948, lambda=1.4044985606386604, learning_rate=0.369625805189222, max_depth=5, min_child_weight=1, n_estimators=400, scale_pos_weight=1.5164826046975342, subsample=0.9818687929703306; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0936184368683488, gamma=0.3992016690874948, lambda=1.4044985606386604, learning_rate=0.369625805189222, max_depth=5, min_child_weight=1, n_estimators=400, scale_pos_weight=1.5164826046975342, subsample=0.9818687929703306; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.7324795997582887, gamma=0.1546541846480739, lambda=0.21083646275276374, learning_rate=0.4539121725115546, max_depth=6, min_child_weight=3, n_estimators=450, scale_pos_weight=2.461920923077651, subsample=0.8277957866990068; total time=   0.3s\n",
      "[CV] END alpha=5, colsample_bytree=0.7324795997582887, gamma=0.1546541846480739, lambda=0.21083646275276374, learning_rate=0.4539121725115546, max_depth=6, min_child_weight=3, n_estimators=450, scale_pos_weight=2.461920923077651, subsample=0.8277957866990068; total time=   0.3s\n",
      "[CV] END alpha=5, colsample_bytree=0.7324795997582887, gamma=0.1546541846480739, lambda=0.21083646275276374, learning_rate=0.4539121725115546, max_depth=6, min_child_weight=3, n_estimators=450, scale_pos_weight=2.461920923077651, subsample=0.8277957866990068; total time=   0.3s\n",
      "[CV] END alpha=5, colsample_bytree=0.7324795997582887, gamma=0.1546541846480739, lambda=0.21083646275276374, learning_rate=0.4539121725115546, max_depth=6, min_child_weight=3, n_estimators=450, scale_pos_weight=2.461920923077651, subsample=0.8277957866990068; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.5282018648903901, gamma=0.4423046449225767, lambda=0.6227387882373081, learning_rate=0.33001716365212774, max_depth=11, min_child_weight=3, n_estimators=650, scale_pos_weight=2.2281838738650253, subsample=1.1829002227627128; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5282018648903901, gamma=0.4423046449225767, lambda=0.6227387882373081, learning_rate=0.33001716365212774, max_depth=11, min_child_weight=3, n_estimators=650, scale_pos_weight=2.2281838738650253, subsample=1.1829002227627128; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5282018648903901, gamma=0.4423046449225767, lambda=0.6227387882373081, learning_rate=0.33001716365212774, max_depth=11, min_child_weight=3, n_estimators=650, scale_pos_weight=2.2281838738650253, subsample=1.1829002227627128; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5282018648903901, gamma=0.4423046449225767, lambda=0.6227387882373081, learning_rate=0.33001716365212774, max_depth=11, min_child_weight=3, n_estimators=650, scale_pos_weight=2.2281838738650253, subsample=1.1829002227627128; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.25110453584931697, gamma=0.40165585809118703, lambda=1.4922347897613681, learning_rate=0.039313186936586635, max_depth=8, min_child_weight=3, n_estimators=200, scale_pos_weight=2.054178250985239, subsample=1.257379572864715; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.25110453584931697, gamma=0.40165585809118703, lambda=1.4922347897613681, learning_rate=0.039313186936586635, max_depth=8, min_child_weight=3, n_estimators=200, scale_pos_weight=2.054178250985239, subsample=1.257379572864715; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.25110453584931697, gamma=0.40165585809118703, lambda=1.4922347897613681, learning_rate=0.039313186936586635, max_depth=8, min_child_weight=3, n_estimators=200, scale_pos_weight=2.054178250985239, subsample=1.257379572864715; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.25110453584931697, gamma=0.40165585809118703, lambda=1.4922347897613681, learning_rate=0.039313186936586635, max_depth=8, min_child_weight=3, n_estimators=200, scale_pos_weight=2.054178250985239, subsample=1.257379572864715; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.2712118294412827, gamma=0.19599096204245448, lambda=0.00681720042023537, learning_rate=0.31387270462942685, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=1.019715266429039, subsample=1.5736447078568316; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.2712118294412827, gamma=0.19599096204245448, lambda=0.00681720042023537, learning_rate=0.31387270462942685, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=1.019715266429039, subsample=1.5736447078568316; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.2712118294412827, gamma=0.19599096204245448, lambda=0.00681720042023537, learning_rate=0.31387270462942685, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=1.019715266429039, subsample=1.5736447078568316; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.2712118294412827, gamma=0.19599096204245448, lambda=0.00681720042023537, learning_rate=0.31387270462942685, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=1.019715266429039, subsample=1.5736447078568316; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0448501499184006, gamma=0.38208599356523554, lambda=1.077024778281541, learning_rate=0.48665484898579037, max_depth=5, min_child_weight=3, n_estimators=300, scale_pos_weight=2.757025932870058, subsample=1.4194379819827065; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0448501499184006, gamma=0.38208599356523554, lambda=1.077024778281541, learning_rate=0.48665484898579037, max_depth=5, min_child_weight=3, n_estimators=300, scale_pos_weight=2.757025932870058, subsample=1.4194379819827065; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0448501499184006, gamma=0.38208599356523554, lambda=1.077024778281541, learning_rate=0.48665484898579037, max_depth=5, min_child_weight=3, n_estimators=300, scale_pos_weight=2.757025932870058, subsample=1.4194379819827065; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0448501499184006, gamma=0.38208599356523554, lambda=1.077024778281541, learning_rate=0.48665484898579037, max_depth=5, min_child_weight=3, n_estimators=300, scale_pos_weight=2.757025932870058, subsample=1.4194379819827065; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.4989091963617219, gamma=0.4107529627336319, lambda=1.3739476938750097, learning_rate=0.1296919215314915, max_depth=11, min_child_weight=1, n_estimators=700, scale_pos_weight=2.2269980676241756, subsample=1.2406576893848786; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.4989091963617219, gamma=0.4107529627336319, lambda=1.3739476938750097, learning_rate=0.1296919215314915, max_depth=11, min_child_weight=1, n_estimators=700, scale_pos_weight=2.2269980676241756, subsample=1.2406576893848786; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.4989091963617219, gamma=0.4107529627336319, lambda=1.3739476938750097, learning_rate=0.1296919215314915, max_depth=11, min_child_weight=1, n_estimators=700, scale_pos_weight=2.2269980676241756, subsample=1.2406576893848786; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.4989091963617219, gamma=0.4107529627336319, lambda=1.3739476938750097, learning_rate=0.1296919215314915, max_depth=11, min_child_weight=1, n_estimators=700, scale_pos_weight=2.2269980676241756, subsample=1.2406576893848786; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.7240506175147581, gamma=0.416152296684758, lambda=0.49393464658599506, learning_rate=0.5004063365856696, max_depth=9, min_child_weight=1, n_estimators=300, scale_pos_weight=1.6113428588510774, subsample=0.9137833740463458; total time=   0.2s\n",
      "[CV] END alpha=5, colsample_bytree=0.7240506175147581, gamma=0.416152296684758, lambda=0.49393464658599506, learning_rate=0.5004063365856696, max_depth=9, min_child_weight=1, n_estimators=300, scale_pos_weight=1.6113428588510774, subsample=0.9137833740463458; total time=   0.2s\n",
      "[CV] END alpha=5, colsample_bytree=0.7240506175147581, gamma=0.416152296684758, lambda=0.49393464658599506, learning_rate=0.5004063365856696, max_depth=9, min_child_weight=1, n_estimators=300, scale_pos_weight=1.6113428588510774, subsample=0.9137833740463458; total time=   0.2s\n",
      "[CV] END alpha=5, colsample_bytree=0.7240506175147581, gamma=0.416152296684758, lambda=0.49393464658599506, learning_rate=0.5004063365856696, max_depth=9, min_child_weight=1, n_estimators=300, scale_pos_weight=1.6113428588510774, subsample=0.9137833740463458; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.912301880919498, gamma=0.00454266711985668, lambda=0.6464776465707778, learning_rate=0.15872739273091824, max_depth=7, min_child_weight=3, n_estimators=450, scale_pos_weight=1.6012391008574836, subsample=1.099772067775194; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.912301880919498, gamma=0.00454266711985668, lambda=0.6464776465707778, learning_rate=0.15872739273091824, max_depth=7, min_child_weight=3, n_estimators=450, scale_pos_weight=1.6012391008574836, subsample=1.099772067775194; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.912301880919498, gamma=0.00454266711985668, lambda=0.6464776465707778, learning_rate=0.15872739273091824, max_depth=7, min_child_weight=3, n_estimators=450, scale_pos_weight=1.6012391008574836, subsample=1.099772067775194; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.912301880919498, gamma=0.00454266711985668, lambda=0.6464776465707778, learning_rate=0.15872739273091824, max_depth=7, min_child_weight=3, n_estimators=450, scale_pos_weight=1.6012391008574836, subsample=1.099772067775194; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.31266953882140774, gamma=0.47120893023021504, lambda=0.8075904712295388, learning_rate=0.43258088241992476, max_depth=10, min_child_weight=1, n_estimators=500, scale_pos_weight=2.5070359879378388, subsample=1.0601142700585915; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.31266953882140774, gamma=0.47120893023021504, lambda=0.8075904712295388, learning_rate=0.43258088241992476, max_depth=10, min_child_weight=1, n_estimators=500, scale_pos_weight=2.5070359879378388, subsample=1.0601142700585915; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.31266953882140774, gamma=0.47120893023021504, lambda=0.8075904712295388, learning_rate=0.43258088241992476, max_depth=10, min_child_weight=1, n_estimators=500, scale_pos_weight=2.5070359879378388, subsample=1.0601142700585915; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.31266953882140774, gamma=0.47120893023021504, lambda=0.8075904712295388, learning_rate=0.43258088241992476, max_depth=10, min_child_weight=1, n_estimators=500, scale_pos_weight=2.5070359879378388, subsample=1.0601142700585915; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.026776564641609, gamma=0.012286310625181263, lambda=0.826765069235452, learning_rate=0.2466570107650295, max_depth=9, min_child_weight=1, n_estimators=650, scale_pos_weight=2.831310250135579, subsample=1.5217456816790684; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.026776564641609, gamma=0.012286310625181263, lambda=0.826765069235452, learning_rate=0.2466570107650295, max_depth=9, min_child_weight=1, n_estimators=650, scale_pos_weight=2.831310250135579, subsample=1.5217456816790684; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.026776564641609, gamma=0.012286310625181263, lambda=0.826765069235452, learning_rate=0.2466570107650295, max_depth=9, min_child_weight=1, n_estimators=650, scale_pos_weight=2.831310250135579, subsample=1.5217456816790684; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.026776564641609, gamma=0.012286310625181263, lambda=0.826765069235452, learning_rate=0.2466570107650295, max_depth=9, min_child_weight=1, n_estimators=650, scale_pos_weight=2.831310250135579, subsample=1.5217456816790684; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.680394129269998, gamma=0.301204177224527, lambda=0.02858927513222731, learning_rate=0.4017387420001474, max_depth=8, min_child_weight=1, n_estimators=250, scale_pos_weight=1.8701877566409626, subsample=0.7217481424121088; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=0.680394129269998, gamma=0.301204177224527, lambda=0.02858927513222731, learning_rate=0.4017387420001474, max_depth=8, min_child_weight=1, n_estimators=250, scale_pos_weight=1.8701877566409626, subsample=0.7217481424121088; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=0.680394129269998, gamma=0.301204177224527, lambda=0.02858927513222731, learning_rate=0.4017387420001474, max_depth=8, min_child_weight=1, n_estimators=250, scale_pos_weight=1.8701877566409626, subsample=0.7217481424121088; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=0.680394129269998, gamma=0.301204177224527, lambda=0.02858927513222731, learning_rate=0.4017387420001474, max_depth=8, min_child_weight=1, n_estimators=250, scale_pos_weight=1.8701877566409626, subsample=0.7217481424121088; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.7373601355352031, gamma=0.020694479242515718, lambda=0.06789061684772002, learning_rate=0.3626215728685471, max_depth=11, min_child_weight=1, n_estimators=500, scale_pos_weight=1.6492114871849315, subsample=1.3076720246917075; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7373601355352031, gamma=0.020694479242515718, lambda=0.06789061684772002, learning_rate=0.3626215728685471, max_depth=11, min_child_weight=1, n_estimators=500, scale_pos_weight=1.6492114871849315, subsample=1.3076720246917075; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7373601355352031, gamma=0.020694479242515718, lambda=0.06789061684772002, learning_rate=0.3626215728685471, max_depth=11, min_child_weight=1, n_estimators=500, scale_pos_weight=1.6492114871849315, subsample=1.3076720246917075; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7373601355352031, gamma=0.020694479242515718, lambda=0.06789061684772002, learning_rate=0.3626215728685471, max_depth=11, min_child_weight=1, n_estimators=500, scale_pos_weight=1.6492114871849315, subsample=1.3076720246917075; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.770130606015089, gamma=0.2830173156303721, lambda=1.4197299697370829, learning_rate=0.18643091537554402, max_depth=10, min_child_weight=1, n_estimators=650, scale_pos_weight=1.04695908859214, subsample=1.0767859738896055; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.770130606015089, gamma=0.2830173156303721, lambda=1.4197299697370829, learning_rate=0.18643091537554402, max_depth=10, min_child_weight=1, n_estimators=650, scale_pos_weight=1.04695908859214, subsample=1.0767859738896055; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.770130606015089, gamma=0.2830173156303721, lambda=1.4197299697370829, learning_rate=0.18643091537554402, max_depth=10, min_child_weight=1, n_estimators=650, scale_pos_weight=1.04695908859214, subsample=1.0767859738896055; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.770130606015089, gamma=0.2830173156303721, lambda=1.4197299697370829, learning_rate=0.18643091537554402, max_depth=10, min_child_weight=1, n_estimators=650, scale_pos_weight=1.04695908859214, subsample=1.0767859738896055; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1201790779914045, gamma=0.040758420011464846, lambda=0.268580718364282, learning_rate=0.022377948647965433, max_depth=11, min_child_weight=3, n_estimators=550, scale_pos_weight=2.6072011710438865, subsample=1.0373964328053724; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1201790779914045, gamma=0.040758420011464846, lambda=0.268580718364282, learning_rate=0.022377948647965433, max_depth=11, min_child_weight=3, n_estimators=550, scale_pos_weight=2.6072011710438865, subsample=1.0373964328053724; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1201790779914045, gamma=0.040758420011464846, lambda=0.268580718364282, learning_rate=0.022377948647965433, max_depth=11, min_child_weight=3, n_estimators=550, scale_pos_weight=2.6072011710438865, subsample=1.0373964328053724; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1201790779914045, gamma=0.040758420011464846, lambda=0.268580718364282, learning_rate=0.022377948647965433, max_depth=11, min_child_weight=3, n_estimators=550, scale_pos_weight=2.6072011710438865, subsample=1.0373964328053724; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.43816193558659283, gamma=0.3212847454641093, lambda=1.4524718053529426, learning_rate=0.027045298428532587, max_depth=6, min_child_weight=1, n_estimators=400, scale_pos_weight=2.058860095253382, subsample=1.4131959046131923; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.43816193558659283, gamma=0.3212847454641093, lambda=1.4524718053529426, learning_rate=0.027045298428532587, max_depth=6, min_child_weight=1, n_estimators=400, scale_pos_weight=2.058860095253382, subsample=1.4131959046131923; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.43816193558659283, gamma=0.3212847454641093, lambda=1.4524718053529426, learning_rate=0.027045298428532587, max_depth=6, min_child_weight=1, n_estimators=400, scale_pos_weight=2.058860095253382, subsample=1.4131959046131923; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.43816193558659283, gamma=0.3212847454641093, lambda=1.4524718053529426, learning_rate=0.027045298428532587, max_depth=6, min_child_weight=1, n_estimators=400, scale_pos_weight=2.058860095253382, subsample=1.4131959046131923; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.9801055040694215, gamma=0.18828430209243413, lambda=1.4073031934171536, learning_rate=0.335983719274813, max_depth=11, min_child_weight=3, n_estimators=700, scale_pos_weight=1.209882027795405, subsample=1.1308428212788972; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.9801055040694215, gamma=0.18828430209243413, lambda=1.4073031934171536, learning_rate=0.335983719274813, max_depth=11, min_child_weight=3, n_estimators=700, scale_pos_weight=1.209882027795405, subsample=1.1308428212788972; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.9801055040694215, gamma=0.18828430209243413, lambda=1.4073031934171536, learning_rate=0.335983719274813, max_depth=11, min_child_weight=3, n_estimators=700, scale_pos_weight=1.209882027795405, subsample=1.1308428212788972; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.9801055040694215, gamma=0.18828430209243413, lambda=1.4073031934171536, learning_rate=0.335983719274813, max_depth=11, min_child_weight=3, n_estimators=700, scale_pos_weight=1.209882027795405, subsample=1.1308428212788972; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.9105047789050631, gamma=0.37729554140934346, lambda=1.2020086210460466, learning_rate=0.39001575760209717, max_depth=5, min_child_weight=1, n_estimators=450, scale_pos_weight=1.8729411865005554, subsample=0.6268069209378564; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.9105047789050631, gamma=0.37729554140934346, lambda=1.2020086210460466, learning_rate=0.39001575760209717, max_depth=5, min_child_weight=1, n_estimators=450, scale_pos_weight=1.8729411865005554, subsample=0.6268069209378564; total time=   0.4s\n",
      "[CV] END alpha=10, colsample_bytree=0.9105047789050631, gamma=0.37729554140934346, lambda=1.2020086210460466, learning_rate=0.39001575760209717, max_depth=5, min_child_weight=1, n_estimators=450, scale_pos_weight=1.8729411865005554, subsample=0.6268069209378564; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.9105047789050631, gamma=0.37729554140934346, lambda=1.2020086210460466, learning_rate=0.39001575760209717, max_depth=5, min_child_weight=1, n_estimators=450, scale_pos_weight=1.8729411865005554, subsample=0.6268069209378564; total time=   0.4s\n",
      "[CV] END alpha=20, colsample_bytree=0.7606577446529172, gamma=0.4359888470404646, lambda=0.45718347597583064, learning_rate=0.1411169151826815, max_depth=5, min_child_weight=1, n_estimators=400, scale_pos_weight=2.191900036824345, subsample=0.6136380644734439; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.7606577446529172, gamma=0.4359888470404646, lambda=0.45718347597583064, learning_rate=0.1411169151826815, max_depth=5, min_child_weight=1, n_estimators=400, scale_pos_weight=2.191900036824345, subsample=0.6136380644734439; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.7606577446529172, gamma=0.4359888470404646, lambda=0.45718347597583064, learning_rate=0.1411169151826815, max_depth=5, min_child_weight=1, n_estimators=400, scale_pos_weight=2.191900036824345, subsample=0.6136380644734439; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.7606577446529172, gamma=0.4359888470404646, lambda=0.45718347597583064, learning_rate=0.1411169151826815, max_depth=5, min_child_weight=1, n_estimators=400, scale_pos_weight=2.191900036824345, subsample=0.6136380644734439; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=1.1584992812291546, gamma=0.39480272854971665, lambda=0.8740916047063311, learning_rate=0.5060376488355072, max_depth=9, min_child_weight=3, n_estimators=400, scale_pos_weight=2.699574966921446, subsample=0.9773958943320852; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1584992812291546, gamma=0.39480272854971665, lambda=0.8740916047063311, learning_rate=0.5060376488355072, max_depth=9, min_child_weight=3, n_estimators=400, scale_pos_weight=2.699574966921446, subsample=0.9773958943320852; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1584992812291546, gamma=0.39480272854971665, lambda=0.8740916047063311, learning_rate=0.5060376488355072, max_depth=9, min_child_weight=3, n_estimators=400, scale_pos_weight=2.699574966921446, subsample=0.9773958943320852; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1584992812291546, gamma=0.39480272854971665, lambda=0.8740916047063311, learning_rate=0.5060376488355072, max_depth=9, min_child_weight=3, n_estimators=400, scale_pos_weight=2.699574966921446, subsample=0.9773958943320852; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1427100661250558, gamma=0.4816902633492866, lambda=0.667529090643866, learning_rate=0.2513893264570362, max_depth=7, min_child_weight=3, n_estimators=250, scale_pos_weight=1.1876671439223467, subsample=1.1448205491668344; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1427100661250558, gamma=0.4816902633492866, lambda=0.667529090643866, learning_rate=0.2513893264570362, max_depth=7, min_child_weight=3, n_estimators=250, scale_pos_weight=1.1876671439223467, subsample=1.1448205491668344; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1427100661250558, gamma=0.4816902633492866, lambda=0.667529090643866, learning_rate=0.2513893264570362, max_depth=7, min_child_weight=3, n_estimators=250, scale_pos_weight=1.1876671439223467, subsample=1.1448205491668344; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1427100661250558, gamma=0.4816902633492866, lambda=0.667529090643866, learning_rate=0.2513893264570362, max_depth=7, min_child_weight=3, n_estimators=250, scale_pos_weight=1.1876671439223467, subsample=1.1448205491668344; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5723412665568013, gamma=0.09909086889816815, lambda=1.4918881400239852, learning_rate=0.26619366477282863, max_depth=9, min_child_weight=3, n_estimators=750, scale_pos_weight=1.8229103832431326, subsample=0.8045070537227451; total time=   0.4s\n",
      "[CV] END alpha=20, colsample_bytree=0.5723412665568013, gamma=0.09909086889816815, lambda=1.4918881400239852, learning_rate=0.26619366477282863, max_depth=9, min_child_weight=3, n_estimators=750, scale_pos_weight=1.8229103832431326, subsample=0.8045070537227451; total time=   0.4s\n",
      "[CV] END alpha=20, colsample_bytree=0.5723412665568013, gamma=0.09909086889816815, lambda=1.4918881400239852, learning_rate=0.26619366477282863, max_depth=9, min_child_weight=3, n_estimators=750, scale_pos_weight=1.8229103832431326, subsample=0.8045070537227451; total time=   0.4s\n",
      "[CV] END alpha=20, colsample_bytree=0.5723412665568013, gamma=0.09909086889816815, lambda=1.4918881400239852, learning_rate=0.26619366477282863, max_depth=9, min_child_weight=3, n_estimators=750, scale_pos_weight=1.8229103832431326, subsample=0.8045070537227451; total time=   0.4s\n",
      "[CV] END alpha=5, colsample_bytree=1.1854655719939573, gamma=0.10627686090203248, lambda=0.343319148395954, learning_rate=0.3921512696257017, max_depth=6, min_child_weight=1, n_estimators=650, scale_pos_weight=2.659764514818039, subsample=1.4717781068724891; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1854655719939573, gamma=0.10627686090203248, lambda=0.343319148395954, learning_rate=0.3921512696257017, max_depth=6, min_child_weight=1, n_estimators=650, scale_pos_weight=2.659764514818039, subsample=1.4717781068724891; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1854655719939573, gamma=0.10627686090203248, lambda=0.343319148395954, learning_rate=0.3921512696257017, max_depth=6, min_child_weight=1, n_estimators=650, scale_pos_weight=2.659764514818039, subsample=1.4717781068724891; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1854655719939573, gamma=0.10627686090203248, lambda=0.343319148395954, learning_rate=0.3921512696257017, max_depth=6, min_child_weight=1, n_estimators=650, scale_pos_weight=2.659764514818039, subsample=1.4717781068724891; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.040246146143935, gamma=0.15864645897788626, lambda=0.28397279024714284, learning_rate=0.3850261123751798, max_depth=7, min_child_weight=1, n_estimators=700, scale_pos_weight=1.5543925692529141, subsample=1.4441876268627838; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.040246146143935, gamma=0.15864645897788626, lambda=0.28397279024714284, learning_rate=0.3850261123751798, max_depth=7, min_child_weight=1, n_estimators=700, scale_pos_weight=1.5543925692529141, subsample=1.4441876268627838; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.040246146143935, gamma=0.15864645897788626, lambda=0.28397279024714284, learning_rate=0.3850261123751798, max_depth=7, min_child_weight=1, n_estimators=700, scale_pos_weight=1.5543925692529141, subsample=1.4441876268627838; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.040246146143935, gamma=0.15864645897788626, lambda=0.28397279024714284, learning_rate=0.3850261123751798, max_depth=7, min_child_weight=1, n_estimators=700, scale_pos_weight=1.5543925692529141, subsample=1.4441876268627838; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9079296738703202, gamma=0.2698944106844391, lambda=0.7081343765094283, learning_rate=0.31368154272434584, max_depth=11, min_child_weight=1, n_estimators=750, scale_pos_weight=1.3112840618838097, subsample=1.0813292217053507; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9079296738703202, gamma=0.2698944106844391, lambda=0.7081343765094283, learning_rate=0.31368154272434584, max_depth=11, min_child_weight=1, n_estimators=750, scale_pos_weight=1.3112840618838097, subsample=1.0813292217053507; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9079296738703202, gamma=0.2698944106844391, lambda=0.7081343765094283, learning_rate=0.31368154272434584, max_depth=11, min_child_weight=1, n_estimators=750, scale_pos_weight=1.3112840618838097, subsample=1.0813292217053507; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9079296738703202, gamma=0.2698944106844391, lambda=0.7081343765094283, learning_rate=0.31368154272434584, max_depth=11, min_child_weight=1, n_estimators=750, scale_pos_weight=1.3112840618838097, subsample=1.0813292217053507; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.6196676211639822, gamma=0.4594074072727686, lambda=1.2843342554503443, learning_rate=0.012866875807393754, max_depth=10, min_child_weight=3, n_estimators=300, scale_pos_weight=1.30985891486832, subsample=0.6957922037446137; total time=   0.9s\n",
      "[CV] END alpha=5, colsample_bytree=0.6196676211639822, gamma=0.4594074072727686, lambda=1.2843342554503443, learning_rate=0.012866875807393754, max_depth=10, min_child_weight=3, n_estimators=300, scale_pos_weight=1.30985891486832, subsample=0.6957922037446137; total time=   0.9s\n",
      "[CV] END alpha=5, colsample_bytree=0.6196676211639822, gamma=0.4594074072727686, lambda=1.2843342554503443, learning_rate=0.012866875807393754, max_depth=10, min_child_weight=3, n_estimators=300, scale_pos_weight=1.30985891486832, subsample=0.6957922037446137; total time=   0.9s\n",
      "[CV] END alpha=5, colsample_bytree=0.6196676211639822, gamma=0.4594074072727686, lambda=1.2843342554503443, learning_rate=0.012866875807393754, max_depth=10, min_child_weight=3, n_estimators=300, scale_pos_weight=1.30985891486832, subsample=0.6957922037446137; total time=   0.9s\n",
      "[CV] END alpha=20, colsample_bytree=0.8633391513086976, gamma=0.3746187754419153, lambda=0.33912183038231397, learning_rate=0.1962280209134798, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=2.414541327477813, subsample=0.8122284679421352; total time=   0.4s\n",
      "[CV] END alpha=20, colsample_bytree=0.8633391513086976, gamma=0.3746187754419153, lambda=0.33912183038231397, learning_rate=0.1962280209134798, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=2.414541327477813, subsample=0.8122284679421352; total time=   0.5s\n",
      "[CV] END alpha=20, colsample_bytree=0.8633391513086976, gamma=0.3746187754419153, lambda=0.33912183038231397, learning_rate=0.1962280209134798, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=2.414541327477813, subsample=0.8122284679421352; total time=   0.4s\n",
      "[CV] END alpha=20, colsample_bytree=0.8633391513086976, gamma=0.3746187754419153, lambda=0.33912183038231397, learning_rate=0.1962280209134798, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=2.414541327477813, subsample=0.8122284679421352; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.7927588090584485, gamma=0.10026693783511315, lambda=0.5606825004924458, learning_rate=0.13074967463421883, max_depth=10, min_child_weight=1, n_estimators=550, scale_pos_weight=2.809159574395496, subsample=1.0834041172529272; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.7927588090584485, gamma=0.10026693783511315, lambda=0.5606825004924458, learning_rate=0.13074967463421883, max_depth=10, min_child_weight=1, n_estimators=550, scale_pos_weight=2.809159574395496, subsample=1.0834041172529272; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.7927588090584485, gamma=0.10026693783511315, lambda=0.5606825004924458, learning_rate=0.13074967463421883, max_depth=10, min_child_weight=1, n_estimators=550, scale_pos_weight=2.809159574395496, subsample=1.0834041172529272; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.7927588090584485, gamma=0.10026693783511315, lambda=0.5606825004924458, learning_rate=0.13074967463421883, max_depth=10, min_child_weight=1, n_estimators=550, scale_pos_weight=2.809159574395496, subsample=1.0834041172529272; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.43066705798459265, gamma=0.420957657601357, lambda=0.8346637856454762, learning_rate=0.04206662702079388, max_depth=6, min_child_weight=3, n_estimators=650, scale_pos_weight=0.7091448219682902, subsample=0.7754204716137203; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.43066705798459265, gamma=0.420957657601357, lambda=0.8346637856454762, learning_rate=0.04206662702079388, max_depth=6, min_child_weight=3, n_estimators=650, scale_pos_weight=0.7091448219682902, subsample=0.7754204716137203; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.43066705798459265, gamma=0.420957657601357, lambda=0.8346637856454762, learning_rate=0.04206662702079388, max_depth=6, min_child_weight=3, n_estimators=650, scale_pos_weight=0.7091448219682902, subsample=0.7754204716137203; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.43066705798459265, gamma=0.420957657601357, lambda=0.8346637856454762, learning_rate=0.04206662702079388, max_depth=6, min_child_weight=3, n_estimators=650, scale_pos_weight=0.7091448219682902, subsample=0.7754204716137203; total time=   0.3s\n",
      "[CV] END alpha=15, colsample_bytree=0.20276219122358125, gamma=0.11424185316530006, lambda=1.078909554877046, learning_rate=0.03365423272797668, max_depth=9, min_child_weight=1, n_estimators=600, scale_pos_weight=2.2881759938277697, subsample=1.0779282629671543; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.20276219122358125, gamma=0.11424185316530006, lambda=1.078909554877046, learning_rate=0.03365423272797668, max_depth=9, min_child_weight=1, n_estimators=600, scale_pos_weight=2.2881759938277697, subsample=1.0779282629671543; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.20276219122358125, gamma=0.11424185316530006, lambda=1.078909554877046, learning_rate=0.03365423272797668, max_depth=9, min_child_weight=1, n_estimators=600, scale_pos_weight=2.2881759938277697, subsample=1.0779282629671543; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.20276219122358125, gamma=0.11424185316530006, lambda=1.078909554877046, learning_rate=0.03365423272797668, max_depth=9, min_child_weight=1, n_estimators=600, scale_pos_weight=2.2881759938277697, subsample=1.0779282629671543; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1155971743597684, gamma=0.005604150155171794, lambda=0.10126923411812905, learning_rate=0.3659924477404025, max_depth=10, min_child_weight=1, n_estimators=750, scale_pos_weight=2.616578838718395, subsample=1.4458535719706391; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1155971743597684, gamma=0.005604150155171794, lambda=0.10126923411812905, learning_rate=0.3659924477404025, max_depth=10, min_child_weight=1, n_estimators=750, scale_pos_weight=2.616578838718395, subsample=1.4458535719706391; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1155971743597684, gamma=0.005604150155171794, lambda=0.10126923411812905, learning_rate=0.3659924477404025, max_depth=10, min_child_weight=1, n_estimators=750, scale_pos_weight=2.616578838718395, subsample=1.4458535719706391; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1155971743597684, gamma=0.005604150155171794, lambda=0.10126923411812905, learning_rate=0.3659924477404025, max_depth=10, min_child_weight=1, n_estimators=750, scale_pos_weight=2.616578838718395, subsample=1.4458535719706391; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.3530358917845889, gamma=0.32244678310244335, lambda=1.2259899763962638, learning_rate=0.4541783528033342, max_depth=8, min_child_weight=3, n_estimators=450, scale_pos_weight=0.8483647013503814, subsample=0.7355779765449861; total time=   0.2s\n",
      "[CV] END alpha=5, colsample_bytree=0.3530358917845889, gamma=0.32244678310244335, lambda=1.2259899763962638, learning_rate=0.4541783528033342, max_depth=8, min_child_weight=3, n_estimators=450, scale_pos_weight=0.8483647013503814, subsample=0.7355779765449861; total time=   0.3s\n",
      "[CV] END alpha=5, colsample_bytree=0.3530358917845889, gamma=0.32244678310244335, lambda=1.2259899763962638, learning_rate=0.4541783528033342, max_depth=8, min_child_weight=3, n_estimators=450, scale_pos_weight=0.8483647013503814, subsample=0.7355779765449861; total time=   0.2s\n",
      "[CV] END alpha=5, colsample_bytree=0.3530358917845889, gamma=0.32244678310244335, lambda=1.2259899763962638, learning_rate=0.4541783528033342, max_depth=8, min_child_weight=3, n_estimators=450, scale_pos_weight=0.8483647013503814, subsample=0.7355779765449861; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.9444510183354033, gamma=0.4157052689282652, lambda=1.279391485385822, learning_rate=0.4831403494801343, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=1.8980620439239093, subsample=1.559510022539652; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.9444510183354033, gamma=0.4157052689282652, lambda=1.279391485385822, learning_rate=0.4831403494801343, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=1.8980620439239093, subsample=1.559510022539652; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.9444510183354033, gamma=0.4157052689282652, lambda=1.279391485385822, learning_rate=0.4831403494801343, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=1.8980620439239093, subsample=1.559510022539652; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.9444510183354033, gamma=0.4157052689282652, lambda=1.279391485385822, learning_rate=0.4831403494801343, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=1.8980620439239093, subsample=1.559510022539652; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.7526394402514625, gamma=0.11763123316425261, lambda=0.7887210413384982, learning_rate=0.08162381455642191, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=1.7240294949335722, subsample=1.5631354270840259; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.7526394402514625, gamma=0.11763123316425261, lambda=0.7887210413384982, learning_rate=0.08162381455642191, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=1.7240294949335722, subsample=1.5631354270840259; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.7526394402514625, gamma=0.11763123316425261, lambda=0.7887210413384982, learning_rate=0.08162381455642191, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=1.7240294949335722, subsample=1.5631354270840259; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.7526394402514625, gamma=0.11763123316425261, lambda=0.7887210413384982, learning_rate=0.08162381455642191, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=1.7240294949335722, subsample=1.5631354270840259; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0778891832212008, gamma=0.03759505301226124, lambda=1.0947816690676004, learning_rate=0.05597740716124643, max_depth=5, min_child_weight=3, n_estimators=700, scale_pos_weight=2.0829084447775523, subsample=1.4516600273816465; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0778891832212008, gamma=0.03759505301226124, lambda=1.0947816690676004, learning_rate=0.05597740716124643, max_depth=5, min_child_weight=3, n_estimators=700, scale_pos_weight=2.0829084447775523, subsample=1.4516600273816465; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0778891832212008, gamma=0.03759505301226124, lambda=1.0947816690676004, learning_rate=0.05597740716124643, max_depth=5, min_child_weight=3, n_estimators=700, scale_pos_weight=2.0829084447775523, subsample=1.4516600273816465; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0778891832212008, gamma=0.03759505301226124, lambda=1.0947816690676004, learning_rate=0.05597740716124643, max_depth=5, min_child_weight=3, n_estimators=700, scale_pos_weight=2.0829084447775523, subsample=1.4516600273816465; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6005145463998796, gamma=0.3570935226501121, lambda=0.8729146610396085, learning_rate=0.4270038175960835, max_depth=10, min_child_weight=3, n_estimators=400, scale_pos_weight=1.3819209585386898, subsample=1.1498194355330749; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6005145463998796, gamma=0.3570935226501121, lambda=0.8729146610396085, learning_rate=0.4270038175960835, max_depth=10, min_child_weight=3, n_estimators=400, scale_pos_weight=1.3819209585386898, subsample=1.1498194355330749; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6005145463998796, gamma=0.3570935226501121, lambda=0.8729146610396085, learning_rate=0.4270038175960835, max_depth=10, min_child_weight=3, n_estimators=400, scale_pos_weight=1.3819209585386898, subsample=1.1498194355330749; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6005145463998796, gamma=0.3570935226501121, lambda=0.8729146610396085, learning_rate=0.4270038175960835, max_depth=10, min_child_weight=3, n_estimators=400, scale_pos_weight=1.3819209585386898, subsample=1.1498194355330749; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.7431588516002918, gamma=0.026873983334998075, lambda=1.3251818214913695, learning_rate=0.3084781811771228, max_depth=6, min_child_weight=3, n_estimators=700, scale_pos_weight=2.784430802679709, subsample=0.6978024034783916; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.7431588516002918, gamma=0.026873983334998075, lambda=1.3251818214913695, learning_rate=0.3084781811771228, max_depth=6, min_child_weight=3, n_estimators=700, scale_pos_weight=2.784430802679709, subsample=0.6978024034783916; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.7431588516002918, gamma=0.026873983334998075, lambda=1.3251818214913695, learning_rate=0.3084781811771228, max_depth=6, min_child_weight=3, n_estimators=700, scale_pos_weight=2.784430802679709, subsample=0.6978024034783916; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.7431588516002918, gamma=0.026873983334998075, lambda=1.3251818214913695, learning_rate=0.3084781811771228, max_depth=6, min_child_weight=3, n_estimators=700, scale_pos_weight=2.784430802679709, subsample=0.6978024034783916; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.7171926942732865, gamma=0.14256350839938448, lambda=0.06637466781879531, learning_rate=0.21877325847841939, max_depth=8, min_child_weight=3, n_estimators=450, scale_pos_weight=1.2132198381162476, subsample=1.528363253688235; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.7171926942732865, gamma=0.14256350839938448, lambda=0.06637466781879531, learning_rate=0.21877325847841939, max_depth=8, min_child_weight=3, n_estimators=450, scale_pos_weight=1.2132198381162476, subsample=1.528363253688235; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.7171926942732865, gamma=0.14256350839938448, lambda=0.06637466781879531, learning_rate=0.21877325847841939, max_depth=8, min_child_weight=3, n_estimators=450, scale_pos_weight=1.2132198381162476, subsample=1.528363253688235; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.7171926942732865, gamma=0.14256350839938448, lambda=0.06637466781879531, learning_rate=0.21877325847841939, max_depth=8, min_child_weight=3, n_estimators=450, scale_pos_weight=1.2132198381162476, subsample=1.528363253688235; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.4904637327518769, gamma=0.24883002717306069, lambda=1.0703283045760106, learning_rate=0.037032640091257334, max_depth=11, min_child_weight=3, n_estimators=300, scale_pos_weight=1.240367366435264, subsample=0.8597544635151857; total time=   0.4s\n",
      "[CV] END alpha=15, colsample_bytree=0.4904637327518769, gamma=0.24883002717306069, lambda=1.0703283045760106, learning_rate=0.037032640091257334, max_depth=11, min_child_weight=3, n_estimators=300, scale_pos_weight=1.240367366435264, subsample=0.8597544635151857; total time=   0.4s\n",
      "[CV] END alpha=15, colsample_bytree=0.4904637327518769, gamma=0.24883002717306069, lambda=1.0703283045760106, learning_rate=0.037032640091257334, max_depth=11, min_child_weight=3, n_estimators=300, scale_pos_weight=1.240367366435264, subsample=0.8597544635151857; total time=   0.4s\n",
      "[CV] END alpha=15, colsample_bytree=0.4904637327518769, gamma=0.24883002717306069, lambda=1.0703283045760106, learning_rate=0.037032640091257334, max_depth=11, min_child_weight=3, n_estimators=300, scale_pos_weight=1.240367366435264, subsample=0.8597544635151857; total time=   0.4s\n",
      "[CV] END alpha=10, colsample_bytree=0.6709692288681082, gamma=0.03025822570994996, lambda=0.39542692565404913, learning_rate=0.32149741123357245, max_depth=11, min_child_weight=1, n_estimators=350, scale_pos_weight=2.305767996409375, subsample=0.7856208176777035; total time=   0.5s\n",
      "[CV] END alpha=10, colsample_bytree=0.6709692288681082, gamma=0.03025822570994996, lambda=0.39542692565404913, learning_rate=0.32149741123357245, max_depth=11, min_child_weight=1, n_estimators=350, scale_pos_weight=2.305767996409375, subsample=0.7856208176777035; total time=   0.5s\n",
      "[CV] END alpha=10, colsample_bytree=0.6709692288681082, gamma=0.03025822570994996, lambda=0.39542692565404913, learning_rate=0.32149741123357245, max_depth=11, min_child_weight=1, n_estimators=350, scale_pos_weight=2.305767996409375, subsample=0.7856208176777035; total time=   0.5s\n",
      "[CV] END alpha=10, colsample_bytree=0.6709692288681082, gamma=0.03025822570994996, lambda=0.39542692565404913, learning_rate=0.32149741123357245, max_depth=11, min_child_weight=1, n_estimators=350, scale_pos_weight=2.305767996409375, subsample=0.7856208176777035; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.5648492324631933, gamma=0.30143214787693806, lambda=0.7584809269749035, learning_rate=0.308580490722584, max_depth=8, min_child_weight=1, n_estimators=550, scale_pos_weight=0.7416321723749278, subsample=1.1730899290884291; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5648492324631933, gamma=0.30143214787693806, lambda=0.7584809269749035, learning_rate=0.308580490722584, max_depth=8, min_child_weight=1, n_estimators=550, scale_pos_weight=0.7416321723749278, subsample=1.1730899290884291; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5648492324631933, gamma=0.30143214787693806, lambda=0.7584809269749035, learning_rate=0.308580490722584, max_depth=8, min_child_weight=1, n_estimators=550, scale_pos_weight=0.7416321723749278, subsample=1.1730899290884291; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5648492324631933, gamma=0.30143214787693806, lambda=0.7584809269749035, learning_rate=0.308580490722584, max_depth=8, min_child_weight=1, n_estimators=550, scale_pos_weight=0.7416321723749278, subsample=1.1730899290884291; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.21321855956791852, gamma=0.47649434846306177, lambda=1.3017169463161775, learning_rate=0.4310601371168681, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=2.7396470126939994, subsample=0.8572397793172776; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.21321855956791852, gamma=0.47649434846306177, lambda=1.3017169463161775, learning_rate=0.4310601371168681, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=2.7396470126939994, subsample=0.8572397793172776; total time=   0.3s\n",
      "[CV] END alpha=5, colsample_bytree=0.21321855956791852, gamma=0.47649434846306177, lambda=1.3017169463161775, learning_rate=0.4310601371168681, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=2.7396470126939994, subsample=0.8572397793172776; total time=   0.3s\n",
      "[CV] END alpha=5, colsample_bytree=0.21321855956791852, gamma=0.47649434846306177, lambda=1.3017169463161775, learning_rate=0.4310601371168681, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=2.7396470126939994, subsample=0.8572397793172776; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.25681376025521346, gamma=0.21984191527925168, lambda=0.9836304673991567, learning_rate=0.3465670958569943, max_depth=5, min_child_weight=3, n_estimators=200, scale_pos_weight=0.7361115140541421, subsample=1.3189169382743364; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.25681376025521346, gamma=0.21984191527925168, lambda=0.9836304673991567, learning_rate=0.3465670958569943, max_depth=5, min_child_weight=3, n_estimators=200, scale_pos_weight=0.7361115140541421, subsample=1.3189169382743364; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.25681376025521346, gamma=0.21984191527925168, lambda=0.9836304673991567, learning_rate=0.3465670958569943, max_depth=5, min_child_weight=3, n_estimators=200, scale_pos_weight=0.7361115140541421, subsample=1.3189169382743364; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.25681376025521346, gamma=0.21984191527925168, lambda=0.9836304673991567, learning_rate=0.3465670958569943, max_depth=5, min_child_weight=3, n_estimators=200, scale_pos_weight=0.7361115140541421, subsample=1.3189169382743364; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9052077364377242, gamma=0.1203522375759683, lambda=0.3859802298159286, learning_rate=0.46752702503262905, max_depth=11, min_child_weight=1, n_estimators=250, scale_pos_weight=2.4039951267875015, subsample=1.1284415907424004; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9052077364377242, gamma=0.1203522375759683, lambda=0.3859802298159286, learning_rate=0.46752702503262905, max_depth=11, min_child_weight=1, n_estimators=250, scale_pos_weight=2.4039951267875015, subsample=1.1284415907424004; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9052077364377242, gamma=0.1203522375759683, lambda=0.3859802298159286, learning_rate=0.46752702503262905, max_depth=11, min_child_weight=1, n_estimators=250, scale_pos_weight=2.4039951267875015, subsample=1.1284415907424004; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9052077364377242, gamma=0.1203522375759683, lambda=0.3859802298159286, learning_rate=0.46752702503262905, max_depth=11, min_child_weight=1, n_estimators=250, scale_pos_weight=2.4039951267875015, subsample=1.1284415907424004; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.8033704335671121, gamma=0.08136677965183325, lambda=0.1914051172048098, learning_rate=0.2970391752504484, max_depth=10, min_child_weight=3, n_estimators=250, scale_pos_weight=2.729543680938643, subsample=0.8460211233682585; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.8033704335671121, gamma=0.08136677965183325, lambda=0.1914051172048098, learning_rate=0.2970391752504484, max_depth=10, min_child_weight=3, n_estimators=250, scale_pos_weight=2.729543680938643, subsample=0.8460211233682585; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.8033704335671121, gamma=0.08136677965183325, lambda=0.1914051172048098, learning_rate=0.2970391752504484, max_depth=10, min_child_weight=3, n_estimators=250, scale_pos_weight=2.729543680938643, subsample=0.8460211233682585; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.8033704335671121, gamma=0.08136677965183325, lambda=0.1914051172048098, learning_rate=0.2970391752504484, max_depth=10, min_child_weight=3, n_estimators=250, scale_pos_weight=2.729543680938643, subsample=0.8460211233682585; total time=   0.2s\n",
      "[CV] END alpha=5, colsample_bytree=0.8215857768973089, gamma=0.13090063275172586, lambda=1.45621216565389, learning_rate=0.506167784371001, max_depth=8, min_child_weight=3, n_estimators=550, scale_pos_weight=1.3801332124316417, subsample=0.8714582487087775; total time=   0.4s\n",
      "[CV] END alpha=5, colsample_bytree=0.8215857768973089, gamma=0.13090063275172586, lambda=1.45621216565389, learning_rate=0.506167784371001, max_depth=8, min_child_weight=3, n_estimators=550, scale_pos_weight=1.3801332124316417, subsample=0.8714582487087775; total time=   0.3s\n",
      "[CV] END alpha=5, colsample_bytree=0.8215857768973089, gamma=0.13090063275172586, lambda=1.45621216565389, learning_rate=0.506167784371001, max_depth=8, min_child_weight=3, n_estimators=550, scale_pos_weight=1.3801332124316417, subsample=0.8714582487087775; total time=   0.3s\n",
      "[CV] END alpha=5, colsample_bytree=0.8215857768973089, gamma=0.13090063275172586, lambda=1.45621216565389, learning_rate=0.506167784371001, max_depth=8, min_child_weight=3, n_estimators=550, scale_pos_weight=1.3801332124316417, subsample=0.8714582487087775; total time=   0.3s\n",
      "[CV] END alpha=5, colsample_bytree=0.233859907332918, gamma=0.07279322699345425, lambda=0.5998820002072909, learning_rate=0.43674647467221617, max_depth=6, min_child_weight=1, n_estimators=250, scale_pos_weight=2.045478582764427, subsample=0.7603418025061441; total time=   0.2s\n",
      "[CV] END alpha=5, colsample_bytree=0.233859907332918, gamma=0.07279322699345425, lambda=0.5998820002072909, learning_rate=0.43674647467221617, max_depth=6, min_child_weight=1, n_estimators=250, scale_pos_weight=2.045478582764427, subsample=0.7603418025061441; total time=   0.2s\n",
      "[CV] END alpha=5, colsample_bytree=0.233859907332918, gamma=0.07279322699345425, lambda=0.5998820002072909, learning_rate=0.43674647467221617, max_depth=6, min_child_weight=1, n_estimators=250, scale_pos_weight=2.045478582764427, subsample=0.7603418025061441; total time=   0.2s\n",
      "[CV] END alpha=5, colsample_bytree=0.233859907332918, gamma=0.07279322699345425, lambda=0.5998820002072909, learning_rate=0.43674647467221617, max_depth=6, min_child_weight=1, n_estimators=250, scale_pos_weight=2.045478582764427, subsample=0.7603418025061441; total time=   0.2s\n",
      "[CV] END alpha=15, colsample_bytree=1.1684381191073059, gamma=0.3166372142825618, lambda=1.2898316736991786, learning_rate=0.26752120749238256, max_depth=11, min_child_weight=3, n_estimators=700, scale_pos_weight=0.8716124498474163, subsample=1.119869043177324; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1684381191073059, gamma=0.3166372142825618, lambda=1.2898316736991786, learning_rate=0.26752120749238256, max_depth=11, min_child_weight=3, n_estimators=700, scale_pos_weight=0.8716124498474163, subsample=1.119869043177324; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1684381191073059, gamma=0.3166372142825618, lambda=1.2898316736991786, learning_rate=0.26752120749238256, max_depth=11, min_child_weight=3, n_estimators=700, scale_pos_weight=0.8716124498474163, subsample=1.119869043177324; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1684381191073059, gamma=0.3166372142825618, lambda=1.2898316736991786, learning_rate=0.26752120749238256, max_depth=11, min_child_weight=3, n_estimators=700, scale_pos_weight=0.8716124498474163, subsample=1.119869043177324; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.31305270676990254, gamma=0.35942986378141384, lambda=0.34889978265294436, learning_rate=0.11624712866115038, max_depth=9, min_child_weight=3, n_estimators=450, scale_pos_weight=2.2649879348959514, subsample=1.010550162613872; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.31305270676990254, gamma=0.35942986378141384, lambda=0.34889978265294436, learning_rate=0.11624712866115038, max_depth=9, min_child_weight=3, n_estimators=450, scale_pos_weight=2.2649879348959514, subsample=1.010550162613872; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.31305270676990254, gamma=0.35942986378141384, lambda=0.34889978265294436, learning_rate=0.11624712866115038, max_depth=9, min_child_weight=3, n_estimators=450, scale_pos_weight=2.2649879348959514, subsample=1.010550162613872; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.31305270676990254, gamma=0.35942986378141384, lambda=0.34889978265294436, learning_rate=0.11624712866115038, max_depth=9, min_child_weight=3, n_estimators=450, scale_pos_weight=2.2649879348959514, subsample=1.010550162613872; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.9261637528109667, gamma=0.25651172958784085, lambda=1.2821768573659478, learning_rate=0.37617718996416183, max_depth=11, min_child_weight=1, n_estimators=200, scale_pos_weight=1.6198620090069187, subsample=0.8756860425574157; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=0.9261637528109667, gamma=0.25651172958784085, lambda=1.2821768573659478, learning_rate=0.37617718996416183, max_depth=11, min_child_weight=1, n_estimators=200, scale_pos_weight=1.6198620090069187, subsample=0.8756860425574157; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=0.9261637528109667, gamma=0.25651172958784085, lambda=1.2821768573659478, learning_rate=0.37617718996416183, max_depth=11, min_child_weight=1, n_estimators=200, scale_pos_weight=1.6198620090069187, subsample=0.8756860425574157; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=0.9261637528109667, gamma=0.25651172958784085, lambda=1.2821768573659478, learning_rate=0.37617718996416183, max_depth=11, min_child_weight=1, n_estimators=200, scale_pos_weight=1.6198620090069187, subsample=0.8756860425574157; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=1.0944446479172034, gamma=0.47007177931706956, lambda=0.6234088385908694, learning_rate=0.37029256919446923, max_depth=11, min_child_weight=3, n_estimators=300, scale_pos_weight=1.3310700703897207, subsample=0.9926126912645744; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0944446479172034, gamma=0.47007177931706956, lambda=0.6234088385908694, learning_rate=0.37029256919446923, max_depth=11, min_child_weight=3, n_estimators=300, scale_pos_weight=1.3310700703897207, subsample=0.9926126912645744; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0944446479172034, gamma=0.47007177931706956, lambda=0.6234088385908694, learning_rate=0.37029256919446923, max_depth=11, min_child_weight=3, n_estimators=300, scale_pos_weight=1.3310700703897207, subsample=0.9926126912645744; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0944446479172034, gamma=0.47007177931706956, lambda=0.6234088385908694, learning_rate=0.37029256919446923, max_depth=11, min_child_weight=3, n_estimators=300, scale_pos_weight=1.3310700703897207, subsample=0.9926126912645744; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.24880129625832642, gamma=0.050930235207125474, lambda=0.7754859344141105, learning_rate=0.4899226429482615, max_depth=11, min_child_weight=1, n_estimators=400, scale_pos_weight=1.674596691877262, subsample=1.4973570090858965; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.24880129625832642, gamma=0.050930235207125474, lambda=0.7754859344141105, learning_rate=0.4899226429482615, max_depth=11, min_child_weight=1, n_estimators=400, scale_pos_weight=1.674596691877262, subsample=1.4973570090858965; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.24880129625832642, gamma=0.050930235207125474, lambda=0.7754859344141105, learning_rate=0.4899226429482615, max_depth=11, min_child_weight=1, n_estimators=400, scale_pos_weight=1.674596691877262, subsample=1.4973570090858965; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.24880129625832642, gamma=0.050930235207125474, lambda=0.7754859344141105, learning_rate=0.4899226429482615, max_depth=11, min_child_weight=1, n_estimators=400, scale_pos_weight=1.674596691877262, subsample=1.4973570090858965; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1251741358312655, gamma=0.23990863653589595, lambda=1.347603910719624, learning_rate=0.505011213372078, max_depth=10, min_child_weight=1, n_estimators=600, scale_pos_weight=1.995986361413463, subsample=1.5855304053087862; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1251741358312655, gamma=0.23990863653589595, lambda=1.347603910719624, learning_rate=0.505011213372078, max_depth=10, min_child_weight=1, n_estimators=600, scale_pos_weight=1.995986361413463, subsample=1.5855304053087862; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1251741358312655, gamma=0.23990863653589595, lambda=1.347603910719624, learning_rate=0.505011213372078, max_depth=10, min_child_weight=1, n_estimators=600, scale_pos_weight=1.995986361413463, subsample=1.5855304053087862; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1251741358312655, gamma=0.23990863653589595, lambda=1.347603910719624, learning_rate=0.505011213372078, max_depth=10, min_child_weight=1, n_estimators=600, scale_pos_weight=1.995986361413463, subsample=1.5855304053087862; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9856387560640631, gamma=0.38155250394406104, lambda=1.0830655973018355, learning_rate=0.07171799587407716, max_depth=10, min_child_weight=3, n_estimators=350, scale_pos_weight=1.7480007304537897, subsample=0.6313158255834624; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.9856387560640631, gamma=0.38155250394406104, lambda=1.0830655973018355, learning_rate=0.07171799587407716, max_depth=10, min_child_weight=3, n_estimators=350, scale_pos_weight=1.7480007304537897, subsample=0.6313158255834624; total time=   0.6s\n",
      "[CV] END alpha=15, colsample_bytree=0.9856387560640631, gamma=0.38155250394406104, lambda=1.0830655973018355, learning_rate=0.07171799587407716, max_depth=10, min_child_weight=3, n_estimators=350, scale_pos_weight=1.7480007304537897, subsample=0.6313158255834624; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.9856387560640631, gamma=0.38155250394406104, lambda=1.0830655973018355, learning_rate=0.07171799587407716, max_depth=10, min_child_weight=3, n_estimators=350, scale_pos_weight=1.7480007304537897, subsample=0.6313158255834624; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=1.1142104669405681, gamma=0.3410231436700447, lambda=0.3346988632033463, learning_rate=0.4260360360536273, max_depth=7, min_child_weight=1, n_estimators=200, scale_pos_weight=1.7384855305388591, subsample=1.5357431385874378; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1142104669405681, gamma=0.3410231436700447, lambda=0.3346988632033463, learning_rate=0.4260360360536273, max_depth=7, min_child_weight=1, n_estimators=200, scale_pos_weight=1.7384855305388591, subsample=1.5357431385874378; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1142104669405681, gamma=0.3410231436700447, lambda=0.3346988632033463, learning_rate=0.4260360360536273, max_depth=7, min_child_weight=1, n_estimators=200, scale_pos_weight=1.7384855305388591, subsample=1.5357431385874378; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1142104669405681, gamma=0.3410231436700447, lambda=0.3346988632033463, learning_rate=0.4260360360536273, max_depth=7, min_child_weight=1, n_estimators=200, scale_pos_weight=1.7384855305388591, subsample=1.5357431385874378; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.41810872105781866, gamma=0.35312946851283716, lambda=1.1820133277203104, learning_rate=0.4106455738496445, max_depth=6, min_child_weight=3, n_estimators=300, scale_pos_weight=2.660452558714036, subsample=1.1265533564588914; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.41810872105781866, gamma=0.35312946851283716, lambda=1.1820133277203104, learning_rate=0.4106455738496445, max_depth=6, min_child_weight=3, n_estimators=300, scale_pos_weight=2.660452558714036, subsample=1.1265533564588914; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.41810872105781866, gamma=0.35312946851283716, lambda=1.1820133277203104, learning_rate=0.4106455738496445, max_depth=6, min_child_weight=3, n_estimators=300, scale_pos_weight=2.660452558714036, subsample=1.1265533564588914; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.41810872105781866, gamma=0.35312946851283716, lambda=1.1820133277203104, learning_rate=0.4106455738496445, max_depth=6, min_child_weight=3, n_estimators=300, scale_pos_weight=2.660452558714036, subsample=1.1265533564588914; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7131363426275865, gamma=0.06731145474266931, lambda=1.2367648987532323, learning_rate=0.01660644910641828, max_depth=5, min_child_weight=1, n_estimators=500, scale_pos_weight=0.8219360279757073, subsample=1.1507077913847898; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7131363426275865, gamma=0.06731145474266931, lambda=1.2367648987532323, learning_rate=0.01660644910641828, max_depth=5, min_child_weight=1, n_estimators=500, scale_pos_weight=0.8219360279757073, subsample=1.1507077913847898; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7131363426275865, gamma=0.06731145474266931, lambda=1.2367648987532323, learning_rate=0.01660644910641828, max_depth=5, min_child_weight=1, n_estimators=500, scale_pos_weight=0.8219360279757073, subsample=1.1507077913847898; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7131363426275865, gamma=0.06731145474266931, lambda=1.2367648987532323, learning_rate=0.01660644910641828, max_depth=5, min_child_weight=1, n_estimators=500, scale_pos_weight=0.8219360279757073, subsample=1.1507077913847898; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.170248374088005, gamma=0.15139945023703033, lambda=1.1803973553993587, learning_rate=0.35954617235781944, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=2.1140583385415592, subsample=1.4216386329277044; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.170248374088005, gamma=0.15139945023703033, lambda=1.1803973553993587, learning_rate=0.35954617235781944, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=2.1140583385415592, subsample=1.4216386329277044; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.170248374088005, gamma=0.15139945023703033, lambda=1.1803973553993587, learning_rate=0.35954617235781944, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=2.1140583385415592, subsample=1.4216386329277044; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.170248374088005, gamma=0.15139945023703033, lambda=1.1803973553993587, learning_rate=0.35954617235781944, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=2.1140583385415592, subsample=1.4216386329277044; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.8876768096984715, gamma=0.23456958325071758, lambda=0.4350380243391709, learning_rate=0.11546559902865282, max_depth=6, min_child_weight=1, n_estimators=350, scale_pos_weight=2.589809490362584, subsample=0.6651093063600101; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.8876768096984715, gamma=0.23456958325071758, lambda=0.4350380243391709, learning_rate=0.11546559902865282, max_depth=6, min_child_weight=1, n_estimators=350, scale_pos_weight=2.589809490362584, subsample=0.6651093063600101; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.8876768096984715, gamma=0.23456958325071758, lambda=0.4350380243391709, learning_rate=0.11546559902865282, max_depth=6, min_child_weight=1, n_estimators=350, scale_pos_weight=2.589809490362584, subsample=0.6651093063600101; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.8876768096984715, gamma=0.23456958325071758, lambda=0.4350380243391709, learning_rate=0.11546559902865282, max_depth=6, min_child_weight=1, n_estimators=350, scale_pos_weight=2.589809490362584, subsample=0.6651093063600101; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.3728663290293352, gamma=0.026458715056680293, lambda=0.9439054376995922, learning_rate=0.040920930901702283, max_depth=5, min_child_weight=3, n_estimators=750, scale_pos_weight=1.664819321477025, subsample=0.8728903956910835; total time=   0.4s\n",
      "[CV] END alpha=25, colsample_bytree=0.3728663290293352, gamma=0.026458715056680293, lambda=0.9439054376995922, learning_rate=0.040920930901702283, max_depth=5, min_child_weight=3, n_estimators=750, scale_pos_weight=1.664819321477025, subsample=0.8728903956910835; total time=   0.4s\n",
      "[CV] END alpha=25, colsample_bytree=0.3728663290293352, gamma=0.026458715056680293, lambda=0.9439054376995922, learning_rate=0.040920930901702283, max_depth=5, min_child_weight=3, n_estimators=750, scale_pos_weight=1.664819321477025, subsample=0.8728903956910835; total time=   0.4s\n",
      "[CV] END alpha=25, colsample_bytree=0.3728663290293352, gamma=0.026458715056680293, lambda=0.9439054376995922, learning_rate=0.040920930901702283, max_depth=5, min_child_weight=3, n_estimators=750, scale_pos_weight=1.664819321477025, subsample=0.8728903956910835; total time=   0.4s\n",
      "[CV] END alpha=20, colsample_bytree=0.5232803488100948, gamma=0.02656812836955119, lambda=0.9699228884353737, learning_rate=0.013887824309776689, max_depth=8, min_child_weight=3, n_estimators=500, scale_pos_weight=1.4305720172666305, subsample=0.7318286907129143; total time=   0.7s\n",
      "[CV] END alpha=20, colsample_bytree=0.5232803488100948, gamma=0.02656812836955119, lambda=0.9699228884353737, learning_rate=0.013887824309776689, max_depth=8, min_child_weight=3, n_estimators=500, scale_pos_weight=1.4305720172666305, subsample=0.7318286907129143; total time=   0.6s\n",
      "[CV] END alpha=20, colsample_bytree=0.5232803488100948, gamma=0.02656812836955119, lambda=0.9699228884353737, learning_rate=0.013887824309776689, max_depth=8, min_child_weight=3, n_estimators=500, scale_pos_weight=1.4305720172666305, subsample=0.7318286907129143; total time=   0.7s\n",
      "[CV] END alpha=20, colsample_bytree=0.5232803488100948, gamma=0.02656812836955119, lambda=0.9699228884353737, learning_rate=0.013887824309776689, max_depth=8, min_child_weight=3, n_estimators=500, scale_pos_weight=1.4305720172666305, subsample=0.7318286907129143; total time=   0.7s\n",
      "[CV] END alpha=25, colsample_bytree=0.5536091411468893, gamma=0.1496739350402425, lambda=0.15713741720351693, learning_rate=0.15093778551933834, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=1.6851673890023728, subsample=1.073599009048827; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5536091411468893, gamma=0.1496739350402425, lambda=0.15713741720351693, learning_rate=0.15093778551933834, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=1.6851673890023728, subsample=1.073599009048827; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5536091411468893, gamma=0.1496739350402425, lambda=0.15713741720351693, learning_rate=0.15093778551933834, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=1.6851673890023728, subsample=1.073599009048827; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5536091411468893, gamma=0.1496739350402425, lambda=0.15713741720351693, learning_rate=0.15093778551933834, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=1.6851673890023728, subsample=1.073599009048827; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8197267628388611, gamma=0.002751330577285549, lambda=0.9426602049531319, learning_rate=0.036997826009839356, max_depth=6, min_child_weight=1, n_estimators=750, scale_pos_weight=2.1962258407309445, subsample=1.2045695281006146; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8197267628388611, gamma=0.002751330577285549, lambda=0.9426602049531319, learning_rate=0.036997826009839356, max_depth=6, min_child_weight=1, n_estimators=750, scale_pos_weight=2.1962258407309445, subsample=1.2045695281006146; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8197267628388611, gamma=0.002751330577285549, lambda=0.9426602049531319, learning_rate=0.036997826009839356, max_depth=6, min_child_weight=1, n_estimators=750, scale_pos_weight=2.1962258407309445, subsample=1.2045695281006146; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8197267628388611, gamma=0.002751330577285549, lambda=0.9426602049531319, learning_rate=0.036997826009839356, max_depth=6, min_child_weight=1, n_estimators=750, scale_pos_weight=2.1962258407309445, subsample=1.2045695281006146; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.5394498310719988, gamma=0.3022888201069062, lambda=0.3445588730575699, learning_rate=0.04618121001391561, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=2.16195950915331, subsample=0.7718637500821799; total time=   0.8s\n",
      "[CV] END alpha=10, colsample_bytree=0.5394498310719988, gamma=0.3022888201069062, lambda=0.3445588730575699, learning_rate=0.04618121001391561, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=2.16195950915331, subsample=0.7718637500821799; total time=   0.8s\n",
      "[CV] END alpha=10, colsample_bytree=0.5394498310719988, gamma=0.3022888201069062, lambda=0.3445588730575699, learning_rate=0.04618121001391561, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=2.16195950915331, subsample=0.7718637500821799; total time=   0.8s\n",
      "[CV] END alpha=10, colsample_bytree=0.5394498310719988, gamma=0.3022888201069062, lambda=0.3445588730575699, learning_rate=0.04618121001391561, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=2.16195950915331, subsample=0.7718637500821799; total time=   0.8s\n",
      "[CV] END alpha=25, colsample_bytree=0.7270694486084022, gamma=0.47535794771824313, lambda=0.3566350531750871, learning_rate=0.3076000008817449, max_depth=8, min_child_weight=1, n_estimators=700, scale_pos_weight=1.8586730351393248, subsample=0.9543635742732367; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.7270694486084022, gamma=0.47535794771824313, lambda=0.3566350531750871, learning_rate=0.3076000008817449, max_depth=8, min_child_weight=1, n_estimators=700, scale_pos_weight=1.8586730351393248, subsample=0.9543635742732367; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.7270694486084022, gamma=0.47535794771824313, lambda=0.3566350531750871, learning_rate=0.3076000008817449, max_depth=8, min_child_weight=1, n_estimators=700, scale_pos_weight=1.8586730351393248, subsample=0.9543635742732367; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.7270694486084022, gamma=0.47535794771824313, lambda=0.3566350531750871, learning_rate=0.3076000008817449, max_depth=8, min_child_weight=1, n_estimators=700, scale_pos_weight=1.8586730351393248, subsample=0.9543635742732367; total time=   0.4s\n",
      "[CV] END alpha=5, colsample_bytree=0.7091793994902484, gamma=0.09106564927739846, lambda=0.20421982379156395, learning_rate=0.04246406888415837, max_depth=8, min_child_weight=1, n_estimators=750, scale_pos_weight=1.7587932001292177, subsample=0.7933622682893346; total time=   3.6s\n",
      "[CV] END alpha=5, colsample_bytree=0.7091793994902484, gamma=0.09106564927739846, lambda=0.20421982379156395, learning_rate=0.04246406888415837, max_depth=8, min_child_weight=1, n_estimators=750, scale_pos_weight=1.7587932001292177, subsample=0.7933622682893346; total time=   2.6s\n",
      "[CV] END alpha=5, colsample_bytree=0.7091793994902484, gamma=0.09106564927739846, lambda=0.20421982379156395, learning_rate=0.04246406888415837, max_depth=8, min_child_weight=1, n_estimators=750, scale_pos_weight=1.7587932001292177, subsample=0.7933622682893346; total time=   1.9s\n",
      "[CV] END alpha=5, colsample_bytree=0.7091793994902484, gamma=0.09106564927739846, lambda=0.20421982379156395, learning_rate=0.04246406888415837, max_depth=8, min_child_weight=1, n_estimators=750, scale_pos_weight=1.7587932001292177, subsample=0.7933622682893346; total time=   2.3s\n",
      "[CV] END alpha=5, colsample_bytree=0.7555393193152722, gamma=0.4824058926395222, lambda=0.4899688681508602, learning_rate=0.10444105903386096, max_depth=5, min_child_weight=1, n_estimators=300, scale_pos_weight=1.1556655738648753, subsample=0.6910921632158492; total time=   0.6s\n",
      "[CV] END alpha=5, colsample_bytree=0.7555393193152722, gamma=0.4824058926395222, lambda=0.4899688681508602, learning_rate=0.10444105903386096, max_depth=5, min_child_weight=1, n_estimators=300, scale_pos_weight=1.1556655738648753, subsample=0.6910921632158492; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.7555393193152722, gamma=0.4824058926395222, lambda=0.4899688681508602, learning_rate=0.10444105903386096, max_depth=5, min_child_weight=1, n_estimators=300, scale_pos_weight=1.1556655738648753, subsample=0.6910921632158492; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.7555393193152722, gamma=0.4824058926395222, lambda=0.4899688681508602, learning_rate=0.10444105903386096, max_depth=5, min_child_weight=1, n_estimators=300, scale_pos_weight=1.1556655738648753, subsample=0.6910921632158492; total time=   0.4s\n",
      "[CV] END alpha=10, colsample_bytree=0.7635028663115311, gamma=0.2096972112646014, lambda=0.8028877298825647, learning_rate=0.4652346286889537, max_depth=10, min_child_weight=3, n_estimators=550, scale_pos_weight=2.7579125812096255, subsample=1.5547523160736394; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7635028663115311, gamma=0.2096972112646014, lambda=0.8028877298825647, learning_rate=0.4652346286889537, max_depth=10, min_child_weight=3, n_estimators=550, scale_pos_weight=2.7579125812096255, subsample=1.5547523160736394; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7635028663115311, gamma=0.2096972112646014, lambda=0.8028877298825647, learning_rate=0.4652346286889537, max_depth=10, min_child_weight=3, n_estimators=550, scale_pos_weight=2.7579125812096255, subsample=1.5547523160736394; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7635028663115311, gamma=0.2096972112646014, lambda=0.8028877298825647, learning_rate=0.4652346286889537, max_depth=10, min_child_weight=3, n_estimators=550, scale_pos_weight=2.7579125812096255, subsample=1.5547523160736394; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.4079180386205797, gamma=0.3984093873599385, lambda=0.24338820238826914, learning_rate=0.14463784604254698, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=2.672153682427571, subsample=1.3826269736883325; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.4079180386205797, gamma=0.3984093873599385, lambda=0.24338820238826914, learning_rate=0.14463784604254698, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=2.672153682427571, subsample=1.3826269736883325; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.4079180386205797, gamma=0.3984093873599385, lambda=0.24338820238826914, learning_rate=0.14463784604254698, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=2.672153682427571, subsample=1.3826269736883325; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.4079180386205797, gamma=0.3984093873599385, lambda=0.24338820238826914, learning_rate=0.14463784604254698, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=2.672153682427571, subsample=1.3826269736883325; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.771870932298548, gamma=0.10776791961638704, lambda=0.8122905985309881, learning_rate=0.30861866966229345, max_depth=5, min_child_weight=1, n_estimators=300, scale_pos_weight=2.591915607050098, subsample=1.5946491141723536; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.771870932298548, gamma=0.10776791961638704, lambda=0.8122905985309881, learning_rate=0.30861866966229345, max_depth=5, min_child_weight=1, n_estimators=300, scale_pos_weight=2.591915607050098, subsample=1.5946491141723536; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.771870932298548, gamma=0.10776791961638704, lambda=0.8122905985309881, learning_rate=0.30861866966229345, max_depth=5, min_child_weight=1, n_estimators=300, scale_pos_weight=2.591915607050098, subsample=1.5946491141723536; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.771870932298548, gamma=0.10776791961638704, lambda=0.8122905985309881, learning_rate=0.30861866966229345, max_depth=5, min_child_weight=1, n_estimators=300, scale_pos_weight=2.591915607050098, subsample=1.5946491141723536; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4888403193237491, gamma=0.28886354745050985, lambda=0.07810359176353232, learning_rate=0.48290900554195954, max_depth=10, min_child_weight=1, n_estimators=600, scale_pos_weight=1.8235973073652536, subsample=1.5261425054701023; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4888403193237491, gamma=0.28886354745050985, lambda=0.07810359176353232, learning_rate=0.48290900554195954, max_depth=10, min_child_weight=1, n_estimators=600, scale_pos_weight=1.8235973073652536, subsample=1.5261425054701023; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4888403193237491, gamma=0.28886354745050985, lambda=0.07810359176353232, learning_rate=0.48290900554195954, max_depth=10, min_child_weight=1, n_estimators=600, scale_pos_weight=1.8235973073652536, subsample=1.5261425054701023; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4888403193237491, gamma=0.28886354745050985, lambda=0.07810359176353232, learning_rate=0.48290900554195954, max_depth=10, min_child_weight=1, n_estimators=600, scale_pos_weight=1.8235973073652536, subsample=1.5261425054701023; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.3415773764736983, gamma=0.26335585881540047, lambda=1.1894345214995623, learning_rate=0.07510568066045907, max_depth=6, min_child_weight=3, n_estimators=400, scale_pos_weight=0.8803907540713304, subsample=0.6826996640090318; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.3415773764736983, gamma=0.26335585881540047, lambda=1.1894345214995623, learning_rate=0.07510568066045907, max_depth=6, min_child_weight=3, n_estimators=400, scale_pos_weight=0.8803907540713304, subsample=0.6826996640090318; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.3415773764736983, gamma=0.26335585881540047, lambda=1.1894345214995623, learning_rate=0.07510568066045907, max_depth=6, min_child_weight=3, n_estimators=400, scale_pos_weight=0.8803907540713304, subsample=0.6826996640090318; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.3415773764736983, gamma=0.26335585881540047, lambda=1.1894345214995623, learning_rate=0.07510568066045907, max_depth=6, min_child_weight=3, n_estimators=400, scale_pos_weight=0.8803907540713304, subsample=0.6826996640090318; total time=   0.2s\n",
      "[CV] END alpha=15, colsample_bytree=0.512570529967624, gamma=0.4764866941498746, lambda=0.7595779997670549, learning_rate=0.30040117122648763, max_depth=11, min_child_weight=3, n_estimators=750, scale_pos_weight=1.2487473623819825, subsample=1.5300516875331878; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.512570529967624, gamma=0.4764866941498746, lambda=0.7595779997670549, learning_rate=0.30040117122648763, max_depth=11, min_child_weight=3, n_estimators=750, scale_pos_weight=1.2487473623819825, subsample=1.5300516875331878; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.512570529967624, gamma=0.4764866941498746, lambda=0.7595779997670549, learning_rate=0.30040117122648763, max_depth=11, min_child_weight=3, n_estimators=750, scale_pos_weight=1.2487473623819825, subsample=1.5300516875331878; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.512570529967624, gamma=0.4764866941498746, lambda=0.7595779997670549, learning_rate=0.30040117122648763, max_depth=11, min_child_weight=3, n_estimators=750, scale_pos_weight=1.2487473623819825, subsample=1.5300516875331878; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0961451422591735, gamma=0.06039321455827812, lambda=0.2614603983455463, learning_rate=0.2626696785870804, max_depth=9, min_child_weight=3, n_estimators=350, scale_pos_weight=2.4570150710941157, subsample=1.4293059646062807; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0961451422591735, gamma=0.06039321455827812, lambda=0.2614603983455463, learning_rate=0.2626696785870804, max_depth=9, min_child_weight=3, n_estimators=350, scale_pos_weight=2.4570150710941157, subsample=1.4293059646062807; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0961451422591735, gamma=0.06039321455827812, lambda=0.2614603983455463, learning_rate=0.2626696785870804, max_depth=9, min_child_weight=3, n_estimators=350, scale_pos_weight=2.4570150710941157, subsample=1.4293059646062807; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0961451422591735, gamma=0.06039321455827812, lambda=0.2614603983455463, learning_rate=0.2626696785870804, max_depth=9, min_child_weight=3, n_estimators=350, scale_pos_weight=2.4570150710941157, subsample=1.4293059646062807; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.4754728028576541, gamma=0.4099214899428764, lambda=0.9113715930828208, learning_rate=0.10256377088891293, max_depth=9, min_child_weight=1, n_estimators=400, scale_pos_weight=1.0095890341099514, subsample=1.4873037373230398; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.4754728028576541, gamma=0.4099214899428764, lambda=0.9113715930828208, learning_rate=0.10256377088891293, max_depth=9, min_child_weight=1, n_estimators=400, scale_pos_weight=1.0095890341099514, subsample=1.4873037373230398; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.4754728028576541, gamma=0.4099214899428764, lambda=0.9113715930828208, learning_rate=0.10256377088891293, max_depth=9, min_child_weight=1, n_estimators=400, scale_pos_weight=1.0095890341099514, subsample=1.4873037373230398; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.4754728028576541, gamma=0.4099214899428764, lambda=0.9113715930828208, learning_rate=0.10256377088891293, max_depth=9, min_child_weight=1, n_estimators=400, scale_pos_weight=1.0095890341099514, subsample=1.4873037373230398; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.674372842656189, gamma=0.2536372881671054, lambda=0.51758895278147, learning_rate=0.4135545351106495, max_depth=10, min_child_weight=3, n_estimators=550, scale_pos_weight=2.4852072635194604, subsample=0.7318356660034108; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.674372842656189, gamma=0.2536372881671054, lambda=0.51758895278147, learning_rate=0.4135545351106495, max_depth=10, min_child_weight=3, n_estimators=550, scale_pos_weight=2.4852072635194604, subsample=0.7318356660034108; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.674372842656189, gamma=0.2536372881671054, lambda=0.51758895278147, learning_rate=0.4135545351106495, max_depth=10, min_child_weight=3, n_estimators=550, scale_pos_weight=2.4852072635194604, subsample=0.7318356660034108; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.674372842656189, gamma=0.2536372881671054, lambda=0.51758895278147, learning_rate=0.4135545351106495, max_depth=10, min_child_weight=3, n_estimators=550, scale_pos_weight=2.4852072635194604, subsample=0.7318356660034108; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.8426990720312035, gamma=0.033465228406425684, lambda=0.1677530247533075, learning_rate=0.17665381964737908, max_depth=10, min_child_weight=1, n_estimators=600, scale_pos_weight=1.5661986306066886, subsample=1.458062925904966; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.8426990720312035, gamma=0.033465228406425684, lambda=0.1677530247533075, learning_rate=0.17665381964737908, max_depth=10, min_child_weight=1, n_estimators=600, scale_pos_weight=1.5661986306066886, subsample=1.458062925904966; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.8426990720312035, gamma=0.033465228406425684, lambda=0.1677530247533075, learning_rate=0.17665381964737908, max_depth=10, min_child_weight=1, n_estimators=600, scale_pos_weight=1.5661986306066886, subsample=1.458062925904966; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.8426990720312035, gamma=0.033465228406425684, lambda=0.1677530247533075, learning_rate=0.17665381964737908, max_depth=10, min_child_weight=1, n_estimators=600, scale_pos_weight=1.5661986306066886, subsample=1.458062925904966; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0528162307302344, gamma=0.07050482028227645, lambda=0.018354731544333813, learning_rate=0.4602667305801503, max_depth=5, min_child_weight=3, n_estimators=550, scale_pos_weight=2.2630242500663713, subsample=1.5217521604528503; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0528162307302344, gamma=0.07050482028227645, lambda=0.018354731544333813, learning_rate=0.4602667305801503, max_depth=5, min_child_weight=3, n_estimators=550, scale_pos_weight=2.2630242500663713, subsample=1.5217521604528503; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0528162307302344, gamma=0.07050482028227645, lambda=0.018354731544333813, learning_rate=0.4602667305801503, max_depth=5, min_child_weight=3, n_estimators=550, scale_pos_weight=2.2630242500663713, subsample=1.5217521604528503; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0528162307302344, gamma=0.07050482028227645, lambda=0.018354731544333813, learning_rate=0.4602667305801503, max_depth=5, min_child_weight=3, n_estimators=550, scale_pos_weight=2.2630242500663713, subsample=1.5217521604528503; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.160412355114169, gamma=0.10934926934822631, lambda=0.25747956225956126, learning_rate=0.3402455841847841, max_depth=8, min_child_weight=3, n_estimators=750, scale_pos_weight=1.4572988637779885, subsample=1.062050691361304; total time=   0.1s\n",
      "[CV] END alpha=10, colsample_bytree=1.160412355114169, gamma=0.10934926934822631, lambda=0.25747956225956126, learning_rate=0.3402455841847841, max_depth=8, min_child_weight=3, n_estimators=750, scale_pos_weight=1.4572988637779885, subsample=1.062050691361304; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.160412355114169, gamma=0.10934926934822631, lambda=0.25747956225956126, learning_rate=0.3402455841847841, max_depth=8, min_child_weight=3, n_estimators=750, scale_pos_weight=1.4572988637779885, subsample=1.062050691361304; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.160412355114169, gamma=0.10934926934822631, lambda=0.25747956225956126, learning_rate=0.3402455841847841, max_depth=8, min_child_weight=3, n_estimators=750, scale_pos_weight=1.4572988637779885, subsample=1.062050691361304; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1784263836621895, gamma=0.30551011317576154, lambda=0.44776639474663443, learning_rate=0.484742632814736, max_depth=6, min_child_weight=3, n_estimators=200, scale_pos_weight=1.6996920580293722, subsample=1.4583141299267997; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1784263836621895, gamma=0.30551011317576154, lambda=0.44776639474663443, learning_rate=0.484742632814736, max_depth=6, min_child_weight=3, n_estimators=200, scale_pos_weight=1.6996920580293722, subsample=1.4583141299267997; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1784263836621895, gamma=0.30551011317576154, lambda=0.44776639474663443, learning_rate=0.484742632814736, max_depth=6, min_child_weight=3, n_estimators=200, scale_pos_weight=1.6996920580293722, subsample=1.4583141299267997; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1784263836621895, gamma=0.30551011317576154, lambda=0.44776639474663443, learning_rate=0.484742632814736, max_depth=6, min_child_weight=3, n_estimators=200, scale_pos_weight=1.6996920580293722, subsample=1.4583141299267997; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0315276466198628, gamma=0.4912189939816661, lambda=1.2533400336134535, learning_rate=0.01619570236330963, max_depth=9, min_child_weight=1, n_estimators=300, scale_pos_weight=1.0103018885306967, subsample=1.2630541205468138; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0315276466198628, gamma=0.4912189939816661, lambda=1.2533400336134535, learning_rate=0.01619570236330963, max_depth=9, min_child_weight=1, n_estimators=300, scale_pos_weight=1.0103018885306967, subsample=1.2630541205468138; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0315276466198628, gamma=0.4912189939816661, lambda=1.2533400336134535, learning_rate=0.01619570236330963, max_depth=9, min_child_weight=1, n_estimators=300, scale_pos_weight=1.0103018885306967, subsample=1.2630541205468138; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0315276466198628, gamma=0.4912189939816661, lambda=1.2533400336134535, learning_rate=0.01619570236330963, max_depth=9, min_child_weight=1, n_estimators=300, scale_pos_weight=1.0103018885306967, subsample=1.2630541205468138; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.599125722651052, gamma=0.4760047878927309, lambda=1.3651243694053397, learning_rate=0.1262968748945869, max_depth=6, min_child_weight=3, n_estimators=350, scale_pos_weight=1.7741114611762707, subsample=1.5656848267860437; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.599125722651052, gamma=0.4760047878927309, lambda=1.3651243694053397, learning_rate=0.1262968748945869, max_depth=6, min_child_weight=3, n_estimators=350, scale_pos_weight=1.7741114611762707, subsample=1.5656848267860437; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.599125722651052, gamma=0.4760047878927309, lambda=1.3651243694053397, learning_rate=0.1262968748945869, max_depth=6, min_child_weight=3, n_estimators=350, scale_pos_weight=1.7741114611762707, subsample=1.5656848267860437; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.599125722651052, gamma=0.4760047878927309, lambda=1.3651243694053397, learning_rate=0.1262968748945869, max_depth=6, min_child_weight=3, n_estimators=350, scale_pos_weight=1.7741114611762707, subsample=1.5656848267860437; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.21088341644881875, gamma=0.07361557678141989, lambda=0.9085074717492256, learning_rate=0.4765335648279705, max_depth=8, min_child_weight=1, n_estimators=600, scale_pos_weight=1.8953073912957743, subsample=1.041497617584897; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.21088341644881875, gamma=0.07361557678141989, lambda=0.9085074717492256, learning_rate=0.4765335648279705, max_depth=8, min_child_weight=1, n_estimators=600, scale_pos_weight=1.8953073912957743, subsample=1.041497617584897; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.21088341644881875, gamma=0.07361557678141989, lambda=0.9085074717492256, learning_rate=0.4765335648279705, max_depth=8, min_child_weight=1, n_estimators=600, scale_pos_weight=1.8953073912957743, subsample=1.041497617584897; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.21088341644881875, gamma=0.07361557678141989, lambda=0.9085074717492256, learning_rate=0.4765335648279705, max_depth=8, min_child_weight=1, n_estimators=600, scale_pos_weight=1.8953073912957743, subsample=1.041497617584897; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1891196852306916, gamma=0.13662606982819298, lambda=1.05856986562647, learning_rate=0.2341946612400707, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=1.272058500079164, subsample=1.408950829428294; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1891196852306916, gamma=0.13662606982819298, lambda=1.05856986562647, learning_rate=0.2341946612400707, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=1.272058500079164, subsample=1.408950829428294; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1891196852306916, gamma=0.13662606982819298, lambda=1.05856986562647, learning_rate=0.2341946612400707, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=1.272058500079164, subsample=1.408950829428294; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1891196852306916, gamma=0.13662606982819298, lambda=1.05856986562647, learning_rate=0.2341946612400707, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=1.272058500079164, subsample=1.408950829428294; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.40171086201337286, gamma=0.43267421057049515, lambda=1.1792907670695956, learning_rate=0.22853061051988866, max_depth=9, min_child_weight=1, n_estimators=200, scale_pos_weight=1.2629403594811657, subsample=0.7131137223297079; total time=   0.3s\n",
      "[CV] END alpha=15, colsample_bytree=0.40171086201337286, gamma=0.43267421057049515, lambda=1.1792907670695956, learning_rate=0.22853061051988866, max_depth=9, min_child_weight=1, n_estimators=200, scale_pos_weight=1.2629403594811657, subsample=0.7131137223297079; total time=   0.2s\n",
      "[CV] END alpha=15, colsample_bytree=0.40171086201337286, gamma=0.43267421057049515, lambda=1.1792907670695956, learning_rate=0.22853061051988866, max_depth=9, min_child_weight=1, n_estimators=200, scale_pos_weight=1.2629403594811657, subsample=0.7131137223297079; total time=   0.2s\n",
      "[CV] END alpha=15, colsample_bytree=0.40171086201337286, gamma=0.43267421057049515, lambda=1.1792907670695956, learning_rate=0.22853061051988866, max_depth=9, min_child_weight=1, n_estimators=200, scale_pos_weight=1.2629403594811657, subsample=0.7131137223297079; total time=   0.1s\n",
      "[CV] END alpha=25, colsample_bytree=1.1322619617563954, gamma=0.37986646441234895, lambda=0.3085335193507455, learning_rate=0.44155593626719336, max_depth=6, min_child_weight=1, n_estimators=700, scale_pos_weight=1.2890765197456737, subsample=1.421022663694406; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1322619617563954, gamma=0.37986646441234895, lambda=0.3085335193507455, learning_rate=0.44155593626719336, max_depth=6, min_child_weight=1, n_estimators=700, scale_pos_weight=1.2890765197456737, subsample=1.421022663694406; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1322619617563954, gamma=0.37986646441234895, lambda=0.3085335193507455, learning_rate=0.44155593626719336, max_depth=6, min_child_weight=1, n_estimators=700, scale_pos_weight=1.2890765197456737, subsample=1.421022663694406; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.1322619617563954, gamma=0.37986646441234895, lambda=0.3085335193507455, learning_rate=0.44155593626719336, max_depth=6, min_child_weight=1, n_estimators=700, scale_pos_weight=1.2890765197456737, subsample=1.421022663694406; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9567513853085063, gamma=0.3291331549876761, lambda=1.0531799810652662, learning_rate=0.2554645291870609, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=2.2641753822843564, subsample=1.2615415971153996; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9567513853085063, gamma=0.3291331549876761, lambda=1.0531799810652662, learning_rate=0.2554645291870609, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=2.2641753822843564, subsample=1.2615415971153996; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9567513853085063, gamma=0.3291331549876761, lambda=1.0531799810652662, learning_rate=0.2554645291870609, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=2.2641753822843564, subsample=1.2615415971153996; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9567513853085063, gamma=0.3291331549876761, lambda=1.0531799810652662, learning_rate=0.2554645291870609, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=2.2641753822843564, subsample=1.2615415971153996; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.8218079947854853, gamma=0.20164751035916556, lambda=0.9042218140171412, learning_rate=0.1048483657842094, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=2.2129938157340394, subsample=0.7300235606765139; total time=   0.7s\n",
      "[CV] END alpha=10, colsample_bytree=0.8218079947854853, gamma=0.20164751035916556, lambda=0.9042218140171412, learning_rate=0.1048483657842094, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=2.2129938157340394, subsample=0.7300235606765139; total time=   0.8s\n",
      "[CV] END alpha=10, colsample_bytree=0.8218079947854853, gamma=0.20164751035916556, lambda=0.9042218140171412, learning_rate=0.1048483657842094, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=2.2129938157340394, subsample=0.7300235606765139; total time=   0.7s\n",
      "[CV] END alpha=10, colsample_bytree=0.8218079947854853, gamma=0.20164751035916556, lambda=0.9042218140171412, learning_rate=0.1048483657842094, max_depth=10, min_child_weight=1, n_estimators=200, scale_pos_weight=2.2129938157340394, subsample=0.7300235606765139; total time=   0.6s\n",
      "[CV] END alpha=15, colsample_bytree=1.0328063429688397, gamma=0.21184997249112425, lambda=0.7469452402122394, learning_rate=0.3211023229468699, max_depth=7, min_child_weight=1, n_estimators=550, scale_pos_weight=2.7990551003691033, subsample=1.0477075695968758; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0328063429688397, gamma=0.21184997249112425, lambda=0.7469452402122394, learning_rate=0.3211023229468699, max_depth=7, min_child_weight=1, n_estimators=550, scale_pos_weight=2.7990551003691033, subsample=1.0477075695968758; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0328063429688397, gamma=0.21184997249112425, lambda=0.7469452402122394, learning_rate=0.3211023229468699, max_depth=7, min_child_weight=1, n_estimators=550, scale_pos_weight=2.7990551003691033, subsample=1.0477075695968758; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0328063429688397, gamma=0.21184997249112425, lambda=0.7469452402122394, learning_rate=0.3211023229468699, max_depth=7, min_child_weight=1, n_estimators=550, scale_pos_weight=2.7990551003691033, subsample=1.0477075695968758; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0114721620883456, gamma=0.19195247032628904, lambda=1.2161698173011835, learning_rate=0.32092563632134935, max_depth=11, min_child_weight=3, n_estimators=700, scale_pos_weight=1.612629032633238, subsample=1.241011316292257; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0114721620883456, gamma=0.19195247032628904, lambda=1.2161698173011835, learning_rate=0.32092563632134935, max_depth=11, min_child_weight=3, n_estimators=700, scale_pos_weight=1.612629032633238, subsample=1.241011316292257; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0114721620883456, gamma=0.19195247032628904, lambda=1.2161698173011835, learning_rate=0.32092563632134935, max_depth=11, min_child_weight=3, n_estimators=700, scale_pos_weight=1.612629032633238, subsample=1.241011316292257; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0114721620883456, gamma=0.19195247032628904, lambda=1.2161698173011835, learning_rate=0.32092563632134935, max_depth=11, min_child_weight=3, n_estimators=700, scale_pos_weight=1.612629032633238, subsample=1.241011316292257; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5221594112704546, gamma=0.037939685089066144, lambda=0.8855281859314925, learning_rate=0.48612041136001916, max_depth=7, min_child_weight=3, n_estimators=350, scale_pos_weight=1.4782245663385252, subsample=1.300649868838617; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5221594112704546, gamma=0.037939685089066144, lambda=0.8855281859314925, learning_rate=0.48612041136001916, max_depth=7, min_child_weight=3, n_estimators=350, scale_pos_weight=1.4782245663385252, subsample=1.300649868838617; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5221594112704546, gamma=0.037939685089066144, lambda=0.8855281859314925, learning_rate=0.48612041136001916, max_depth=7, min_child_weight=3, n_estimators=350, scale_pos_weight=1.4782245663385252, subsample=1.300649868838617; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5221594112704546, gamma=0.037939685089066144, lambda=0.8855281859314925, learning_rate=0.48612041136001916, max_depth=7, min_child_weight=3, n_estimators=350, scale_pos_weight=1.4782245663385252, subsample=1.300649868838617; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0759827431200462, gamma=0.39562129912388516, lambda=0.3020449572865204, learning_rate=0.45188149481025514, max_depth=11, min_child_weight=1, n_estimators=300, scale_pos_weight=2.606505902201079, subsample=0.7241050881945122; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0759827431200462, gamma=0.39562129912388516, lambda=0.3020449572865204, learning_rate=0.45188149481025514, max_depth=11, min_child_weight=1, n_estimators=300, scale_pos_weight=2.606505902201079, subsample=0.7241050881945122; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0759827431200462, gamma=0.39562129912388516, lambda=0.3020449572865204, learning_rate=0.45188149481025514, max_depth=11, min_child_weight=1, n_estimators=300, scale_pos_weight=2.606505902201079, subsample=0.7241050881945122; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0759827431200462, gamma=0.39562129912388516, lambda=0.3020449572865204, learning_rate=0.45188149481025514, max_depth=11, min_child_weight=1, n_estimators=300, scale_pos_weight=2.606505902201079, subsample=0.7241050881945122; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1271296839794178, gamma=0.43905517054613696, lambda=0.7898898622973645, learning_rate=0.30245856009041666, max_depth=9, min_child_weight=3, n_estimators=650, scale_pos_weight=2.419760568959565, subsample=1.2051098268041351; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1271296839794178, gamma=0.43905517054613696, lambda=0.7898898622973645, learning_rate=0.30245856009041666, max_depth=9, min_child_weight=3, n_estimators=650, scale_pos_weight=2.419760568959565, subsample=1.2051098268041351; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1271296839794178, gamma=0.43905517054613696, lambda=0.7898898622973645, learning_rate=0.30245856009041666, max_depth=9, min_child_weight=3, n_estimators=650, scale_pos_weight=2.419760568959565, subsample=1.2051098268041351; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1271296839794178, gamma=0.43905517054613696, lambda=0.7898898622973645, learning_rate=0.30245856009041666, max_depth=9, min_child_weight=3, n_estimators=650, scale_pos_weight=2.419760568959565, subsample=1.2051098268041351; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.096730049473857, gamma=0.29033153010704144, lambda=0.1816456459043811, learning_rate=0.3499131569331087, max_depth=6, min_child_weight=1, n_estimators=650, scale_pos_weight=1.5760911032804934, subsample=1.5069130456896136; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.096730049473857, gamma=0.29033153010704144, lambda=0.1816456459043811, learning_rate=0.3499131569331087, max_depth=6, min_child_weight=1, n_estimators=650, scale_pos_weight=1.5760911032804934, subsample=1.5069130456896136; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.096730049473857, gamma=0.29033153010704144, lambda=0.1816456459043811, learning_rate=0.3499131569331087, max_depth=6, min_child_weight=1, n_estimators=650, scale_pos_weight=1.5760911032804934, subsample=1.5069130456896136; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.096730049473857, gamma=0.29033153010704144, lambda=0.1816456459043811, learning_rate=0.3499131569331087, max_depth=6, min_child_weight=1, n_estimators=650, scale_pos_weight=1.5760911032804934, subsample=1.5069130456896136; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9695309055901038, gamma=0.28468587843577847, lambda=0.7778277458344738, learning_rate=0.3252124820847688, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=1.3969841372692078, subsample=0.9210785957303428; total time=   0.6s\n",
      "[CV] END alpha=15, colsample_bytree=0.9695309055901038, gamma=0.28468587843577847, lambda=0.7778277458344738, learning_rate=0.3252124820847688, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=1.3969841372692078, subsample=0.9210785957303428; total time=   0.3s\n",
      "[CV] END alpha=15, colsample_bytree=0.9695309055901038, gamma=0.28468587843577847, lambda=0.7778277458344738, learning_rate=0.3252124820847688, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=1.3969841372692078, subsample=0.9210785957303428; total time=   0.4s\n",
      "[CV] END alpha=15, colsample_bytree=0.9695309055901038, gamma=0.28468587843577847, lambda=0.7778277458344738, learning_rate=0.3252124820847688, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=1.3969841372692078, subsample=0.9210785957303428; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=1.185179613318462, gamma=0.344292076581487, lambda=1.3013065766874314, learning_rate=0.3332257519940759, max_depth=11, min_child_weight=3, n_estimators=450, scale_pos_weight=0.8514747379829959, subsample=0.6252302303934864; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.185179613318462, gamma=0.344292076581487, lambda=1.3013065766874314, learning_rate=0.3332257519940759, max_depth=11, min_child_weight=3, n_estimators=450, scale_pos_weight=0.8514747379829959, subsample=0.6252302303934864; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.185179613318462, gamma=0.344292076581487, lambda=1.3013065766874314, learning_rate=0.3332257519940759, max_depth=11, min_child_weight=3, n_estimators=450, scale_pos_weight=0.8514747379829959, subsample=0.6252302303934864; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.185179613318462, gamma=0.344292076581487, lambda=1.3013065766874314, learning_rate=0.3332257519940759, max_depth=11, min_child_weight=3, n_estimators=450, scale_pos_weight=0.8514747379829959, subsample=0.6252302303934864; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7408411190819864, gamma=0.3982440573804658, lambda=0.6753384762923534, learning_rate=0.4642954184839787, max_depth=9, min_child_weight=1, n_estimators=650, scale_pos_weight=1.499314660571718, subsample=0.7007626036744959; total time=   0.4s\n",
      "[CV] END alpha=25, colsample_bytree=0.7408411190819864, gamma=0.3982440573804658, lambda=0.6753384762923534, learning_rate=0.4642954184839787, max_depth=9, min_child_weight=1, n_estimators=650, scale_pos_weight=1.499314660571718, subsample=0.7007626036744959; total time=   0.4s\n",
      "[CV] END alpha=25, colsample_bytree=0.7408411190819864, gamma=0.3982440573804658, lambda=0.6753384762923534, learning_rate=0.4642954184839787, max_depth=9, min_child_weight=1, n_estimators=650, scale_pos_weight=1.499314660571718, subsample=0.7007626036744959; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.7408411190819864, gamma=0.3982440573804658, lambda=0.6753384762923534, learning_rate=0.4642954184839787, max_depth=9, min_child_weight=1, n_estimators=650, scale_pos_weight=1.499314660571718, subsample=0.7007626036744959; total time=   0.4s\n",
      "[CV] END alpha=10, colsample_bytree=0.8632359645154317, gamma=0.19890114941998877, lambda=1.0953177647350107, learning_rate=0.46747228388143025, max_depth=8, min_child_weight=1, n_estimators=400, scale_pos_weight=2.6488630925572014, subsample=0.8647785023429838; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.8632359645154317, gamma=0.19890114941998877, lambda=1.0953177647350107, learning_rate=0.46747228388143025, max_depth=8, min_child_weight=1, n_estimators=400, scale_pos_weight=2.6488630925572014, subsample=0.8647785023429838; total time=   0.4s\n",
      "[CV] END alpha=10, colsample_bytree=0.8632359645154317, gamma=0.19890114941998877, lambda=1.0953177647350107, learning_rate=0.46747228388143025, max_depth=8, min_child_weight=1, n_estimators=400, scale_pos_weight=2.6488630925572014, subsample=0.8647785023429838; total time=   0.4s\n",
      "[CV] END alpha=10, colsample_bytree=0.8632359645154317, gamma=0.19890114941998877, lambda=1.0953177647350107, learning_rate=0.46747228388143025, max_depth=8, min_child_weight=1, n_estimators=400, scale_pos_weight=2.6488630925572014, subsample=0.8647785023429838; total time=   0.4s\n",
      "[CV] END alpha=15, colsample_bytree=1.1626054570366398, gamma=0.0701600731279804, lambda=0.6634603716836318, learning_rate=0.24881882911166842, max_depth=8, min_child_weight=1, n_estimators=250, scale_pos_weight=1.3092240547432812, subsample=1.5225103278400418; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1626054570366398, gamma=0.0701600731279804, lambda=0.6634603716836318, learning_rate=0.24881882911166842, max_depth=8, min_child_weight=1, n_estimators=250, scale_pos_weight=1.3092240547432812, subsample=1.5225103278400418; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1626054570366398, gamma=0.0701600731279804, lambda=0.6634603716836318, learning_rate=0.24881882911166842, max_depth=8, min_child_weight=1, n_estimators=250, scale_pos_weight=1.3092240547432812, subsample=1.5225103278400418; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.1626054570366398, gamma=0.0701600731279804, lambda=0.6634603716836318, learning_rate=0.24881882911166842, max_depth=8, min_child_weight=1, n_estimators=250, scale_pos_weight=1.3092240547432812, subsample=1.5225103278400418; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.554058502312248, gamma=0.4543302054114232, lambda=0.8485015024315332, learning_rate=0.19699601277064993, max_depth=9, min_child_weight=1, n_estimators=400, scale_pos_weight=1.165367026425677, subsample=0.9845119038053575; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.554058502312248, gamma=0.4543302054114232, lambda=0.8485015024315332, learning_rate=0.19699601277064993, max_depth=9, min_child_weight=1, n_estimators=400, scale_pos_weight=1.165367026425677, subsample=0.9845119038053575; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.554058502312248, gamma=0.4543302054114232, lambda=0.8485015024315332, learning_rate=0.19699601277064993, max_depth=9, min_child_weight=1, n_estimators=400, scale_pos_weight=1.165367026425677, subsample=0.9845119038053575; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.554058502312248, gamma=0.4543302054114232, lambda=0.8485015024315332, learning_rate=0.19699601277064993, max_depth=9, min_child_weight=1, n_estimators=400, scale_pos_weight=1.165367026425677, subsample=0.9845119038053575; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=0.8314931786851947, gamma=0.3997012088395923, lambda=1.127649353776434, learning_rate=0.4975221698558966, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=2.5281831665149577, subsample=1.18666029867331; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.8314931786851947, gamma=0.3997012088395923, lambda=1.127649353776434, learning_rate=0.4975221698558966, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=2.5281831665149577, subsample=1.18666029867331; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.8314931786851947, gamma=0.3997012088395923, lambda=1.127649353776434, learning_rate=0.4975221698558966, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=2.5281831665149577, subsample=1.18666029867331; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.8314931786851947, gamma=0.3997012088395923, lambda=1.127649353776434, learning_rate=0.4975221698558966, max_depth=10, min_child_weight=3, n_estimators=750, scale_pos_weight=2.5281831665149577, subsample=1.18666029867331; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7197447408059034, gamma=0.2366092736755151, lambda=0.3014729517683565, learning_rate=0.0380975806568502, max_depth=8, min_child_weight=3, n_estimators=200, scale_pos_weight=1.5495978600750377, subsample=0.9435559479473447; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.7197447408059034, gamma=0.2366092736755151, lambda=0.3014729517683565, learning_rate=0.0380975806568502, max_depth=8, min_child_weight=3, n_estimators=200, scale_pos_weight=1.5495978600750377, subsample=0.9435559479473447; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.7197447408059034, gamma=0.2366092736755151, lambda=0.3014729517683565, learning_rate=0.0380975806568502, max_depth=8, min_child_weight=3, n_estimators=200, scale_pos_weight=1.5495978600750377, subsample=0.9435559479473447; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.7197447408059034, gamma=0.2366092736755151, lambda=0.3014729517683565, learning_rate=0.0380975806568502, max_depth=8, min_child_weight=3, n_estimators=200, scale_pos_weight=1.5495978600750377, subsample=0.9435559479473447; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=0.6322757213780725, gamma=0.20392303752942925, lambda=0.10919695789715667, learning_rate=0.012241823740463944, max_depth=9, min_child_weight=1, n_estimators=700, scale_pos_weight=1.3913026500601267, subsample=1.4016255087438565; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6322757213780725, gamma=0.20392303752942925, lambda=0.10919695789715667, learning_rate=0.012241823740463944, max_depth=9, min_child_weight=1, n_estimators=700, scale_pos_weight=1.3913026500601267, subsample=1.4016255087438565; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6322757213780725, gamma=0.20392303752942925, lambda=0.10919695789715667, learning_rate=0.012241823740463944, max_depth=9, min_child_weight=1, n_estimators=700, scale_pos_weight=1.3913026500601267, subsample=1.4016255087438565; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6322757213780725, gamma=0.20392303752942925, lambda=0.10919695789715667, learning_rate=0.012241823740463944, max_depth=9, min_child_weight=1, n_estimators=700, scale_pos_weight=1.3913026500601267, subsample=1.4016255087438565; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.45860408861852303, gamma=0.41084597442009574, lambda=0.1176238549876441, learning_rate=0.402611136867983, max_depth=7, min_child_weight=1, n_estimators=600, scale_pos_weight=1.6729767399265105, subsample=1.5556273574079094; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.45860408861852303, gamma=0.41084597442009574, lambda=0.1176238549876441, learning_rate=0.402611136867983, max_depth=7, min_child_weight=1, n_estimators=600, scale_pos_weight=1.6729767399265105, subsample=1.5556273574079094; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.45860408861852303, gamma=0.41084597442009574, lambda=0.1176238549876441, learning_rate=0.402611136867983, max_depth=7, min_child_weight=1, n_estimators=600, scale_pos_weight=1.6729767399265105, subsample=1.5556273574079094; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.45860408861852303, gamma=0.41084597442009574, lambda=0.1176238549876441, learning_rate=0.402611136867983, max_depth=7, min_child_weight=1, n_estimators=600, scale_pos_weight=1.6729767399265105, subsample=1.5556273574079094; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.5067006735209898, gamma=0.2905153225076429, lambda=1.4544248748128223, learning_rate=0.23642254519129946, max_depth=8, min_child_weight=1, n_estimators=350, scale_pos_weight=1.2561546583381573, subsample=1.341736677858477; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.5067006735209898, gamma=0.2905153225076429, lambda=1.4544248748128223, learning_rate=0.23642254519129946, max_depth=8, min_child_weight=1, n_estimators=350, scale_pos_weight=1.2561546583381573, subsample=1.341736677858477; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.5067006735209898, gamma=0.2905153225076429, lambda=1.4544248748128223, learning_rate=0.23642254519129946, max_depth=8, min_child_weight=1, n_estimators=350, scale_pos_weight=1.2561546583381573, subsample=1.341736677858477; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.5067006735209898, gamma=0.2905153225076429, lambda=1.4544248748128223, learning_rate=0.23642254519129946, max_depth=8, min_child_weight=1, n_estimators=350, scale_pos_weight=1.2561546583381573, subsample=1.341736677858477; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9684322129357823, gamma=0.24133549764422535, lambda=0.2033505481643147, learning_rate=0.12866423575166352, max_depth=8, min_child_weight=3, n_estimators=400, scale_pos_weight=0.762091268082748, subsample=1.5046153509581606; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9684322129357823, gamma=0.24133549764422535, lambda=0.2033505481643147, learning_rate=0.12866423575166352, max_depth=8, min_child_weight=3, n_estimators=400, scale_pos_weight=0.762091268082748, subsample=1.5046153509581606; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9684322129357823, gamma=0.24133549764422535, lambda=0.2033505481643147, learning_rate=0.12866423575166352, max_depth=8, min_child_weight=3, n_estimators=400, scale_pos_weight=0.762091268082748, subsample=1.5046153509581606; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9684322129357823, gamma=0.24133549764422535, lambda=0.2033505481643147, learning_rate=0.12866423575166352, max_depth=8, min_child_weight=3, n_estimators=400, scale_pos_weight=0.762091268082748, subsample=1.5046153509581606; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7447488282059125, gamma=0.240813399638461, lambda=0.409954302137158, learning_rate=0.24317538867868543, max_depth=5, min_child_weight=1, n_estimators=350, scale_pos_weight=1.8010898539935944, subsample=1.549744124280045; total time=   0.1s\n",
      "[CV] END alpha=10, colsample_bytree=0.7447488282059125, gamma=0.240813399638461, lambda=0.409954302137158, learning_rate=0.24317538867868543, max_depth=5, min_child_weight=1, n_estimators=350, scale_pos_weight=1.8010898539935944, subsample=1.549744124280045; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7447488282059125, gamma=0.240813399638461, lambda=0.409954302137158, learning_rate=0.24317538867868543, max_depth=5, min_child_weight=1, n_estimators=350, scale_pos_weight=1.8010898539935944, subsample=1.549744124280045; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7447488282059125, gamma=0.240813399638461, lambda=0.409954302137158, learning_rate=0.24317538867868543, max_depth=5, min_child_weight=1, n_estimators=350, scale_pos_weight=1.8010898539935944, subsample=1.549744124280045; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.6146803023301142, gamma=0.4222036006256597, lambda=1.463561269363289, learning_rate=0.08907249896525575, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=1.0444587498392073, subsample=1.0305322343246945; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.6146803023301142, gamma=0.4222036006256597, lambda=1.463561269363289, learning_rate=0.08907249896525575, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=1.0444587498392073, subsample=1.0305322343246945; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.6146803023301142, gamma=0.4222036006256597, lambda=1.463561269363289, learning_rate=0.08907249896525575, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=1.0444587498392073, subsample=1.0305322343246945; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.6146803023301142, gamma=0.4222036006256597, lambda=1.463561269363289, learning_rate=0.08907249896525575, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=1.0444587498392073, subsample=1.0305322343246945; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4851842713439301, gamma=0.11988814149261168, lambda=1.434866477130499, learning_rate=0.07089758245223408, max_depth=8, min_child_weight=3, n_estimators=450, scale_pos_weight=2.1478135613484985, subsample=0.9758267398406076; total time=   0.6s\n",
      "[CV] END alpha=10, colsample_bytree=0.4851842713439301, gamma=0.11988814149261168, lambda=1.434866477130499, learning_rate=0.07089758245223408, max_depth=8, min_child_weight=3, n_estimators=450, scale_pos_weight=2.1478135613484985, subsample=0.9758267398406076; total time=   0.5s\n",
      "[CV] END alpha=10, colsample_bytree=0.4851842713439301, gamma=0.11988814149261168, lambda=1.434866477130499, learning_rate=0.07089758245223408, max_depth=8, min_child_weight=3, n_estimators=450, scale_pos_weight=2.1478135613484985, subsample=0.9758267398406076; total time=   0.5s\n",
      "[CV] END alpha=10, colsample_bytree=0.4851842713439301, gamma=0.11988814149261168, lambda=1.434866477130499, learning_rate=0.07089758245223408, max_depth=8, min_child_weight=3, n_estimators=450, scale_pos_weight=2.1478135613484985, subsample=0.9758267398406076; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=1.0882173346907338, gamma=0.07548190225239731, lambda=1.0653268148148287, learning_rate=0.4488256542392964, max_depth=9, min_child_weight=3, n_estimators=450, scale_pos_weight=2.1447223371499966, subsample=1.1637713024002383; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0882173346907338, gamma=0.07548190225239731, lambda=1.0653268148148287, learning_rate=0.4488256542392964, max_depth=9, min_child_weight=3, n_estimators=450, scale_pos_weight=2.1447223371499966, subsample=1.1637713024002383; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0882173346907338, gamma=0.07548190225239731, lambda=1.0653268148148287, learning_rate=0.4488256542392964, max_depth=9, min_child_weight=3, n_estimators=450, scale_pos_weight=2.1447223371499966, subsample=1.1637713024002383; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0882173346907338, gamma=0.07548190225239731, lambda=1.0653268148148287, learning_rate=0.4488256542392964, max_depth=9, min_child_weight=3, n_estimators=450, scale_pos_weight=2.1447223371499966, subsample=1.1637713024002383; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0688234458410062, gamma=0.2830864094392161, lambda=0.5608012026367102, learning_rate=0.22769873456593254, max_depth=8, min_child_weight=3, n_estimators=500, scale_pos_weight=0.9289765654434281, subsample=1.0503451529998389; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0688234458410062, gamma=0.2830864094392161, lambda=0.5608012026367102, learning_rate=0.22769873456593254, max_depth=8, min_child_weight=3, n_estimators=500, scale_pos_weight=0.9289765654434281, subsample=1.0503451529998389; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0688234458410062, gamma=0.2830864094392161, lambda=0.5608012026367102, learning_rate=0.22769873456593254, max_depth=8, min_child_weight=3, n_estimators=500, scale_pos_weight=0.9289765654434281, subsample=1.0503451529998389; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0688234458410062, gamma=0.2830864094392161, lambda=0.5608012026367102, learning_rate=0.22769873456593254, max_depth=8, min_child_weight=3, n_estimators=500, scale_pos_weight=0.9289765654434281, subsample=1.0503451529998389; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9586511889281788, gamma=0.24934085536809464, lambda=0.973336928203654, learning_rate=0.36117118939812176, max_depth=10, min_child_weight=3, n_estimators=250, scale_pos_weight=1.64246193625543, subsample=1.5292123303845409; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9586511889281788, gamma=0.24934085536809464, lambda=0.973336928203654, learning_rate=0.36117118939812176, max_depth=10, min_child_weight=3, n_estimators=250, scale_pos_weight=1.64246193625543, subsample=1.5292123303845409; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9586511889281788, gamma=0.24934085536809464, lambda=0.973336928203654, learning_rate=0.36117118939812176, max_depth=10, min_child_weight=3, n_estimators=250, scale_pos_weight=1.64246193625543, subsample=1.5292123303845409; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9586511889281788, gamma=0.24934085536809464, lambda=0.973336928203654, learning_rate=0.36117118939812176, max_depth=10, min_child_weight=3, n_estimators=250, scale_pos_weight=1.64246193625543, subsample=1.5292123303845409; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.7558594727974681, gamma=0.24784213327846516, lambda=0.7373434388611055, learning_rate=0.09189402484624735, max_depth=5, min_child_weight=3, n_estimators=500, scale_pos_weight=2.123263260826999, subsample=1.450552872379251; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.7558594727974681, gamma=0.24784213327846516, lambda=0.7373434388611055, learning_rate=0.09189402484624735, max_depth=5, min_child_weight=3, n_estimators=500, scale_pos_weight=2.123263260826999, subsample=1.450552872379251; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.7558594727974681, gamma=0.24784213327846516, lambda=0.7373434388611055, learning_rate=0.09189402484624735, max_depth=5, min_child_weight=3, n_estimators=500, scale_pos_weight=2.123263260826999, subsample=1.450552872379251; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.7558594727974681, gamma=0.24784213327846516, lambda=0.7373434388611055, learning_rate=0.09189402484624735, max_depth=5, min_child_weight=3, n_estimators=500, scale_pos_weight=2.123263260826999, subsample=1.450552872379251; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5603386327000601, gamma=0.14080797887431146, lambda=1.47816053618299, learning_rate=0.3470390235244431, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=2.023967866943393, subsample=1.068292923804846; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5603386327000601, gamma=0.14080797887431146, lambda=1.47816053618299, learning_rate=0.3470390235244431, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=2.023967866943393, subsample=1.068292923804846; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5603386327000601, gamma=0.14080797887431146, lambda=1.47816053618299, learning_rate=0.3470390235244431, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=2.023967866943393, subsample=1.068292923804846; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.5603386327000601, gamma=0.14080797887431146, lambda=1.47816053618299, learning_rate=0.3470390235244431, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=2.023967866943393, subsample=1.068292923804846; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.110032972869274, gamma=0.4709937815463342, lambda=0.9193491127702789, learning_rate=0.13949739384082593, max_depth=5, min_child_weight=1, n_estimators=300, scale_pos_weight=1.0027209120665832, subsample=1.1177095248338538; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.110032972869274, gamma=0.4709937815463342, lambda=0.9193491127702789, learning_rate=0.13949739384082593, max_depth=5, min_child_weight=1, n_estimators=300, scale_pos_weight=1.0027209120665832, subsample=1.1177095248338538; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.110032972869274, gamma=0.4709937815463342, lambda=0.9193491127702789, learning_rate=0.13949739384082593, max_depth=5, min_child_weight=1, n_estimators=300, scale_pos_weight=1.0027209120665832, subsample=1.1177095248338538; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.110032972869274, gamma=0.4709937815463342, lambda=0.9193491127702789, learning_rate=0.13949739384082593, max_depth=5, min_child_weight=1, n_estimators=300, scale_pos_weight=1.0027209120665832, subsample=1.1177095248338538; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1551118988740732, gamma=0.2700715474107061, lambda=1.0396908032763845, learning_rate=0.03261333437306912, max_depth=6, min_child_weight=3, n_estimators=650, scale_pos_weight=1.1417077657633508, subsample=0.6936205416669551; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1551118988740732, gamma=0.2700715474107061, lambda=1.0396908032763845, learning_rate=0.03261333437306912, max_depth=6, min_child_weight=3, n_estimators=650, scale_pos_weight=1.1417077657633508, subsample=0.6936205416669551; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1551118988740732, gamma=0.2700715474107061, lambda=1.0396908032763845, learning_rate=0.03261333437306912, max_depth=6, min_child_weight=3, n_estimators=650, scale_pos_weight=1.1417077657633508, subsample=0.6936205416669551; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1551118988740732, gamma=0.2700715474107061, lambda=1.0396908032763845, learning_rate=0.03261333437306912, max_depth=6, min_child_weight=3, n_estimators=650, scale_pos_weight=1.1417077657633508, subsample=0.6936205416669551; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.6896540218292926, gamma=0.41135118631020096, lambda=0.9390730205344132, learning_rate=0.37847106897384514, max_depth=7, min_child_weight=3, n_estimators=350, scale_pos_weight=1.3200815168614992, subsample=1.1149477402045758; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.6896540218292926, gamma=0.41135118631020096, lambda=0.9390730205344132, learning_rate=0.37847106897384514, max_depth=7, min_child_weight=3, n_estimators=350, scale_pos_weight=1.3200815168614992, subsample=1.1149477402045758; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.6896540218292926, gamma=0.41135118631020096, lambda=0.9390730205344132, learning_rate=0.37847106897384514, max_depth=7, min_child_weight=3, n_estimators=350, scale_pos_weight=1.3200815168614992, subsample=1.1149477402045758; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.6896540218292926, gamma=0.41135118631020096, lambda=0.9390730205344132, learning_rate=0.37847106897384514, max_depth=7, min_child_weight=3, n_estimators=350, scale_pos_weight=1.3200815168614992, subsample=1.1149477402045758; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.4210234606293231, gamma=0.4914564039392795, lambda=0.3388624067522622, learning_rate=0.2880520732361812, max_depth=8, min_child_weight=3, n_estimators=700, scale_pos_weight=1.9638390675375224, subsample=0.6875062558536535; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.4210234606293231, gamma=0.4914564039392795, lambda=0.3388624067522622, learning_rate=0.2880520732361812, max_depth=8, min_child_weight=3, n_estimators=700, scale_pos_weight=1.9638390675375224, subsample=0.6875062558536535; total time=   0.4s\n",
      "[CV] END alpha=15, colsample_bytree=0.4210234606293231, gamma=0.4914564039392795, lambda=0.3388624067522622, learning_rate=0.2880520732361812, max_depth=8, min_child_weight=3, n_estimators=700, scale_pos_weight=1.9638390675375224, subsample=0.6875062558536535; total time=   0.4s\n",
      "[CV] END alpha=15, colsample_bytree=0.4210234606293231, gamma=0.4914564039392795, lambda=0.3388624067522622, learning_rate=0.2880520732361812, max_depth=8, min_child_weight=3, n_estimators=700, scale_pos_weight=1.9638390675375224, subsample=0.6875062558536535; total time=   0.4s\n",
      "[CV] END alpha=10, colsample_bytree=1.0644637440416849, gamma=0.14924394576071776, lambda=1.07818851918939, learning_rate=0.34931151333075916, max_depth=8, min_child_weight=3, n_estimators=350, scale_pos_weight=1.6813460455824238, subsample=1.1822042472863967; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0644637440416849, gamma=0.14924394576071776, lambda=1.07818851918939, learning_rate=0.34931151333075916, max_depth=8, min_child_weight=3, n_estimators=350, scale_pos_weight=1.6813460455824238, subsample=1.1822042472863967; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0644637440416849, gamma=0.14924394576071776, lambda=1.07818851918939, learning_rate=0.34931151333075916, max_depth=8, min_child_weight=3, n_estimators=350, scale_pos_weight=1.6813460455824238, subsample=1.1822042472863967; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.0644637440416849, gamma=0.14924394576071776, lambda=1.07818851918939, learning_rate=0.34931151333075916, max_depth=8, min_child_weight=3, n_estimators=350, scale_pos_weight=1.6813460455824238, subsample=1.1822042472863967; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.2930497548547419, gamma=0.01702737688379158, lambda=0.253365208772024, learning_rate=0.10275716149710838, max_depth=11, min_child_weight=1, n_estimators=500, scale_pos_weight=0.8112647697190776, subsample=1.429853337803918; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.2930497548547419, gamma=0.01702737688379158, lambda=0.253365208772024, learning_rate=0.10275716149710838, max_depth=11, min_child_weight=1, n_estimators=500, scale_pos_weight=0.8112647697190776, subsample=1.429853337803918; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.2930497548547419, gamma=0.01702737688379158, lambda=0.253365208772024, learning_rate=0.10275716149710838, max_depth=11, min_child_weight=1, n_estimators=500, scale_pos_weight=0.8112647697190776, subsample=1.429853337803918; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.2930497548547419, gamma=0.01702737688379158, lambda=0.253365208772024, learning_rate=0.10275716149710838, max_depth=11, min_child_weight=1, n_estimators=500, scale_pos_weight=0.8112647697190776, subsample=1.429853337803918; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.6718395373020443, gamma=0.4389066051177188, lambda=1.469069041385823, learning_rate=0.17041052180223865, max_depth=6, min_child_weight=1, n_estimators=350, scale_pos_weight=1.5003428585481167, subsample=0.697925816085745; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.6718395373020443, gamma=0.4389066051177188, lambda=1.469069041385823, learning_rate=0.17041052180223865, max_depth=6, min_child_weight=1, n_estimators=350, scale_pos_weight=1.5003428585481167, subsample=0.697925816085745; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.6718395373020443, gamma=0.4389066051177188, lambda=1.469069041385823, learning_rate=0.17041052180223865, max_depth=6, min_child_weight=1, n_estimators=350, scale_pos_weight=1.5003428585481167, subsample=0.697925816085745; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.6718395373020443, gamma=0.4389066051177188, lambda=1.469069041385823, learning_rate=0.17041052180223865, max_depth=6, min_child_weight=1, n_estimators=350, scale_pos_weight=1.5003428585481167, subsample=0.697925816085745; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.33342839424145604, gamma=0.3172128639306283, lambda=0.4836579556845733, learning_rate=0.47362162089856197, max_depth=10, min_child_weight=3, n_estimators=700, scale_pos_weight=2.2154383485573703, subsample=0.9320151790566409; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.33342839424145604, gamma=0.3172128639306283, lambda=0.4836579556845733, learning_rate=0.47362162089856197, max_depth=10, min_child_weight=3, n_estimators=700, scale_pos_weight=2.2154383485573703, subsample=0.9320151790566409; total time=   0.4s\n",
      "[CV] END alpha=25, colsample_bytree=0.33342839424145604, gamma=0.3172128639306283, lambda=0.4836579556845733, learning_rate=0.47362162089856197, max_depth=10, min_child_weight=3, n_estimators=700, scale_pos_weight=2.2154383485573703, subsample=0.9320151790566409; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.33342839424145604, gamma=0.3172128639306283, lambda=0.4836579556845733, learning_rate=0.47362162089856197, max_depth=10, min_child_weight=3, n_estimators=700, scale_pos_weight=2.2154383485573703, subsample=0.9320151790566409; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.6919391255698235, gamma=0.2452533671578102, lambda=0.9203633689235691, learning_rate=0.026015067232630633, max_depth=7, min_child_weight=1, n_estimators=250, scale_pos_weight=2.3344791368913693, subsample=0.8846934789930835; total time=   0.4s\n",
      "[CV] END alpha=25, colsample_bytree=0.6919391255698235, gamma=0.2452533671578102, lambda=0.9203633689235691, learning_rate=0.026015067232630633, max_depth=7, min_child_weight=1, n_estimators=250, scale_pos_weight=2.3344791368913693, subsample=0.8846934789930835; total time=   0.5s\n",
      "[CV] END alpha=25, colsample_bytree=0.6919391255698235, gamma=0.2452533671578102, lambda=0.9203633689235691, learning_rate=0.026015067232630633, max_depth=7, min_child_weight=1, n_estimators=250, scale_pos_weight=2.3344791368913693, subsample=0.8846934789930835; total time=   0.4s\n",
      "[CV] END alpha=25, colsample_bytree=0.6919391255698235, gamma=0.2452533671578102, lambda=0.9203633689235691, learning_rate=0.026015067232630633, max_depth=7, min_child_weight=1, n_estimators=250, scale_pos_weight=2.3344791368913693, subsample=0.8846934789930835; total time=   0.4s\n",
      "[CV] END alpha=10, colsample_bytree=0.7906867066411856, gamma=0.37837396622102726, lambda=1.2561708226952317, learning_rate=0.5071068880691721, max_depth=11, min_child_weight=1, n_estimators=350, scale_pos_weight=2.269523143657641, subsample=0.7289524999688664; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.7906867066411856, gamma=0.37837396622102726, lambda=1.2561708226952317, learning_rate=0.5071068880691721, max_depth=11, min_child_weight=1, n_estimators=350, scale_pos_weight=2.269523143657641, subsample=0.7289524999688664; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.7906867066411856, gamma=0.37837396622102726, lambda=1.2561708226952317, learning_rate=0.5071068880691721, max_depth=11, min_child_weight=1, n_estimators=350, scale_pos_weight=2.269523143657641, subsample=0.7289524999688664; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.7906867066411856, gamma=0.37837396622102726, lambda=1.2561708226952317, learning_rate=0.5071068880691721, max_depth=11, min_child_weight=1, n_estimators=350, scale_pos_weight=2.269523143657641, subsample=0.7289524999688664; total time=   0.4s\n",
      "[CV] END alpha=5, colsample_bytree=1.1491751784955817, gamma=0.0646979472909538, lambda=0.2701941866708923, learning_rate=0.1876295623178681, max_depth=7, min_child_weight=3, n_estimators=450, scale_pos_weight=1.7035174224930074, subsample=0.6401771517617705; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1491751784955817, gamma=0.0646979472909538, lambda=0.2701941866708923, learning_rate=0.1876295623178681, max_depth=7, min_child_weight=3, n_estimators=450, scale_pos_weight=1.7035174224930074, subsample=0.6401771517617705; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1491751784955817, gamma=0.0646979472909538, lambda=0.2701941866708923, learning_rate=0.1876295623178681, max_depth=7, min_child_weight=3, n_estimators=450, scale_pos_weight=1.7035174224930074, subsample=0.6401771517617705; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1491751784955817, gamma=0.0646979472909538, lambda=0.2701941866708923, learning_rate=0.1876295623178681, max_depth=7, min_child_weight=3, n_estimators=450, scale_pos_weight=1.7035174224930074, subsample=0.6401771517617705; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.9017263551517443, gamma=0.28555875994239865, lambda=0.7812153517302696, learning_rate=0.04274482025578779, max_depth=11, min_child_weight=3, n_estimators=450, scale_pos_weight=1.7809101181770228, subsample=0.9467483444841486; total time=   1.2s\n",
      "[CV] END alpha=5, colsample_bytree=0.9017263551517443, gamma=0.28555875994239865, lambda=0.7812153517302696, learning_rate=0.04274482025578779, max_depth=11, min_child_weight=3, n_estimators=450, scale_pos_weight=1.7809101181770228, subsample=0.9467483444841486; total time=   1.2s\n",
      "[CV] END alpha=5, colsample_bytree=0.9017263551517443, gamma=0.28555875994239865, lambda=0.7812153517302696, learning_rate=0.04274482025578779, max_depth=11, min_child_weight=3, n_estimators=450, scale_pos_weight=1.7809101181770228, subsample=0.9467483444841486; total time=   1.2s\n",
      "[CV] END alpha=5, colsample_bytree=0.9017263551517443, gamma=0.28555875994239865, lambda=0.7812153517302696, learning_rate=0.04274482025578779, max_depth=11, min_child_weight=3, n_estimators=450, scale_pos_weight=1.7809101181770228, subsample=0.9467483444841486; total time=   1.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.4746256390013592, gamma=0.10527541054651052, lambda=0.18387758779790803, learning_rate=0.37370993589913426, max_depth=9, min_child_weight=1, n_estimators=600, scale_pos_weight=2.127644374627242, subsample=1.2998113790822425; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4746256390013592, gamma=0.10527541054651052, lambda=0.18387758779790803, learning_rate=0.37370993589913426, max_depth=9, min_child_weight=1, n_estimators=600, scale_pos_weight=2.127644374627242, subsample=1.2998113790822425; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4746256390013592, gamma=0.10527541054651052, lambda=0.18387758779790803, learning_rate=0.37370993589913426, max_depth=9, min_child_weight=1, n_estimators=600, scale_pos_weight=2.127644374627242, subsample=1.2998113790822425; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4746256390013592, gamma=0.10527541054651052, lambda=0.18387758779790803, learning_rate=0.37370993589913426, max_depth=9, min_child_weight=1, n_estimators=600, scale_pos_weight=2.127644374627242, subsample=1.2998113790822425; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.43510913473593255, gamma=0.0692893866769898, lambda=0.3076015556746307, learning_rate=0.24616156739171113, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=0.7586008489774765, subsample=1.5642155145496477; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.43510913473593255, gamma=0.0692893866769898, lambda=0.3076015556746307, learning_rate=0.24616156739171113, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=0.7586008489774765, subsample=1.5642155145496477; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.43510913473593255, gamma=0.0692893866769898, lambda=0.3076015556746307, learning_rate=0.24616156739171113, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=0.7586008489774765, subsample=1.5642155145496477; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.43510913473593255, gamma=0.0692893866769898, lambda=0.3076015556746307, learning_rate=0.24616156739171113, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=0.7586008489774765, subsample=1.5642155145496477; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0905605120677633, gamma=0.4752803277922075, lambda=0.3142639772998727, learning_rate=0.13347702078210238, max_depth=9, min_child_weight=3, n_estimators=250, scale_pos_weight=2.321773569296456, subsample=0.9316374892793845; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0905605120677633, gamma=0.4752803277922075, lambda=0.3142639772998727, learning_rate=0.13347702078210238, max_depth=9, min_child_weight=3, n_estimators=250, scale_pos_weight=2.321773569296456, subsample=0.9316374892793845; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0905605120677633, gamma=0.4752803277922075, lambda=0.3142639772998727, learning_rate=0.13347702078210238, max_depth=9, min_child_weight=3, n_estimators=250, scale_pos_weight=2.321773569296456, subsample=0.9316374892793845; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0905605120677633, gamma=0.4752803277922075, lambda=0.3142639772998727, learning_rate=0.13347702078210238, max_depth=9, min_child_weight=3, n_estimators=250, scale_pos_weight=2.321773569296456, subsample=0.9316374892793845; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.48542107186946065, gamma=0.07663901603018064, lambda=0.09790394541340236, learning_rate=0.04721838263714694, max_depth=11, min_child_weight=1, n_estimators=750, scale_pos_weight=2.3116287139840566, subsample=1.3795209834816102; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.48542107186946065, gamma=0.07663901603018064, lambda=0.09790394541340236, learning_rate=0.04721838263714694, max_depth=11, min_child_weight=1, n_estimators=750, scale_pos_weight=2.3116287139840566, subsample=1.3795209834816102; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.48542107186946065, gamma=0.07663901603018064, lambda=0.09790394541340236, learning_rate=0.04721838263714694, max_depth=11, min_child_weight=1, n_estimators=750, scale_pos_weight=2.3116287139840566, subsample=1.3795209834816102; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.48542107186946065, gamma=0.07663901603018064, lambda=0.09790394541340236, learning_rate=0.04721838263714694, max_depth=11, min_child_weight=1, n_estimators=750, scale_pos_weight=2.3116287139840566, subsample=1.3795209834816102; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.8434211937122889, gamma=0.26152074414367565, lambda=1.228777848768118, learning_rate=0.01667302082903959, max_depth=6, min_child_weight=3, n_estimators=750, scale_pos_weight=0.8963641669317778, subsample=0.8795928487707081; total time=   0.8s\n",
      "[CV] END alpha=15, colsample_bytree=0.8434211937122889, gamma=0.26152074414367565, lambda=1.228777848768118, learning_rate=0.01667302082903959, max_depth=6, min_child_weight=3, n_estimators=750, scale_pos_weight=0.8963641669317778, subsample=0.8795928487707081; total time=   0.7s\n",
      "[CV] END alpha=15, colsample_bytree=0.8434211937122889, gamma=0.26152074414367565, lambda=1.228777848768118, learning_rate=0.01667302082903959, max_depth=6, min_child_weight=3, n_estimators=750, scale_pos_weight=0.8963641669317778, subsample=0.8795928487707081; total time=   0.7s\n",
      "[CV] END alpha=15, colsample_bytree=0.8434211937122889, gamma=0.26152074414367565, lambda=1.228777848768118, learning_rate=0.01667302082903959, max_depth=6, min_child_weight=3, n_estimators=750, scale_pos_weight=0.8963641669317778, subsample=0.8795928487707081; total time=   0.7s\n",
      "[CV] END alpha=10, colsample_bytree=0.7644889220979854, gamma=0.271257010995088, lambda=0.7403157497999271, learning_rate=0.4950803904765962, max_depth=9, min_child_weight=3, n_estimators=200, scale_pos_weight=2.346842013261517, subsample=1.5076809696804068; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7644889220979854, gamma=0.271257010995088, lambda=0.7403157497999271, learning_rate=0.4950803904765962, max_depth=9, min_child_weight=3, n_estimators=200, scale_pos_weight=2.346842013261517, subsample=1.5076809696804068; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7644889220979854, gamma=0.271257010995088, lambda=0.7403157497999271, learning_rate=0.4950803904765962, max_depth=9, min_child_weight=3, n_estimators=200, scale_pos_weight=2.346842013261517, subsample=1.5076809696804068; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7644889220979854, gamma=0.271257010995088, lambda=0.7403157497999271, learning_rate=0.4950803904765962, max_depth=9, min_child_weight=3, n_estimators=200, scale_pos_weight=2.346842013261517, subsample=1.5076809696804068; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.573787081429219, gamma=0.18355629014135866, lambda=0.5739350027698715, learning_rate=0.4541292561628014, max_depth=5, min_child_weight=3, n_estimators=300, scale_pos_weight=1.2264112963081595, subsample=1.2005442763805223; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.573787081429219, gamma=0.18355629014135866, lambda=0.5739350027698715, learning_rate=0.4541292561628014, max_depth=5, min_child_weight=3, n_estimators=300, scale_pos_weight=1.2264112963081595, subsample=1.2005442763805223; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.573787081429219, gamma=0.18355629014135866, lambda=0.5739350027698715, learning_rate=0.4541292561628014, max_depth=5, min_child_weight=3, n_estimators=300, scale_pos_weight=1.2264112963081595, subsample=1.2005442763805223; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.573787081429219, gamma=0.18355629014135866, lambda=0.5739350027698715, learning_rate=0.4541292561628014, max_depth=5, min_child_weight=3, n_estimators=300, scale_pos_weight=1.2264112963081595, subsample=1.2005442763805223; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.6346196576132299, gamma=0.3033972446882931, lambda=0.9767934121082091, learning_rate=0.2636532934180838, max_depth=10, min_child_weight=3, n_estimators=250, scale_pos_weight=2.7748865230973614, subsample=0.901414186043687; total time=   0.4s\n",
      "[CV] END alpha=5, colsample_bytree=0.6346196576132299, gamma=0.3033972446882931, lambda=0.9767934121082091, learning_rate=0.2636532934180838, max_depth=10, min_child_weight=3, n_estimators=250, scale_pos_weight=2.7748865230973614, subsample=0.901414186043687; total time=   0.4s\n",
      "[CV] END alpha=5, colsample_bytree=0.6346196576132299, gamma=0.3033972446882931, lambda=0.9767934121082091, learning_rate=0.2636532934180838, max_depth=10, min_child_weight=3, n_estimators=250, scale_pos_weight=2.7748865230973614, subsample=0.901414186043687; total time=   0.4s\n",
      "[CV] END alpha=5, colsample_bytree=0.6346196576132299, gamma=0.3033972446882931, lambda=0.9767934121082091, learning_rate=0.2636532934180838, max_depth=10, min_child_weight=3, n_estimators=250, scale_pos_weight=2.7748865230973614, subsample=0.901414186043687; total time=   0.4s\n",
      "[CV] END alpha=20, colsample_bytree=0.6301105248685741, gamma=0.20653701494529958, lambda=0.20086481546752266, learning_rate=0.1595448017434623, max_depth=6, min_child_weight=1, n_estimators=450, scale_pos_weight=0.9085925004318466, subsample=1.3599133497617695; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.6301105248685741, gamma=0.20653701494529958, lambda=0.20086481546752266, learning_rate=0.1595448017434623, max_depth=6, min_child_weight=1, n_estimators=450, scale_pos_weight=0.9085925004318466, subsample=1.3599133497617695; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.6301105248685741, gamma=0.20653701494529958, lambda=0.20086481546752266, learning_rate=0.1595448017434623, max_depth=6, min_child_weight=1, n_estimators=450, scale_pos_weight=0.9085925004318466, subsample=1.3599133497617695; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.6301105248685741, gamma=0.20653701494529958, lambda=0.20086481546752266, learning_rate=0.1595448017434623, max_depth=6, min_child_weight=1, n_estimators=450, scale_pos_weight=0.9085925004318466, subsample=1.3599133497617695; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.43367352644586327, gamma=0.49847976336015204, lambda=1.473115814344489, learning_rate=0.027849041532906953, max_depth=8, min_child_weight=1, n_estimators=450, scale_pos_weight=2.036267638496107, subsample=0.9717750567238017; total time=   0.6s\n",
      "[CV] END alpha=15, colsample_bytree=0.43367352644586327, gamma=0.49847976336015204, lambda=1.473115814344489, learning_rate=0.027849041532906953, max_depth=8, min_child_weight=1, n_estimators=450, scale_pos_weight=2.036267638496107, subsample=0.9717750567238017; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.43367352644586327, gamma=0.49847976336015204, lambda=1.473115814344489, learning_rate=0.027849041532906953, max_depth=8, min_child_weight=1, n_estimators=450, scale_pos_weight=2.036267638496107, subsample=0.9717750567238017; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.43367352644586327, gamma=0.49847976336015204, lambda=1.473115814344489, learning_rate=0.027849041532906953, max_depth=8, min_child_weight=1, n_estimators=450, scale_pos_weight=2.036267638496107, subsample=0.9717750567238017; total time=   0.5s\n",
      "[CV] END alpha=10, colsample_bytree=0.22546936952912094, gamma=0.3330810899780768, lambda=0.6020111627936011, learning_rate=0.18640783012748469, max_depth=10, min_child_weight=1, n_estimators=600, scale_pos_weight=0.8351951003920439, subsample=0.6569280817683826; total time=   0.4s\n",
      "[CV] END alpha=10, colsample_bytree=0.22546936952912094, gamma=0.3330810899780768, lambda=0.6020111627936011, learning_rate=0.18640783012748469, max_depth=10, min_child_weight=1, n_estimators=600, scale_pos_weight=0.8351951003920439, subsample=0.6569280817683826; total time=   0.4s\n",
      "[CV] END alpha=10, colsample_bytree=0.22546936952912094, gamma=0.3330810899780768, lambda=0.6020111627936011, learning_rate=0.18640783012748469, max_depth=10, min_child_weight=1, n_estimators=600, scale_pos_weight=0.8351951003920439, subsample=0.6569280817683826; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.22546936952912094, gamma=0.3330810899780768, lambda=0.6020111627936011, learning_rate=0.18640783012748469, max_depth=10, min_child_weight=1, n_estimators=600, scale_pos_weight=0.8351951003920439, subsample=0.6569280817683826; total time=   0.4s\n",
      "[CV] END alpha=10, colsample_bytree=0.21795866094910227, gamma=0.04995897775070035, lambda=0.15099369762579834, learning_rate=0.27052167634814683, max_depth=5, min_child_weight=1, n_estimators=350, scale_pos_weight=0.8965554922367799, subsample=1.4417116345293621; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.21795866094910227, gamma=0.04995897775070035, lambda=0.15099369762579834, learning_rate=0.27052167634814683, max_depth=5, min_child_weight=1, n_estimators=350, scale_pos_weight=0.8965554922367799, subsample=1.4417116345293621; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.21795866094910227, gamma=0.04995897775070035, lambda=0.15099369762579834, learning_rate=0.27052167634814683, max_depth=5, min_child_weight=1, n_estimators=350, scale_pos_weight=0.8965554922367799, subsample=1.4417116345293621; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.21795866094910227, gamma=0.04995897775070035, lambda=0.15099369762579834, learning_rate=0.27052167634814683, max_depth=5, min_child_weight=1, n_estimators=350, scale_pos_weight=0.8965554922367799, subsample=1.4417116345293621; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5104924522719612, gamma=0.26420245527202274, lambda=1.3343208158901207, learning_rate=0.06982218000951455, max_depth=8, min_child_weight=1, n_estimators=350, scale_pos_weight=2.341030504148792, subsample=0.9781831319376207; total time=   0.4s\n",
      "[CV] END alpha=25, colsample_bytree=0.5104924522719612, gamma=0.26420245527202274, lambda=1.3343208158901207, learning_rate=0.06982218000951455, max_depth=8, min_child_weight=1, n_estimators=350, scale_pos_weight=2.341030504148792, subsample=0.9781831319376207; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.5104924522719612, gamma=0.26420245527202274, lambda=1.3343208158901207, learning_rate=0.06982218000951455, max_depth=8, min_child_weight=1, n_estimators=350, scale_pos_weight=2.341030504148792, subsample=0.9781831319376207; total time=   1.4s\n",
      "[CV] END alpha=25, colsample_bytree=0.5104924522719612, gamma=0.26420245527202274, lambda=1.3343208158901207, learning_rate=0.06982218000951455, max_depth=8, min_child_weight=1, n_estimators=350, scale_pos_weight=2.341030504148792, subsample=0.9781831319376207; total time=   0.2s\n",
      "[CV] END alpha=15, colsample_bytree=0.5757746739955696, gamma=0.23270637455469761, lambda=1.0870030632994243, learning_rate=0.3420794629710763, max_depth=11, min_child_weight=1, n_estimators=700, scale_pos_weight=2.071724726268192, subsample=1.4570319017460018; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5757746739955696, gamma=0.23270637455469761, lambda=1.0870030632994243, learning_rate=0.3420794629710763, max_depth=11, min_child_weight=1, n_estimators=700, scale_pos_weight=2.071724726268192, subsample=1.4570319017460018; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5757746739955696, gamma=0.23270637455469761, lambda=1.0870030632994243, learning_rate=0.3420794629710763, max_depth=11, min_child_weight=1, n_estimators=700, scale_pos_weight=2.071724726268192, subsample=1.4570319017460018; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5757746739955696, gamma=0.23270637455469761, lambda=1.0870030632994243, learning_rate=0.3420794629710763, max_depth=11, min_child_weight=1, n_estimators=700, scale_pos_weight=2.071724726268192, subsample=1.4570319017460018; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.8935125069417589, gamma=0.1826379772136102, lambda=0.9694434539614594, learning_rate=0.18602214792966537, max_depth=9, min_child_weight=1, n_estimators=650, scale_pos_weight=2.1882353119343123, subsample=0.7473267606941751; total time=   0.6s\n",
      "[CV] END alpha=25, colsample_bytree=0.8935125069417589, gamma=0.1826379772136102, lambda=0.9694434539614594, learning_rate=0.18602214792966537, max_depth=9, min_child_weight=1, n_estimators=650, scale_pos_weight=2.1882353119343123, subsample=0.7473267606941751; total time=   0.5s\n",
      "[CV] END alpha=25, colsample_bytree=0.8935125069417589, gamma=0.1826379772136102, lambda=0.9694434539614594, learning_rate=0.18602214792966537, max_depth=9, min_child_weight=1, n_estimators=650, scale_pos_weight=2.1882353119343123, subsample=0.7473267606941751; total time=   0.5s\n",
      "[CV] END alpha=25, colsample_bytree=0.8935125069417589, gamma=0.1826379772136102, lambda=0.9694434539614594, learning_rate=0.18602214792966537, max_depth=9, min_child_weight=1, n_estimators=650, scale_pos_weight=2.1882353119343123, subsample=0.7473267606941751; total time=   0.5s\n",
      "[CV] END alpha=10, colsample_bytree=0.8978296422501812, gamma=0.05391025921466297, lambda=0.7973897410938864, learning_rate=0.2097536671170162, max_depth=11, min_child_weight=3, n_estimators=400, scale_pos_weight=2.4749042672839643, subsample=1.5626514801730078; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.8978296422501812, gamma=0.05391025921466297, lambda=0.7973897410938864, learning_rate=0.2097536671170162, max_depth=11, min_child_weight=3, n_estimators=400, scale_pos_weight=2.4749042672839643, subsample=1.5626514801730078; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.8978296422501812, gamma=0.05391025921466297, lambda=0.7973897410938864, learning_rate=0.2097536671170162, max_depth=11, min_child_weight=3, n_estimators=400, scale_pos_weight=2.4749042672839643, subsample=1.5626514801730078; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.8978296422501812, gamma=0.05391025921466297, lambda=0.7973897410938864, learning_rate=0.2097536671170162, max_depth=11, min_child_weight=3, n_estimators=400, scale_pos_weight=2.4749042672839643, subsample=1.5626514801730078; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.7541288659858529, gamma=0.21440817675209534, lambda=0.47470611270392704, learning_rate=0.3621291187255439, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=2.3472191761545327, subsample=1.0183840530079302; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.7541288659858529, gamma=0.21440817675209534, lambda=0.47470611270392704, learning_rate=0.3621291187255439, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=2.3472191761545327, subsample=1.0183840530079302; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.7541288659858529, gamma=0.21440817675209534, lambda=0.47470611270392704, learning_rate=0.3621291187255439, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=2.3472191761545327, subsample=1.0183840530079302; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.7541288659858529, gamma=0.21440817675209534, lambda=0.47470611270392704, learning_rate=0.3621291187255439, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=2.3472191761545327, subsample=1.0183840530079302; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1593160235436373, gamma=0.23220824775874294, lambda=1.0838885512419607, learning_rate=0.2381288951473986, max_depth=5, min_child_weight=1, n_estimators=550, scale_pos_weight=2.4885751879290714, subsample=0.6282774054503713; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1593160235436373, gamma=0.23220824775874294, lambda=1.0838885512419607, learning_rate=0.2381288951473986, max_depth=5, min_child_weight=1, n_estimators=550, scale_pos_weight=2.4885751879290714, subsample=0.6282774054503713; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1593160235436373, gamma=0.23220824775874294, lambda=1.0838885512419607, learning_rate=0.2381288951473986, max_depth=5, min_child_weight=1, n_estimators=550, scale_pos_weight=2.4885751879290714, subsample=0.6282774054503713; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1593160235436373, gamma=0.23220824775874294, lambda=1.0838885512419607, learning_rate=0.2381288951473986, max_depth=5, min_child_weight=1, n_estimators=550, scale_pos_weight=2.4885751879290714, subsample=0.6282774054503713; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.542115327910986, gamma=0.054491404608163874, lambda=0.1526235250388856, learning_rate=0.24317239317389783, max_depth=5, min_child_weight=1, n_estimators=550, scale_pos_weight=2.7738950355478, subsample=0.8642692624030509; total time=   0.5s\n",
      "[CV] END alpha=10, colsample_bytree=0.542115327910986, gamma=0.054491404608163874, lambda=0.1526235250388856, learning_rate=0.24317239317389783, max_depth=5, min_child_weight=1, n_estimators=550, scale_pos_weight=2.7738950355478, subsample=0.8642692624030509; total time=   0.5s\n",
      "[CV] END alpha=10, colsample_bytree=0.542115327910986, gamma=0.054491404608163874, lambda=0.1526235250388856, learning_rate=0.24317239317389783, max_depth=5, min_child_weight=1, n_estimators=550, scale_pos_weight=2.7738950355478, subsample=0.8642692624030509; total time=   0.4s\n",
      "[CV] END alpha=10, colsample_bytree=0.542115327910986, gamma=0.054491404608163874, lambda=0.1526235250388856, learning_rate=0.24317239317389783, max_depth=5, min_child_weight=1, n_estimators=550, scale_pos_weight=2.7738950355478, subsample=0.8642692624030509; total time=   0.4s\n",
      "[CV] END alpha=25, colsample_bytree=0.5775954570695452, gamma=0.24427874738266664, lambda=0.3300082115597318, learning_rate=0.15700581650509426, max_depth=7, min_child_weight=1, n_estimators=350, scale_pos_weight=1.834243105177833, subsample=1.233857754713281; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5775954570695452, gamma=0.24427874738266664, lambda=0.3300082115597318, learning_rate=0.15700581650509426, max_depth=7, min_child_weight=1, n_estimators=350, scale_pos_weight=1.834243105177833, subsample=1.233857754713281; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5775954570695452, gamma=0.24427874738266664, lambda=0.3300082115597318, learning_rate=0.15700581650509426, max_depth=7, min_child_weight=1, n_estimators=350, scale_pos_weight=1.834243105177833, subsample=1.233857754713281; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5775954570695452, gamma=0.24427874738266664, lambda=0.3300082115597318, learning_rate=0.15700581650509426, max_depth=7, min_child_weight=1, n_estimators=350, scale_pos_weight=1.834243105177833, subsample=1.233857754713281; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.2541379148876804, gamma=0.2472036076868026, lambda=0.5944755843895932, learning_rate=0.502785753029668, max_depth=10, min_child_weight=3, n_estimators=400, scale_pos_weight=2.0919593698768852, subsample=1.0151427416826326; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.2541379148876804, gamma=0.2472036076868026, lambda=0.5944755843895932, learning_rate=0.502785753029668, max_depth=10, min_child_weight=3, n_estimators=400, scale_pos_weight=2.0919593698768852, subsample=1.0151427416826326; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.2541379148876804, gamma=0.2472036076868026, lambda=0.5944755843895932, learning_rate=0.502785753029668, max_depth=10, min_child_weight=3, n_estimators=400, scale_pos_weight=2.0919593698768852, subsample=1.0151427416826326; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.2541379148876804, gamma=0.2472036076868026, lambda=0.5944755843895932, learning_rate=0.502785753029668, max_depth=10, min_child_weight=3, n_estimators=400, scale_pos_weight=2.0919593698768852, subsample=1.0151427416826326; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0397038173416548, gamma=0.3899817434412184, lambda=1.416082568594486, learning_rate=0.28947836724048287, max_depth=8, min_child_weight=3, n_estimators=300, scale_pos_weight=1.7657228197816122, subsample=1.083512053205051; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0397038173416548, gamma=0.3899817434412184, lambda=1.416082568594486, learning_rate=0.28947836724048287, max_depth=8, min_child_weight=3, n_estimators=300, scale_pos_weight=1.7657228197816122, subsample=1.083512053205051; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0397038173416548, gamma=0.3899817434412184, lambda=1.416082568594486, learning_rate=0.28947836724048287, max_depth=8, min_child_weight=3, n_estimators=300, scale_pos_weight=1.7657228197816122, subsample=1.083512053205051; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0397038173416548, gamma=0.3899817434412184, lambda=1.416082568594486, learning_rate=0.28947836724048287, max_depth=8, min_child_weight=3, n_estimators=300, scale_pos_weight=1.7657228197816122, subsample=1.083512053205051; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.485336127772861, gamma=0.23225752381354903, lambda=0.18320757887983685, learning_rate=0.25120180822737564, max_depth=5, min_child_weight=1, n_estimators=650, scale_pos_weight=1.3480623169621482, subsample=0.9189735475766977; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.485336127772861, gamma=0.23225752381354903, lambda=0.18320757887983685, learning_rate=0.25120180822737564, max_depth=5, min_child_weight=1, n_estimators=650, scale_pos_weight=1.3480623169621482, subsample=0.9189735475766977; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.485336127772861, gamma=0.23225752381354903, lambda=0.18320757887983685, learning_rate=0.25120180822737564, max_depth=5, min_child_weight=1, n_estimators=650, scale_pos_weight=1.3480623169621482, subsample=0.9189735475766977; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.485336127772861, gamma=0.23225752381354903, lambda=0.18320757887983685, learning_rate=0.25120180822737564, max_depth=5, min_child_weight=1, n_estimators=650, scale_pos_weight=1.3480623169621482, subsample=0.9189735475766977; total time=   0.2s\n",
      "[CV] END alpha=15, colsample_bytree=1.0310981865013433, gamma=0.1270120612200643, lambda=0.5213628351828231, learning_rate=0.07383408369452026, max_depth=5, min_child_weight=1, n_estimators=750, scale_pos_weight=1.835641617165995, subsample=1.040868665682296; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0310981865013433, gamma=0.1270120612200643, lambda=0.5213628351828231, learning_rate=0.07383408369452026, max_depth=5, min_child_weight=1, n_estimators=750, scale_pos_weight=1.835641617165995, subsample=1.040868665682296; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0310981865013433, gamma=0.1270120612200643, lambda=0.5213628351828231, learning_rate=0.07383408369452026, max_depth=5, min_child_weight=1, n_estimators=750, scale_pos_weight=1.835641617165995, subsample=1.040868665682296; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0310981865013433, gamma=0.1270120612200643, lambda=0.5213628351828231, learning_rate=0.07383408369452026, max_depth=5, min_child_weight=1, n_estimators=750, scale_pos_weight=1.835641617165995, subsample=1.040868665682296; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4204552930392003, gamma=0.4180707758167877, lambda=1.1153868849566169, learning_rate=0.03708484833176872, max_depth=8, min_child_weight=1, n_estimators=450, scale_pos_weight=2.1721040174391266, subsample=1.588510592533956; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4204552930392003, gamma=0.4180707758167877, lambda=1.1153868849566169, learning_rate=0.03708484833176872, max_depth=8, min_child_weight=1, n_estimators=450, scale_pos_weight=2.1721040174391266, subsample=1.588510592533956; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4204552930392003, gamma=0.4180707758167877, lambda=1.1153868849566169, learning_rate=0.03708484833176872, max_depth=8, min_child_weight=1, n_estimators=450, scale_pos_weight=2.1721040174391266, subsample=1.588510592533956; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4204552930392003, gamma=0.4180707758167877, lambda=1.1153868849566169, learning_rate=0.03708484833176872, max_depth=8, min_child_weight=1, n_estimators=450, scale_pos_weight=2.1721040174391266, subsample=1.588510592533956; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.5040522540375898, gamma=0.022436012712393927, lambda=0.5261362812376211, learning_rate=0.40207255718621565, max_depth=8, min_child_weight=3, n_estimators=600, scale_pos_weight=1.1873943608823132, subsample=1.5103276355744488; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.5040522540375898, gamma=0.022436012712393927, lambda=0.5261362812376211, learning_rate=0.40207255718621565, max_depth=8, min_child_weight=3, n_estimators=600, scale_pos_weight=1.1873943608823132, subsample=1.5103276355744488; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.5040522540375898, gamma=0.022436012712393927, lambda=0.5261362812376211, learning_rate=0.40207255718621565, max_depth=8, min_child_weight=3, n_estimators=600, scale_pos_weight=1.1873943608823132, subsample=1.5103276355744488; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.5040522540375898, gamma=0.022436012712393927, lambda=0.5261362812376211, learning_rate=0.40207255718621565, max_depth=8, min_child_weight=3, n_estimators=600, scale_pos_weight=1.1873943608823132, subsample=1.5103276355744488; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5452821328239641, gamma=0.39125150629173283, lambda=0.5750796838406341, learning_rate=0.14906403956109726, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=2.701486127270752, subsample=0.6464267410880227; total time=   0.3s\n",
      "[CV] END alpha=15, colsample_bytree=0.5452821328239641, gamma=0.39125150629173283, lambda=0.5750796838406341, learning_rate=0.14906403956109726, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=2.701486127270752, subsample=0.6464267410880227; total time=   0.2s\n",
      "[CV] END alpha=15, colsample_bytree=0.5452821328239641, gamma=0.39125150629173283, lambda=0.5750796838406341, learning_rate=0.14906403956109726, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=2.701486127270752, subsample=0.6464267410880227; total time=   0.3s\n",
      "[CV] END alpha=15, colsample_bytree=0.5452821328239641, gamma=0.39125150629173283, lambda=0.5750796838406341, learning_rate=0.14906403956109726, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=2.701486127270752, subsample=0.6464267410880227; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=0.7645312989747721, gamma=0.17931838192264826, lambda=0.029737221135111458, learning_rate=0.18485457230504304, max_depth=11, min_child_weight=3, n_estimators=450, scale_pos_weight=0.7846231196263934, subsample=0.6469519855861371; total time=   0.5s\n",
      "[CV] END alpha=10, colsample_bytree=0.7645312989747721, gamma=0.17931838192264826, lambda=0.029737221135111458, learning_rate=0.18485457230504304, max_depth=11, min_child_weight=3, n_estimators=450, scale_pos_weight=0.7846231196263934, subsample=0.6469519855861371; total time=   0.7s\n",
      "[CV] END alpha=10, colsample_bytree=0.7645312989747721, gamma=0.17931838192264826, lambda=0.029737221135111458, learning_rate=0.18485457230504304, max_depth=11, min_child_weight=3, n_estimators=450, scale_pos_weight=0.7846231196263934, subsample=0.6469519855861371; total time=   0.5s\n",
      "[CV] END alpha=10, colsample_bytree=0.7645312989747721, gamma=0.17931838192264826, lambda=0.029737221135111458, learning_rate=0.18485457230504304, max_depth=11, min_child_weight=3, n_estimators=450, scale_pos_weight=0.7846231196263934, subsample=0.6469519855861371; total time=   0.4s\n",
      "[CV] END alpha=15, colsample_bytree=0.9873577087911134, gamma=0.1008774723063115, lambda=1.1924791525278335, learning_rate=0.14460482071956426, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=0.8208913231510979, subsample=1.4025614595127145; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9873577087911134, gamma=0.1008774723063115, lambda=1.1924791525278335, learning_rate=0.14460482071956426, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=0.8208913231510979, subsample=1.4025614595127145; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9873577087911134, gamma=0.1008774723063115, lambda=1.1924791525278335, learning_rate=0.14460482071956426, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=0.8208913231510979, subsample=1.4025614595127145; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9873577087911134, gamma=0.1008774723063115, lambda=1.1924791525278335, learning_rate=0.14460482071956426, max_depth=10, min_child_weight=3, n_estimators=450, scale_pos_weight=0.8208913231510979, subsample=1.4025614595127145; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1407852992783558, gamma=0.3079065419811778, lambda=1.123439565177691, learning_rate=0.23824089008913446, max_depth=7, min_child_weight=3, n_estimators=650, scale_pos_weight=1.7320583288202838, subsample=0.8478927299181723; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1407852992783558, gamma=0.3079065419811778, lambda=1.123439565177691, learning_rate=0.23824089008913446, max_depth=7, min_child_weight=3, n_estimators=650, scale_pos_weight=1.7320583288202838, subsample=0.8478927299181723; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1407852992783558, gamma=0.3079065419811778, lambda=1.123439565177691, learning_rate=0.23824089008913446, max_depth=7, min_child_weight=3, n_estimators=650, scale_pos_weight=1.7320583288202838, subsample=0.8478927299181723; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.1407852992783558, gamma=0.3079065419811778, lambda=1.123439565177691, learning_rate=0.23824089008913446, max_depth=7, min_child_weight=3, n_estimators=650, scale_pos_weight=1.7320583288202838, subsample=0.8478927299181723; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.7057555011212331, gamma=0.3925741770231251, lambda=0.9221864291835207, learning_rate=0.04115490374474478, max_depth=10, min_child_weight=3, n_estimators=500, scale_pos_weight=1.017295541223042, subsample=1.4320370622062837; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.7057555011212331, gamma=0.3925741770231251, lambda=0.9221864291835207, learning_rate=0.04115490374474478, max_depth=10, min_child_weight=3, n_estimators=500, scale_pos_weight=1.017295541223042, subsample=1.4320370622062837; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.7057555011212331, gamma=0.3925741770231251, lambda=0.9221864291835207, learning_rate=0.04115490374474478, max_depth=10, min_child_weight=3, n_estimators=500, scale_pos_weight=1.017295541223042, subsample=1.4320370622062837; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.7057555011212331, gamma=0.3925741770231251, lambda=0.9221864291835207, learning_rate=0.04115490374474478, max_depth=10, min_child_weight=3, n_estimators=500, scale_pos_weight=1.017295541223042, subsample=1.4320370622062837; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.2659397088163687, gamma=0.06432618152746866, lambda=0.9416800998811931, learning_rate=0.09660647689263695, max_depth=9, min_child_weight=1, n_estimators=400, scale_pos_weight=1.8701278747628274, subsample=0.741294176532136; total time=   0.6s\n",
      "[CV] END alpha=15, colsample_bytree=0.2659397088163687, gamma=0.06432618152746866, lambda=0.9416800998811931, learning_rate=0.09660647689263695, max_depth=9, min_child_weight=1, n_estimators=400, scale_pos_weight=1.8701278747628274, subsample=0.741294176532136; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.2659397088163687, gamma=0.06432618152746866, lambda=0.9416800998811931, learning_rate=0.09660647689263695, max_depth=9, min_child_weight=1, n_estimators=400, scale_pos_weight=1.8701278747628274, subsample=0.741294176532136; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.2659397088163687, gamma=0.06432618152746866, lambda=0.9416800998811931, learning_rate=0.09660647689263695, max_depth=9, min_child_weight=1, n_estimators=400, scale_pos_weight=1.8701278747628274, subsample=0.741294176532136; total time=   0.5s\n",
      "[CV] END alpha=25, colsample_bytree=0.5239008823057745, gamma=0.01888295385179256, lambda=0.6641450343275952, learning_rate=0.1946737017717825, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=2.1952796885761288, subsample=1.0309216095135803; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5239008823057745, gamma=0.01888295385179256, lambda=0.6641450343275952, learning_rate=0.1946737017717825, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=2.1952796885761288, subsample=1.0309216095135803; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5239008823057745, gamma=0.01888295385179256, lambda=0.6641450343275952, learning_rate=0.1946737017717825, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=2.1952796885761288, subsample=1.0309216095135803; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.5239008823057745, gamma=0.01888295385179256, lambda=0.6641450343275952, learning_rate=0.1946737017717825, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=2.1952796885761288, subsample=1.0309216095135803; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.597589756492759, gamma=0.016207426977653594, lambda=1.2818318414701186, learning_rate=0.16303699485904088, max_depth=7, min_child_weight=1, n_estimators=700, scale_pos_weight=2.4292581996206923, subsample=0.9416872398778537; total time=   0.7s\n",
      "[CV] END alpha=15, colsample_bytree=0.597589756492759, gamma=0.016207426977653594, lambda=1.2818318414701186, learning_rate=0.16303699485904088, max_depth=7, min_child_weight=1, n_estimators=700, scale_pos_weight=2.4292581996206923, subsample=0.9416872398778537; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.597589756492759, gamma=0.016207426977653594, lambda=1.2818318414701186, learning_rate=0.16303699485904088, max_depth=7, min_child_weight=1, n_estimators=700, scale_pos_weight=2.4292581996206923, subsample=0.9416872398778537; total time=   0.5s\n",
      "[CV] END alpha=15, colsample_bytree=0.597589756492759, gamma=0.016207426977653594, lambda=1.2818318414701186, learning_rate=0.16303699485904088, max_depth=7, min_child_weight=1, n_estimators=700, scale_pos_weight=2.4292581996206923, subsample=0.9416872398778537; total time=   0.6s\n",
      "[CV] END alpha=5, colsample_bytree=0.4338845422192014, gamma=0.20777695793553302, lambda=0.4521715789449947, learning_rate=0.19441366445221436, max_depth=8, min_child_weight=3, n_estimators=400, scale_pos_weight=2.005587234564498, subsample=0.7811214336757842; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.4338845422192014, gamma=0.20777695793553302, lambda=0.4521715789449947, learning_rate=0.19441366445221436, max_depth=8, min_child_weight=3, n_estimators=400, scale_pos_weight=2.005587234564498, subsample=0.7811214336757842; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.4338845422192014, gamma=0.20777695793553302, lambda=0.4521715789449947, learning_rate=0.19441366445221436, max_depth=8, min_child_weight=3, n_estimators=400, scale_pos_weight=2.005587234564498, subsample=0.7811214336757842; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.4338845422192014, gamma=0.20777695793553302, lambda=0.4521715789449947, learning_rate=0.19441366445221436, max_depth=8, min_child_weight=3, n_estimators=400, scale_pos_weight=2.005587234564498, subsample=0.7811214336757842; total time=   0.5s\n",
      "[CV] END alpha=5, colsample_bytree=0.8436049619550636, gamma=0.3006616151025198, lambda=0.5608701797541964, learning_rate=0.4962998498553765, max_depth=6, min_child_weight=3, n_estimators=600, scale_pos_weight=0.8108194623374184, subsample=1.3703293097307285; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8436049619550636, gamma=0.3006616151025198, lambda=0.5608701797541964, learning_rate=0.4962998498553765, max_depth=6, min_child_weight=3, n_estimators=600, scale_pos_weight=0.8108194623374184, subsample=1.3703293097307285; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8436049619550636, gamma=0.3006616151025198, lambda=0.5608701797541964, learning_rate=0.4962998498553765, max_depth=6, min_child_weight=3, n_estimators=600, scale_pos_weight=0.8108194623374184, subsample=1.3703293097307285; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.8436049619550636, gamma=0.3006616151025198, lambda=0.5608701797541964, learning_rate=0.4962998498553765, max_depth=6, min_child_weight=3, n_estimators=600, scale_pos_weight=0.8108194623374184, subsample=1.3703293097307285; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.9017693701200185, gamma=0.2505918136265169, lambda=1.1441171167759427, learning_rate=0.2429512891982447, max_depth=5, min_child_weight=3, n_estimators=550, scale_pos_weight=1.594281471865089, subsample=0.8821198201249667; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.9017693701200185, gamma=0.2505918136265169, lambda=1.1441171167759427, learning_rate=0.2429512891982447, max_depth=5, min_child_weight=3, n_estimators=550, scale_pos_weight=1.594281471865089, subsample=0.8821198201249667; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.9017693701200185, gamma=0.2505918136265169, lambda=1.1441171167759427, learning_rate=0.2429512891982447, max_depth=5, min_child_weight=3, n_estimators=550, scale_pos_weight=1.594281471865089, subsample=0.8821198201249667; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.9017693701200185, gamma=0.2505918136265169, lambda=1.1441171167759427, learning_rate=0.2429512891982447, max_depth=5, min_child_weight=3, n_estimators=550, scale_pos_weight=1.594281471865089, subsample=0.8821198201249667; total time=   0.3s\n",
      "[CV] END alpha=20, colsample_bytree=0.20449011238334008, gamma=0.429952846216533, lambda=1.0036909398372256, learning_rate=0.31924096083876247, max_depth=9, min_child_weight=3, n_estimators=750, scale_pos_weight=2.558806355451839, subsample=1.0056695871335455; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.20449011238334008, gamma=0.429952846216533, lambda=1.0036909398372256, learning_rate=0.31924096083876247, max_depth=9, min_child_weight=3, n_estimators=750, scale_pos_weight=2.558806355451839, subsample=1.0056695871335455; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.20449011238334008, gamma=0.429952846216533, lambda=1.0036909398372256, learning_rate=0.31924096083876247, max_depth=9, min_child_weight=3, n_estimators=750, scale_pos_weight=2.558806355451839, subsample=1.0056695871335455; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.20449011238334008, gamma=0.429952846216533, lambda=1.0036909398372256, learning_rate=0.31924096083876247, max_depth=9, min_child_weight=3, n_estimators=750, scale_pos_weight=2.558806355451839, subsample=1.0056695871335455; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0097387269184173, gamma=0.28401946063028055, lambda=0.22704578858666874, learning_rate=0.3911883641359672, max_depth=9, min_child_weight=1, n_estimators=350, scale_pos_weight=1.0831615853652041, subsample=1.3812343705032004; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0097387269184173, gamma=0.28401946063028055, lambda=0.22704578858666874, learning_rate=0.3911883641359672, max_depth=9, min_child_weight=1, n_estimators=350, scale_pos_weight=1.0831615853652041, subsample=1.3812343705032004; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0097387269184173, gamma=0.28401946063028055, lambda=0.22704578858666874, learning_rate=0.3911883641359672, max_depth=9, min_child_weight=1, n_estimators=350, scale_pos_weight=1.0831615853652041, subsample=1.3812343705032004; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0097387269184173, gamma=0.28401946063028055, lambda=0.22704578858666874, learning_rate=0.3911883641359672, max_depth=9, min_child_weight=1, n_estimators=350, scale_pos_weight=1.0831615853652041, subsample=1.3812343705032004; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.7472478137645133, gamma=0.1749823325688447, lambda=0.8371111184135649, learning_rate=0.33982308712609127, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=2.071769706265855, subsample=1.1630962049420628; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.7472478137645133, gamma=0.1749823325688447, lambda=0.8371111184135649, learning_rate=0.33982308712609127, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=2.071769706265855, subsample=1.1630962049420628; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.7472478137645133, gamma=0.1749823325688447, lambda=0.8371111184135649, learning_rate=0.33982308712609127, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=2.071769706265855, subsample=1.1630962049420628; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.7472478137645133, gamma=0.1749823325688447, lambda=0.8371111184135649, learning_rate=0.33982308712609127, max_depth=7, min_child_weight=1, n_estimators=750, scale_pos_weight=2.071769706265855, subsample=1.1630962049420628; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.9463693373163868, gamma=0.17031280702518697, lambda=1.463364194998271, learning_rate=0.4541048772474763, max_depth=11, min_child_weight=3, n_estimators=550, scale_pos_weight=0.7219158395625275, subsample=1.0446431364910815; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.9463693373163868, gamma=0.17031280702518697, lambda=1.463364194998271, learning_rate=0.4541048772474763, max_depth=11, min_child_weight=3, n_estimators=550, scale_pos_weight=0.7219158395625275, subsample=1.0446431364910815; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.9463693373163868, gamma=0.17031280702518697, lambda=1.463364194998271, learning_rate=0.4541048772474763, max_depth=11, min_child_weight=3, n_estimators=550, scale_pos_weight=0.7219158395625275, subsample=1.0446431364910815; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.9463693373163868, gamma=0.17031280702518697, lambda=1.463364194998271, learning_rate=0.4541048772474763, max_depth=11, min_child_weight=3, n_estimators=550, scale_pos_weight=0.7219158395625275, subsample=1.0446431364910815; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.6872881351439686, gamma=0.38122179433432635, lambda=0.6966964628276239, learning_rate=0.4584085474675037, max_depth=6, min_child_weight=3, n_estimators=550, scale_pos_weight=2.0930657087764604, subsample=0.6313696003949528; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.6872881351439686, gamma=0.38122179433432635, lambda=0.6966964628276239, learning_rate=0.4584085474675037, max_depth=6, min_child_weight=3, n_estimators=550, scale_pos_weight=2.0930657087764604, subsample=0.6313696003949528; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.6872881351439686, gamma=0.38122179433432635, lambda=0.6966964628276239, learning_rate=0.4584085474675037, max_depth=6, min_child_weight=3, n_estimators=550, scale_pos_weight=2.0930657087764604, subsample=0.6313696003949528; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.6872881351439686, gamma=0.38122179433432635, lambda=0.6966964628276239, learning_rate=0.4584085474675037, max_depth=6, min_child_weight=3, n_estimators=550, scale_pos_weight=2.0930657087764604, subsample=0.6313696003949528; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=0.6882485711432549, gamma=0.17289922003339764, lambda=0.9870690948993686, learning_rate=0.2175127157568077, max_depth=9, min_child_weight=1, n_estimators=450, scale_pos_weight=2.044356990638863, subsample=1.0578744093635013; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6882485711432549, gamma=0.17289922003339764, lambda=0.9870690948993686, learning_rate=0.2175127157568077, max_depth=9, min_child_weight=1, n_estimators=450, scale_pos_weight=2.044356990638863, subsample=1.0578744093635013; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6882485711432549, gamma=0.17289922003339764, lambda=0.9870690948993686, learning_rate=0.2175127157568077, max_depth=9, min_child_weight=1, n_estimators=450, scale_pos_weight=2.044356990638863, subsample=1.0578744093635013; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.6882485711432549, gamma=0.17289922003339764, lambda=0.9870690948993686, learning_rate=0.2175127157568077, max_depth=9, min_child_weight=1, n_estimators=450, scale_pos_weight=2.044356990638863, subsample=1.0578744093635013; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.101467497133885, gamma=0.031052615894804902, lambda=1.2874936150064213, learning_rate=0.08339888919905335, max_depth=8, min_child_weight=1, n_estimators=400, scale_pos_weight=1.4400680363736909, subsample=0.873061714246076; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.101467497133885, gamma=0.031052615894804902, lambda=1.2874936150064213, learning_rate=0.08339888919905335, max_depth=8, min_child_weight=1, n_estimators=400, scale_pos_weight=1.4400680363736909, subsample=0.873061714246076; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.101467497133885, gamma=0.031052615894804902, lambda=1.2874936150064213, learning_rate=0.08339888919905335, max_depth=8, min_child_weight=1, n_estimators=400, scale_pos_weight=1.4400680363736909, subsample=0.873061714246076; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.101467497133885, gamma=0.031052615894804902, lambda=1.2874936150064213, learning_rate=0.08339888919905335, max_depth=8, min_child_weight=1, n_estimators=400, scale_pos_weight=1.4400680363736909, subsample=0.873061714246076; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9730899499319041, gamma=0.17448123868957294, lambda=1.0058968999495876, learning_rate=0.46185653263215753, max_depth=5, min_child_weight=3, n_estimators=250, scale_pos_weight=2.653217074449267, subsample=1.1739973450682348; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9730899499319041, gamma=0.17448123868957294, lambda=1.0058968999495876, learning_rate=0.46185653263215753, max_depth=5, min_child_weight=3, n_estimators=250, scale_pos_weight=2.653217074449267, subsample=1.1739973450682348; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9730899499319041, gamma=0.17448123868957294, lambda=1.0058968999495876, learning_rate=0.46185653263215753, max_depth=5, min_child_weight=3, n_estimators=250, scale_pos_weight=2.653217074449267, subsample=1.1739973450682348; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9730899499319041, gamma=0.17448123868957294, lambda=1.0058968999495876, learning_rate=0.46185653263215753, max_depth=5, min_child_weight=3, n_estimators=250, scale_pos_weight=2.653217074449267, subsample=1.1739973450682348; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.29404626796338246, gamma=0.3771874162090822, lambda=0.62211167155737, learning_rate=0.4040208986499895, max_depth=8, min_child_weight=1, n_estimators=200, scale_pos_weight=0.7647458582280894, subsample=1.0393367976303065; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.29404626796338246, gamma=0.3771874162090822, lambda=0.62211167155737, learning_rate=0.4040208986499895, max_depth=8, min_child_weight=1, n_estimators=200, scale_pos_weight=0.7647458582280894, subsample=1.0393367976303065; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.29404626796338246, gamma=0.3771874162090822, lambda=0.62211167155737, learning_rate=0.4040208986499895, max_depth=8, min_child_weight=1, n_estimators=200, scale_pos_weight=0.7647458582280894, subsample=1.0393367976303065; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.29404626796338246, gamma=0.3771874162090822, lambda=0.62211167155737, learning_rate=0.4040208986499895, max_depth=8, min_child_weight=1, n_estimators=200, scale_pos_weight=0.7647458582280894, subsample=1.0393367976303065; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.7397894313152849, gamma=0.2974538834693633, lambda=0.679479271270407, learning_rate=0.13667925329442243, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=1.5078152386025845, subsample=0.9221346269613853; total time=   0.5s\n",
      "[CV] END alpha=10, colsample_bytree=0.7397894313152849, gamma=0.2974538834693633, lambda=0.679479271270407, learning_rate=0.13667925329442243, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=1.5078152386025845, subsample=0.9221346269613853; total time=   0.4s\n",
      "[CV] END alpha=10, colsample_bytree=0.7397894313152849, gamma=0.2974538834693633, lambda=0.679479271270407, learning_rate=0.13667925329442243, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=1.5078152386025845, subsample=0.9221346269613853; total time=   0.5s\n",
      "[CV] END alpha=10, colsample_bytree=0.7397894313152849, gamma=0.2974538834693633, lambda=0.679479271270407, learning_rate=0.13667925329442243, max_depth=7, min_child_weight=3, n_estimators=700, scale_pos_weight=1.5078152386025845, subsample=0.9221346269613853; total time=   0.4s\n",
      "[CV] END alpha=10, colsample_bytree=0.600859839520433, gamma=0.07503055190683433, lambda=1.268104948623788, learning_rate=0.33880929380482333, max_depth=9, min_child_weight=1, n_estimators=400, scale_pos_weight=0.8444247314614111, subsample=1.0944272275497084; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.600859839520433, gamma=0.07503055190683433, lambda=1.268104948623788, learning_rate=0.33880929380482333, max_depth=9, min_child_weight=1, n_estimators=400, scale_pos_weight=0.8444247314614111, subsample=1.0944272275497084; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.600859839520433, gamma=0.07503055190683433, lambda=1.268104948623788, learning_rate=0.33880929380482333, max_depth=9, min_child_weight=1, n_estimators=400, scale_pos_weight=0.8444247314614111, subsample=1.0944272275497084; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.600859839520433, gamma=0.07503055190683433, lambda=1.268104948623788, learning_rate=0.33880929380482333, max_depth=9, min_child_weight=1, n_estimators=400, scale_pos_weight=0.8444247314614111, subsample=1.0944272275497084; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.41930627702281814, gamma=0.20974826076001712, lambda=1.104193374752081, learning_rate=0.15295609967385043, max_depth=8, min_child_weight=1, n_estimators=350, scale_pos_weight=0.9387276969315297, subsample=1.1464520588289975; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.41930627702281814, gamma=0.20974826076001712, lambda=1.104193374752081, learning_rate=0.15295609967385043, max_depth=8, min_child_weight=1, n_estimators=350, scale_pos_weight=0.9387276969315297, subsample=1.1464520588289975; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.41930627702281814, gamma=0.20974826076001712, lambda=1.104193374752081, learning_rate=0.15295609967385043, max_depth=8, min_child_weight=1, n_estimators=350, scale_pos_weight=0.9387276969315297, subsample=1.1464520588289975; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.41930627702281814, gamma=0.20974826076001712, lambda=1.104193374752081, learning_rate=0.15295609967385043, max_depth=8, min_child_weight=1, n_estimators=350, scale_pos_weight=0.9387276969315297, subsample=1.1464520588289975; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1942392985457868, gamma=0.006419919503378224, lambda=0.0612811858834742, learning_rate=0.3267868636925063, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=2.621046285041954, subsample=0.7588422281063435; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1942392985457868, gamma=0.006419919503378224, lambda=0.0612811858834742, learning_rate=0.3267868636925063, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=2.621046285041954, subsample=0.7588422281063435; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1942392985457868, gamma=0.006419919503378224, lambda=0.0612811858834742, learning_rate=0.3267868636925063, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=2.621046285041954, subsample=0.7588422281063435; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1942392985457868, gamma=0.006419919503378224, lambda=0.0612811858834742, learning_rate=0.3267868636925063, max_depth=5, min_child_weight=1, n_estimators=200, scale_pos_weight=2.621046285041954, subsample=0.7588422281063435; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.6818472282868231, gamma=0.4283693883567359, lambda=0.09360777032848949, learning_rate=0.10438581934462597, max_depth=10, min_child_weight=1, n_estimators=250, scale_pos_weight=1.778477293702936, subsample=1.1483428514476066; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.6818472282868231, gamma=0.4283693883567359, lambda=0.09360777032848949, learning_rate=0.10438581934462597, max_depth=10, min_child_weight=1, n_estimators=250, scale_pos_weight=1.778477293702936, subsample=1.1483428514476066; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.6818472282868231, gamma=0.4283693883567359, lambda=0.09360777032848949, learning_rate=0.10438581934462597, max_depth=10, min_child_weight=1, n_estimators=250, scale_pos_weight=1.778477293702936, subsample=1.1483428514476066; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.6818472282868231, gamma=0.4283693883567359, lambda=0.09360777032848949, learning_rate=0.10438581934462597, max_depth=10, min_child_weight=1, n_estimators=250, scale_pos_weight=1.778477293702936, subsample=1.1483428514476066; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.3269725538279125, gamma=0.07723366705001905, lambda=0.7849858001868459, learning_rate=0.30819129577704685, max_depth=11, min_child_weight=1, n_estimators=400, scale_pos_weight=1.328024917454433, subsample=1.2342670835139757; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.3269725538279125, gamma=0.07723366705001905, lambda=0.7849858001868459, learning_rate=0.30819129577704685, max_depth=11, min_child_weight=1, n_estimators=400, scale_pos_weight=1.328024917454433, subsample=1.2342670835139757; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.3269725538279125, gamma=0.07723366705001905, lambda=0.7849858001868459, learning_rate=0.30819129577704685, max_depth=11, min_child_weight=1, n_estimators=400, scale_pos_weight=1.328024917454433, subsample=1.2342670835139757; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.3269725538279125, gamma=0.07723366705001905, lambda=0.7849858001868459, learning_rate=0.30819129577704685, max_depth=11, min_child_weight=1, n_estimators=400, scale_pos_weight=1.328024917454433, subsample=1.2342670835139757; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.9562800943628273, gamma=0.11405676293670247, lambda=1.2228410383000474, learning_rate=0.23812741808738458, max_depth=8, min_child_weight=3, n_estimators=250, scale_pos_weight=2.4133060705137446, subsample=0.7436896164114284; total time=   0.4s\n",
      "[CV] END alpha=20, colsample_bytree=0.9562800943628273, gamma=0.11405676293670247, lambda=1.2228410383000474, learning_rate=0.23812741808738458, max_depth=8, min_child_weight=3, n_estimators=250, scale_pos_weight=2.4133060705137446, subsample=0.7436896164114284; total time=   0.4s\n",
      "[CV] END alpha=20, colsample_bytree=0.9562800943628273, gamma=0.11405676293670247, lambda=1.2228410383000474, learning_rate=0.23812741808738458, max_depth=8, min_child_weight=3, n_estimators=250, scale_pos_weight=2.4133060705137446, subsample=0.7436896164114284; total time=   0.4s\n",
      "[CV] END alpha=20, colsample_bytree=0.9562800943628273, gamma=0.11405676293670247, lambda=1.2228410383000474, learning_rate=0.23812741808738458, max_depth=8, min_child_weight=3, n_estimators=250, scale_pos_weight=2.4133060705137446, subsample=0.7436896164114284; total time=   0.4s\n",
      "[CV] END alpha=20, colsample_bytree=0.358612334316417, gamma=0.18629376562349903, lambda=1.3709505572318772, learning_rate=0.20742084808244948, max_depth=9, min_child_weight=1, n_estimators=400, scale_pos_weight=0.7600674016905389, subsample=0.8956763200920009; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.358612334316417, gamma=0.18629376562349903, lambda=1.3709505572318772, learning_rate=0.20742084808244948, max_depth=9, min_child_weight=1, n_estimators=400, scale_pos_weight=0.7600674016905389, subsample=0.8956763200920009; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.358612334316417, gamma=0.18629376562349903, lambda=1.3709505572318772, learning_rate=0.20742084808244948, max_depth=9, min_child_weight=1, n_estimators=400, scale_pos_weight=0.7600674016905389, subsample=0.8956763200920009; total time=   0.2s\n",
      "[CV] END alpha=20, colsample_bytree=0.358612334316417, gamma=0.18629376562349903, lambda=1.3709505572318772, learning_rate=0.20742084808244948, max_depth=9, min_child_weight=1, n_estimators=400, scale_pos_weight=0.7600674016905389, subsample=0.8956763200920009; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=0.4832374774869948, gamma=0.22522734563539876, lambda=0.5523817956629349, learning_rate=0.02810747674278046, max_depth=11, min_child_weight=1, n_estimators=250, scale_pos_weight=1.5436775097772406, subsample=1.4714391175971482; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4832374774869948, gamma=0.22522734563539876, lambda=0.5523817956629349, learning_rate=0.02810747674278046, max_depth=11, min_child_weight=1, n_estimators=250, scale_pos_weight=1.5436775097772406, subsample=1.4714391175971482; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4832374774869948, gamma=0.22522734563539876, lambda=0.5523817956629349, learning_rate=0.02810747674278046, max_depth=11, min_child_weight=1, n_estimators=250, scale_pos_weight=1.5436775097772406, subsample=1.4714391175971482; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.4832374774869948, gamma=0.22522734563539876, lambda=0.5523817956629349, learning_rate=0.02810747674278046, max_depth=11, min_child_weight=1, n_estimators=250, scale_pos_weight=1.5436775097772406, subsample=1.4714391175971482; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0419049931401607, gamma=0.4553219893010962, lambda=0.5068167490635705, learning_rate=0.28662391116269065, max_depth=6, min_child_weight=3, n_estimators=650, scale_pos_weight=0.9018937967114704, subsample=0.8821234909985952; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0419049931401607, gamma=0.4553219893010962, lambda=0.5068167490635705, learning_rate=0.28662391116269065, max_depth=6, min_child_weight=3, n_estimators=650, scale_pos_weight=0.9018937967114704, subsample=0.8821234909985952; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0419049931401607, gamma=0.4553219893010962, lambda=0.5068167490635705, learning_rate=0.28662391116269065, max_depth=6, min_child_weight=3, n_estimators=650, scale_pos_weight=0.9018937967114704, subsample=0.8821234909985952; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=1.0419049931401607, gamma=0.4553219893010962, lambda=0.5068167490635705, learning_rate=0.28662391116269065, max_depth=6, min_child_weight=3, n_estimators=650, scale_pos_weight=0.9018937967114704, subsample=0.8821234909985952; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.9767835856859961, gamma=0.006494773994904834, lambda=0.41505331419327157, learning_rate=0.0366862317652411, max_depth=11, min_child_weight=1, n_estimators=450, scale_pos_weight=2.723852388027338, subsample=1.214553052294792; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.9767835856859961, gamma=0.006494773994904834, lambda=0.41505331419327157, learning_rate=0.0366862317652411, max_depth=11, min_child_weight=1, n_estimators=450, scale_pos_weight=2.723852388027338, subsample=1.214553052294792; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.9767835856859961, gamma=0.006494773994904834, lambda=0.41505331419327157, learning_rate=0.0366862317652411, max_depth=11, min_child_weight=1, n_estimators=450, scale_pos_weight=2.723852388027338, subsample=1.214553052294792; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.9767835856859961, gamma=0.006494773994904834, lambda=0.41505331419327157, learning_rate=0.0366862317652411, max_depth=11, min_child_weight=1, n_estimators=450, scale_pos_weight=2.723852388027338, subsample=1.214553052294792; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1070502678381045, gamma=0.2266450718354036, lambda=1.3417525303796134, learning_rate=0.452131326302475, max_depth=11, min_child_weight=1, n_estimators=750, scale_pos_weight=1.0369258975131062, subsample=0.6493740077162073; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1070502678381045, gamma=0.2266450718354036, lambda=1.3417525303796134, learning_rate=0.452131326302475, max_depth=11, min_child_weight=1, n_estimators=750, scale_pos_weight=1.0369258975131062, subsample=0.6493740077162073; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1070502678381045, gamma=0.2266450718354036, lambda=1.3417525303796134, learning_rate=0.452131326302475, max_depth=11, min_child_weight=1, n_estimators=750, scale_pos_weight=1.0369258975131062, subsample=0.6493740077162073; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1070502678381045, gamma=0.2266450718354036, lambda=1.3417525303796134, learning_rate=0.452131326302475, max_depth=11, min_child_weight=1, n_estimators=750, scale_pos_weight=1.0369258975131062, subsample=0.6493740077162073; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.6006605994196872, gamma=0.13530327068837916, lambda=1.1667708073771699, learning_rate=0.20409084888385903, max_depth=6, min_child_weight=1, n_estimators=450, scale_pos_weight=2.1934132091627223, subsample=0.9333198249282924; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.6006605994196872, gamma=0.13530327068837916, lambda=1.1667708073771699, learning_rate=0.20409084888385903, max_depth=6, min_child_weight=1, n_estimators=450, scale_pos_weight=2.1934132091627223, subsample=0.9333198249282924; total time=   0.2s\n",
      "[CV] END alpha=25, colsample_bytree=0.6006605994196872, gamma=0.13530327068837916, lambda=1.1667708073771699, learning_rate=0.20409084888385903, max_depth=6, min_child_weight=1, n_estimators=450, scale_pos_weight=2.1934132091627223, subsample=0.9333198249282924; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.6006605994196872, gamma=0.13530327068837916, lambda=1.1667708073771699, learning_rate=0.20409084888385903, max_depth=6, min_child_weight=1, n_estimators=450, scale_pos_weight=2.1934132091627223, subsample=0.9333198249282924; total time=   0.2s\n",
      "[CV] END alpha=10, colsample_bytree=1.1895498619447145, gamma=0.32820984684434834, lambda=0.8317129410983959, learning_rate=0.1947504506849581, max_depth=8, min_child_weight=1, n_estimators=650, scale_pos_weight=2.146725159788387, subsample=1.1778341639073582; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1895498619447145, gamma=0.32820984684434834, lambda=0.8317129410983959, learning_rate=0.1947504506849581, max_depth=8, min_child_weight=1, n_estimators=650, scale_pos_weight=2.146725159788387, subsample=1.1778341639073582; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1895498619447145, gamma=0.32820984684434834, lambda=0.8317129410983959, learning_rate=0.1947504506849581, max_depth=8, min_child_weight=1, n_estimators=650, scale_pos_weight=2.146725159788387, subsample=1.1778341639073582; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1895498619447145, gamma=0.32820984684434834, lambda=0.8317129410983959, learning_rate=0.1947504506849581, max_depth=8, min_child_weight=1, n_estimators=650, scale_pos_weight=2.146725159788387, subsample=1.1778341639073582; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0448340515132077, gamma=0.028193859476888683, lambda=1.3337821543565171, learning_rate=0.2437809181093688, max_depth=5, min_child_weight=3, n_estimators=200, scale_pos_weight=2.583406924340646, subsample=1.449370724824755; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0448340515132077, gamma=0.028193859476888683, lambda=1.3337821543565171, learning_rate=0.2437809181093688, max_depth=5, min_child_weight=3, n_estimators=200, scale_pos_weight=2.583406924340646, subsample=1.449370724824755; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0448340515132077, gamma=0.028193859476888683, lambda=1.3337821543565171, learning_rate=0.2437809181093688, max_depth=5, min_child_weight=3, n_estimators=200, scale_pos_weight=2.583406924340646, subsample=1.449370724824755; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=1.0448340515132077, gamma=0.028193859476888683, lambda=1.3337821543565171, learning_rate=0.2437809181093688, max_depth=5, min_child_weight=3, n_estimators=200, scale_pos_weight=2.583406924340646, subsample=1.449370724824755; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1927257814911538, gamma=0.3836680172642652, lambda=0.9021580183847482, learning_rate=0.14920772713676722, max_depth=6, min_child_weight=1, n_estimators=200, scale_pos_weight=1.2042237540197505, subsample=1.1149683021983838; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1927257814911538, gamma=0.3836680172642652, lambda=0.9021580183847482, learning_rate=0.14920772713676722, max_depth=6, min_child_weight=1, n_estimators=200, scale_pos_weight=1.2042237540197505, subsample=1.1149683021983838; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1927257814911538, gamma=0.3836680172642652, lambda=0.9021580183847482, learning_rate=0.14920772713676722, max_depth=6, min_child_weight=1, n_estimators=200, scale_pos_weight=1.2042237540197505, subsample=1.1149683021983838; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.1927257814911538, gamma=0.3836680172642652, lambda=0.9021580183847482, learning_rate=0.14920772713676722, max_depth=6, min_child_weight=1, n_estimators=200, scale_pos_weight=1.2042237540197505, subsample=1.1149683021983838; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.7538732730990887, gamma=0.4736881056580213, lambda=0.6109245665624365, learning_rate=0.44910411355018015, max_depth=9, min_child_weight=1, n_estimators=750, scale_pos_weight=1.9328751052533053, subsample=1.312709144016909; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.7538732730990887, gamma=0.4736881056580213, lambda=0.6109245665624365, learning_rate=0.44910411355018015, max_depth=9, min_child_weight=1, n_estimators=750, scale_pos_weight=1.9328751052533053, subsample=1.312709144016909; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.7538732730990887, gamma=0.4736881056580213, lambda=0.6109245665624365, learning_rate=0.44910411355018015, max_depth=9, min_child_weight=1, n_estimators=750, scale_pos_weight=1.9328751052533053, subsample=1.312709144016909; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.7538732730990887, gamma=0.4736881056580213, lambda=0.6109245665624365, learning_rate=0.44910411355018015, max_depth=9, min_child_weight=1, n_estimators=750, scale_pos_weight=1.9328751052533053, subsample=1.312709144016909; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0843622374540491, gamma=0.06389668047500652, lambda=0.009864452667959822, learning_rate=0.06130567981830808, max_depth=8, min_child_weight=1, n_estimators=400, scale_pos_weight=2.393690138404975, subsample=1.3910068366530208; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0843622374540491, gamma=0.06389668047500652, lambda=0.009864452667959822, learning_rate=0.06130567981830808, max_depth=8, min_child_weight=1, n_estimators=400, scale_pos_weight=2.393690138404975, subsample=1.3910068366530208; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0843622374540491, gamma=0.06389668047500652, lambda=0.009864452667959822, learning_rate=0.06130567981830808, max_depth=8, min_child_weight=1, n_estimators=400, scale_pos_weight=2.393690138404975, subsample=1.3910068366530208; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=1.0843622374540491, gamma=0.06389668047500652, lambda=0.009864452667959822, learning_rate=0.06130567981830808, max_depth=8, min_child_weight=1, n_estimators=400, scale_pos_weight=2.393690138404975, subsample=1.3910068366530208; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.27191950382159774, gamma=0.0699248735574341, lambda=1.4801220613716355, learning_rate=0.08898110257830398, max_depth=6, min_child_weight=3, n_estimators=550, scale_pos_weight=2.194250901593339, subsample=0.7375565364281109; total time=   1.3s\n",
      "[CV] END alpha=15, colsample_bytree=0.27191950382159774, gamma=0.0699248735574341, lambda=1.4801220613716355, learning_rate=0.08898110257830398, max_depth=6, min_child_weight=3, n_estimators=550, scale_pos_weight=2.194250901593339, subsample=0.7375565364281109; total time=   1.6s\n",
      "[CV] END alpha=15, colsample_bytree=0.27191950382159774, gamma=0.0699248735574341, lambda=1.4801220613716355, learning_rate=0.08898110257830398, max_depth=6, min_child_weight=3, n_estimators=550, scale_pos_weight=2.194250901593339, subsample=0.7375565364281109; total time=   1.2s\n",
      "[CV] END alpha=15, colsample_bytree=0.27191950382159774, gamma=0.0699248735574341, lambda=1.4801220613716355, learning_rate=0.08898110257830398, max_depth=6, min_child_weight=3, n_estimators=550, scale_pos_weight=2.194250901593339, subsample=0.7375565364281109; total time=   0.5s\n",
      "[CV] END alpha=25, colsample_bytree=0.4592639055722299, gamma=0.08472412290374376, lambda=0.455264291207783, learning_rate=0.2837641985218173, max_depth=6, min_child_weight=3, n_estimators=400, scale_pos_weight=1.1151694007360167, subsample=1.24421302950637; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.4592639055722299, gamma=0.08472412290374376, lambda=0.455264291207783, learning_rate=0.2837641985218173, max_depth=6, min_child_weight=3, n_estimators=400, scale_pos_weight=1.1151694007360167, subsample=1.24421302950637; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.4592639055722299, gamma=0.08472412290374376, lambda=0.455264291207783, learning_rate=0.2837641985218173, max_depth=6, min_child_weight=3, n_estimators=400, scale_pos_weight=1.1151694007360167, subsample=1.24421302950637; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.4592639055722299, gamma=0.08472412290374376, lambda=0.455264291207783, learning_rate=0.2837641985218173, max_depth=6, min_child_weight=3, n_estimators=400, scale_pos_weight=1.1151694007360167, subsample=1.24421302950637; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.3881397450535307, gamma=0.47506883989712473, lambda=0.853419093081683, learning_rate=0.4212154643345676, max_depth=10, min_child_weight=3, n_estimators=500, scale_pos_weight=0.9439832342418979, subsample=0.649146910620181; total time=   0.7s\n",
      "[CV] END alpha=15, colsample_bytree=0.3881397450535307, gamma=0.47506883989712473, lambda=0.853419093081683, learning_rate=0.4212154643345676, max_depth=10, min_child_weight=3, n_estimators=500, scale_pos_weight=0.9439832342418979, subsample=0.649146910620181; total time=   0.8s\n",
      "[CV] END alpha=15, colsample_bytree=0.3881397450535307, gamma=0.47506883989712473, lambda=0.853419093081683, learning_rate=0.4212154643345676, max_depth=10, min_child_weight=3, n_estimators=500, scale_pos_weight=0.9439832342418979, subsample=0.649146910620181; total time=   0.2s\n",
      "[CV] END alpha=15, colsample_bytree=0.3881397450535307, gamma=0.47506883989712473, lambda=0.853419093081683, learning_rate=0.4212154643345676, max_depth=10, min_child_weight=3, n_estimators=500, scale_pos_weight=0.9439832342418979, subsample=0.649146910620181; total time=   0.3s\n",
      "[CV] END alpha=10, colsample_bytree=1.1137627467957174, gamma=0.12694994210513932, lambda=1.1088307871791945, learning_rate=0.40371563582324005, max_depth=9, min_child_weight=3, n_estimators=250, scale_pos_weight=2.3177715719419583, subsample=0.9111048830871076; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1137627467957174, gamma=0.12694994210513932, lambda=1.1088307871791945, learning_rate=0.40371563582324005, max_depth=9, min_child_weight=3, n_estimators=250, scale_pos_weight=2.3177715719419583, subsample=0.9111048830871076; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1137627467957174, gamma=0.12694994210513932, lambda=1.1088307871791945, learning_rate=0.40371563582324005, max_depth=9, min_child_weight=3, n_estimators=250, scale_pos_weight=2.3177715719419583, subsample=0.9111048830871076; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.1137627467957174, gamma=0.12694994210513932, lambda=1.1088307871791945, learning_rate=0.40371563582324005, max_depth=9, min_child_weight=3, n_estimators=250, scale_pos_weight=2.3177715719419583, subsample=0.9111048830871076; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.3135304226306383, gamma=0.3812789957787366, lambda=0.730861366735511, learning_rate=0.11451501809523933, max_depth=5, min_child_weight=3, n_estimators=600, scale_pos_weight=1.418468862716039, subsample=1.0080580957388179; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.3135304226306383, gamma=0.3812789957787366, lambda=0.730861366735511, learning_rate=0.11451501809523933, max_depth=5, min_child_weight=3, n_estimators=600, scale_pos_weight=1.418468862716039, subsample=1.0080580957388179; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.3135304226306383, gamma=0.3812789957787366, lambda=0.730861366735511, learning_rate=0.11451501809523933, max_depth=5, min_child_weight=3, n_estimators=600, scale_pos_weight=1.418468862716039, subsample=1.0080580957388179; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.3135304226306383, gamma=0.3812789957787366, lambda=0.730861366735511, learning_rate=0.11451501809523933, max_depth=5, min_child_weight=3, n_estimators=600, scale_pos_weight=1.418468862716039, subsample=1.0080580957388179; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.4176246490365603, gamma=0.1586107182087444, lambda=0.32651592318184375, learning_rate=0.14570750914702213, max_depth=5, min_child_weight=3, n_estimators=700, scale_pos_weight=1.7728121254541274, subsample=1.5117317171891136; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.4176246490365603, gamma=0.1586107182087444, lambda=0.32651592318184375, learning_rate=0.14570750914702213, max_depth=5, min_child_weight=3, n_estimators=700, scale_pos_weight=1.7728121254541274, subsample=1.5117317171891136; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.4176246490365603, gamma=0.1586107182087444, lambda=0.32651592318184375, learning_rate=0.14570750914702213, max_depth=5, min_child_weight=3, n_estimators=700, scale_pos_weight=1.7728121254541274, subsample=1.5117317171891136; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.4176246490365603, gamma=0.1586107182087444, lambda=0.32651592318184375, learning_rate=0.14570750914702213, max_depth=5, min_child_weight=3, n_estimators=700, scale_pos_weight=1.7728121254541274, subsample=1.5117317171891136; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.5914200986241049, gamma=0.3567500277336191, lambda=0.8269992759123079, learning_rate=0.020431261500869984, max_depth=9, min_child_weight=1, n_estimators=300, scale_pos_weight=1.4252349858508673, subsample=1.0000498427917415; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.5914200986241049, gamma=0.3567500277336191, lambda=0.8269992759123079, learning_rate=0.020431261500869984, max_depth=9, min_child_weight=1, n_estimators=300, scale_pos_weight=1.4252349858508673, subsample=1.0000498427917415; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.5914200986241049, gamma=0.3567500277336191, lambda=0.8269992759123079, learning_rate=0.020431261500869984, max_depth=9, min_child_weight=1, n_estimators=300, scale_pos_weight=1.4252349858508673, subsample=1.0000498427917415; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.5914200986241049, gamma=0.3567500277336191, lambda=0.8269992759123079, learning_rate=0.020431261500869984, max_depth=9, min_child_weight=1, n_estimators=300, scale_pos_weight=1.4252349858508673, subsample=1.0000498427917415; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.4647470707624753, gamma=0.16949218611857386, lambda=0.42608327307350113, learning_rate=0.2402851392077089, max_depth=11, min_child_weight=1, n_estimators=450, scale_pos_weight=1.5838793664779671, subsample=1.4622456475182763; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.4647470707624753, gamma=0.16949218611857386, lambda=0.42608327307350113, learning_rate=0.2402851392077089, max_depth=11, min_child_weight=1, n_estimators=450, scale_pos_weight=1.5838793664779671, subsample=1.4622456475182763; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.4647470707624753, gamma=0.16949218611857386, lambda=0.42608327307350113, learning_rate=0.2402851392077089, max_depth=11, min_child_weight=1, n_estimators=450, scale_pos_weight=1.5838793664779671, subsample=1.4622456475182763; total time=   0.0s\n",
      "[CV] END alpha=20, colsample_bytree=0.4647470707624753, gamma=0.16949218611857386, lambda=0.42608327307350113, learning_rate=0.2402851392077089, max_depth=11, min_child_weight=1, n_estimators=450, scale_pos_weight=1.5838793664779671, subsample=1.4622456475182763; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5741374994727713, gamma=0.39315824977339253, lambda=0.8079359676281792, learning_rate=0.15871133139564586, max_depth=8, min_child_weight=1, n_estimators=200, scale_pos_weight=2.2203276307423323, subsample=1.1733850901048146; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5741374994727713, gamma=0.39315824977339253, lambda=0.8079359676281792, learning_rate=0.15871133139564586, max_depth=8, min_child_weight=1, n_estimators=200, scale_pos_weight=2.2203276307423323, subsample=1.1733850901048146; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5741374994727713, gamma=0.39315824977339253, lambda=0.8079359676281792, learning_rate=0.15871133139564586, max_depth=8, min_child_weight=1, n_estimators=200, scale_pos_weight=2.2203276307423323, subsample=1.1733850901048146; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.5741374994727713, gamma=0.39315824977339253, lambda=0.8079359676281792, learning_rate=0.15871133139564586, max_depth=8, min_child_weight=1, n_estimators=200, scale_pos_weight=2.2203276307423323, subsample=1.1733850901048146; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.9575060857989484, gamma=0.47033698370453353, lambda=0.6619161682238931, learning_rate=0.09033889769768037, max_depth=8, min_child_weight=1, n_estimators=500, scale_pos_weight=1.0519864493959696, subsample=1.5205857771006825; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.9575060857989484, gamma=0.47033698370453353, lambda=0.6619161682238931, learning_rate=0.09033889769768037, max_depth=8, min_child_weight=1, n_estimators=500, scale_pos_weight=1.0519864493959696, subsample=1.5205857771006825; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.9575060857989484, gamma=0.47033698370453353, lambda=0.6619161682238931, learning_rate=0.09033889769768037, max_depth=8, min_child_weight=1, n_estimators=500, scale_pos_weight=1.0519864493959696, subsample=1.5205857771006825; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.9575060857989484, gamma=0.47033698370453353, lambda=0.6619161682238931, learning_rate=0.09033889769768037, max_depth=8, min_child_weight=1, n_estimators=500, scale_pos_weight=1.0519864493959696, subsample=1.5205857771006825; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.093441963545733, gamma=0.1267671201329273, lambda=1.0300392067172994, learning_rate=0.13233006534421604, max_depth=5, min_child_weight=1, n_estimators=750, scale_pos_weight=2.6550650246907876, subsample=0.8149399528614876; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.093441963545733, gamma=0.1267671201329273, lambda=1.0300392067172994, learning_rate=0.13233006534421604, max_depth=5, min_child_weight=1, n_estimators=750, scale_pos_weight=2.6550650246907876, subsample=0.8149399528614876; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.093441963545733, gamma=0.1267671201329273, lambda=1.0300392067172994, learning_rate=0.13233006534421604, max_depth=5, min_child_weight=1, n_estimators=750, scale_pos_weight=2.6550650246907876, subsample=0.8149399528614876; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=1.093441963545733, gamma=0.1267671201329273, lambda=1.0300392067172994, learning_rate=0.13233006534421604, max_depth=5, min_child_weight=1, n_estimators=750, scale_pos_weight=2.6550650246907876, subsample=0.8149399528614876; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.3011090594299352, gamma=0.34423285136073706, lambda=1.2620149551878213, learning_rate=0.3454004022973247, max_depth=8, min_child_weight=1, n_estimators=550, scale_pos_weight=0.7688288331608146, subsample=1.0886134592513859; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.3011090594299352, gamma=0.34423285136073706, lambda=1.2620149551878213, learning_rate=0.3454004022973247, max_depth=8, min_child_weight=1, n_estimators=550, scale_pos_weight=0.7688288331608146, subsample=1.0886134592513859; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.3011090594299352, gamma=0.34423285136073706, lambda=1.2620149551878213, learning_rate=0.3454004022973247, max_depth=8, min_child_weight=1, n_estimators=550, scale_pos_weight=0.7688288331608146, subsample=1.0886134592513859; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.3011090594299352, gamma=0.34423285136073706, lambda=1.2620149551878213, learning_rate=0.3454004022973247, max_depth=8, min_child_weight=1, n_estimators=550, scale_pos_weight=0.7688288331608146, subsample=1.0886134592513859; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.7771593089861986, gamma=0.3864431541889723, lambda=0.5072023317693475, learning_rate=0.051970093902124086, max_depth=7, min_child_weight=3, n_estimators=400, scale_pos_weight=2.32428205422931, subsample=0.6252453367645507; total time=   0.5s\n",
      "[CV] END alpha=25, colsample_bytree=0.7771593089861986, gamma=0.3864431541889723, lambda=0.5072023317693475, learning_rate=0.051970093902124086, max_depth=7, min_child_weight=3, n_estimators=400, scale_pos_weight=2.32428205422931, subsample=0.6252453367645507; total time=   0.5s\n",
      "[CV] END alpha=25, colsample_bytree=0.7771593089861986, gamma=0.3864431541889723, lambda=0.5072023317693475, learning_rate=0.051970093902124086, max_depth=7, min_child_weight=3, n_estimators=400, scale_pos_weight=2.32428205422931, subsample=0.6252453367645507; total time=   0.5s\n",
      "[CV] END alpha=25, colsample_bytree=0.7771593089861986, gamma=0.3864431541889723, lambda=0.5072023317693475, learning_rate=0.051970093902124086, max_depth=7, min_child_weight=3, n_estimators=400, scale_pos_weight=2.32428205422931, subsample=0.6252453367645507; total time=   0.7s\n",
      "[CV] END alpha=25, colsample_bytree=1.089458916369997, gamma=0.34517242489248656, lambda=1.044699262800642, learning_rate=0.3648738251949289, max_depth=7, min_child_weight=3, n_estimators=450, scale_pos_weight=0.9478366224321627, subsample=0.8254244082586893; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.089458916369997, gamma=0.34517242489248656, lambda=1.044699262800642, learning_rate=0.3648738251949289, max_depth=7, min_child_weight=3, n_estimators=450, scale_pos_weight=0.9478366224321627, subsample=0.8254244082586893; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.089458916369997, gamma=0.34517242489248656, lambda=1.044699262800642, learning_rate=0.3648738251949289, max_depth=7, min_child_weight=3, n_estimators=450, scale_pos_weight=0.9478366224321627, subsample=0.8254244082586893; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=1.089458916369997, gamma=0.34517242489248656, lambda=1.044699262800642, learning_rate=0.3648738251949289, max_depth=7, min_child_weight=3, n_estimators=450, scale_pos_weight=0.9478366224321627, subsample=0.8254244082586893; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.7558718716444413, gamma=0.07097797839004388, lambda=0.685138175235026, learning_rate=0.27007008255088394, max_depth=5, min_child_weight=1, n_estimators=450, scale_pos_weight=1.8840427168444729, subsample=1.5550754261898145; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.7558718716444413, gamma=0.07097797839004388, lambda=0.685138175235026, learning_rate=0.27007008255088394, max_depth=5, min_child_weight=1, n_estimators=450, scale_pos_weight=1.8840427168444729, subsample=1.5550754261898145; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.7558718716444413, gamma=0.07097797839004388, lambda=0.685138175235026, learning_rate=0.27007008255088394, max_depth=5, min_child_weight=1, n_estimators=450, scale_pos_weight=1.8840427168444729, subsample=1.5550754261898145; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.7558718716444413, gamma=0.07097797839004388, lambda=0.685138175235026, learning_rate=0.27007008255088394, max_depth=5, min_child_weight=1, n_estimators=450, scale_pos_weight=1.8840427168444729, subsample=1.5550754261898145; total time=   0.0s\n",
      "[CV] END alpha=25, colsample_bytree=0.4359789416502157, gamma=0.4690249479502622, lambda=0.7081551348822577, learning_rate=0.35152321323125346, max_depth=10, min_child_weight=1, n_estimators=700, scale_pos_weight=2.395707080840954, subsample=0.7876150320724794; total time=   0.4s\n",
      "[CV] END alpha=25, colsample_bytree=0.4359789416502157, gamma=0.4690249479502622, lambda=0.7081551348822577, learning_rate=0.35152321323125346, max_depth=10, min_child_weight=1, n_estimators=700, scale_pos_weight=2.395707080840954, subsample=0.7876150320724794; total time=   0.3s\n",
      "[CV] END alpha=25, colsample_bytree=0.4359789416502157, gamma=0.4690249479502622, lambda=0.7081551348822577, learning_rate=0.35152321323125346, max_depth=10, min_child_weight=1, n_estimators=700, scale_pos_weight=2.395707080840954, subsample=0.7876150320724794; total time=   0.4s\n",
      "[CV] END alpha=25, colsample_bytree=0.4359789416502157, gamma=0.4690249479502622, lambda=0.7081551348822577, learning_rate=0.35152321323125346, max_depth=10, min_child_weight=1, n_estimators=700, scale_pos_weight=2.395707080840954, subsample=0.7876150320724794; total time=   0.4s\n",
      "[CV] END alpha=5, colsample_bytree=0.29739674168574987, gamma=0.061608456027622494, lambda=0.10499080610427236, learning_rate=0.388433031899699, max_depth=8, min_child_weight=3, n_estimators=400, scale_pos_weight=1.219311873716303, subsample=1.3171490935279664; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.29739674168574987, gamma=0.061608456027622494, lambda=0.10499080610427236, learning_rate=0.388433031899699, max_depth=8, min_child_weight=3, n_estimators=400, scale_pos_weight=1.219311873716303, subsample=1.3171490935279664; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.29739674168574987, gamma=0.061608456027622494, lambda=0.10499080610427236, learning_rate=0.388433031899699, max_depth=8, min_child_weight=3, n_estimators=400, scale_pos_weight=1.219311873716303, subsample=1.3171490935279664; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.29739674168574987, gamma=0.061608456027622494, lambda=0.10499080610427236, learning_rate=0.388433031899699, max_depth=8, min_child_weight=3, n_estimators=400, scale_pos_weight=1.219311873716303, subsample=1.3171490935279664; total time=   0.0s\n",
      "[CV] END alpha=5, colsample_bytree=0.28138091620974076, gamma=0.0003563203558207828, lambda=0.37828030121937195, learning_rate=0.24474537391896017, max_depth=7, min_child_weight=1, n_estimators=700, scale_pos_weight=2.176535969141062, subsample=0.9041040793260674; total time=   0.7s\n",
      "[CV] END alpha=5, colsample_bytree=0.28138091620974076, gamma=0.0003563203558207828, lambda=0.37828030121937195, learning_rate=0.24474537391896017, max_depth=7, min_child_weight=1, n_estimators=700, scale_pos_weight=2.176535969141062, subsample=0.9041040793260674; total time=   1.3s\n",
      "[CV] END alpha=5, colsample_bytree=0.28138091620974076, gamma=0.0003563203558207828, lambda=0.37828030121937195, learning_rate=0.24474537391896017, max_depth=7, min_child_weight=1, n_estimators=700, scale_pos_weight=2.176535969141062, subsample=0.9041040793260674; total time=   1.6s\n",
      "[CV] END alpha=5, colsample_bytree=0.28138091620974076, gamma=0.0003563203558207828, lambda=0.37828030121937195, learning_rate=0.24474537391896017, max_depth=7, min_child_weight=1, n_estimators=700, scale_pos_weight=2.176535969141062, subsample=0.9041040793260674; total time=   2.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.977260090569362, gamma=0.3313266147978481, lambda=0.4281581657475003, learning_rate=0.3379219407818023, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=2.392973392255658, subsample=1.4419858297325907; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.977260090569362, gamma=0.3313266147978481, lambda=0.4281581657475003, learning_rate=0.3379219407818023, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=2.392973392255658, subsample=1.4419858297325907; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.977260090569362, gamma=0.3313266147978481, lambda=0.4281581657475003, learning_rate=0.3379219407818023, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=2.392973392255658, subsample=1.4419858297325907; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.977260090569362, gamma=0.3313266147978481, lambda=0.4281581657475003, learning_rate=0.3379219407818023, max_depth=5, min_child_weight=1, n_estimators=700, scale_pos_weight=2.392973392255658, subsample=1.4419858297325907; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9635190878413746, gamma=0.27074787099316555, lambda=0.5130852458320744, learning_rate=0.37071635020066607, max_depth=5, min_child_weight=3, n_estimators=200, scale_pos_weight=2.0757269676406813, subsample=1.0768593741875512; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9635190878413746, gamma=0.27074787099316555, lambda=0.5130852458320744, learning_rate=0.37071635020066607, max_depth=5, min_child_weight=3, n_estimators=200, scale_pos_weight=2.0757269676406813, subsample=1.0768593741875512; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9635190878413746, gamma=0.27074787099316555, lambda=0.5130852458320744, learning_rate=0.37071635020066607, max_depth=5, min_child_weight=3, n_estimators=200, scale_pos_weight=2.0757269676406813, subsample=1.0768593741875512; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9635190878413746, gamma=0.27074787099316555, lambda=0.5130852458320744, learning_rate=0.37071635020066607, max_depth=5, min_child_weight=3, n_estimators=200, scale_pos_weight=2.0757269676406813, subsample=1.0768593741875512; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.43348130292951176, gamma=0.02729293759518414, lambda=1.446232592889213, learning_rate=0.4748349286370728, max_depth=7, min_child_weight=1, n_estimators=600, scale_pos_weight=2.5282802506038045, subsample=1.1710382357970746; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.43348130292951176, gamma=0.02729293759518414, lambda=1.446232592889213, learning_rate=0.4748349286370728, max_depth=7, min_child_weight=1, n_estimators=600, scale_pos_weight=2.5282802506038045, subsample=1.1710382357970746; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.43348130292951176, gamma=0.02729293759518414, lambda=1.446232592889213, learning_rate=0.4748349286370728, max_depth=7, min_child_weight=1, n_estimators=600, scale_pos_weight=2.5282802506038045, subsample=1.1710382357970746; total time=   0.0s\n",
      "[CV] END alpha=10, colsample_bytree=0.43348130292951176, gamma=0.02729293759518414, lambda=1.446232592889213, learning_rate=0.4748349286370728, max_depth=7, min_child_weight=1, n_estimators=600, scale_pos_weight=2.5282802506038045, subsample=1.1710382357970746; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9995357629080652, gamma=0.040326249309060425, lambda=0.649329562628981, learning_rate=0.44244784505106316, max_depth=11, min_child_weight=3, n_estimators=550, scale_pos_weight=1.5536009406296332, subsample=1.1034056060849458; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9995357629080652, gamma=0.040326249309060425, lambda=0.649329562628981, learning_rate=0.44244784505106316, max_depth=11, min_child_weight=3, n_estimators=550, scale_pos_weight=1.5536009406296332, subsample=1.1034056060849458; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9995357629080652, gamma=0.040326249309060425, lambda=0.649329562628981, learning_rate=0.44244784505106316, max_depth=11, min_child_weight=3, n_estimators=550, scale_pos_weight=1.5536009406296332, subsample=1.1034056060849458; total time=   0.0s\n",
      "[CV] END alpha=15, colsample_bytree=0.9995357629080652, gamma=0.040326249309060425, lambda=0.649329562628981, learning_rate=0.44244784505106316, max_depth=11, min_child_weight=3, n_estimators=550, scale_pos_weight=1.5536009406296332, subsample=1.1034056060849458; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:516: FitFailedWarning: \n",
      "1376 fits failed out of a total of 2000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.45862 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.12952 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.11499 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.50088 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.02432 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.2461 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.18377 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.0179 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.36199 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.00536 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.1588 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.36769 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.11332 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.02916 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.11771 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.21626 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.02617 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.15018 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.2131 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.53014 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.57717 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.47802 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.2856 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.41136 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.06961 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.52458 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.47386 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.19791 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.00253 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.1596 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.46054 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.12744 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.43348 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.1889 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.26236 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.57813 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.58026 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.0656 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.15091 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.03037 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.14581 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.55284 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.07315 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.17215 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.48924 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.08167 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.19286 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.41928 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.1466 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.11751 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.00947 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.10178 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.40376 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.26649 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.4465 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.56286 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.1596 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.174 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.33315 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.06287 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.29654 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.00507 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.09032 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.13384 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.41918 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.38776 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.01831 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.01475 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.06595 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.56595 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.4223 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.58857 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.33993 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.33042 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.2763 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.17074 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.33455 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.19356 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.08491 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.26275 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.03657 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.27859 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.59135 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.09606 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.00758 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.36379 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.1973 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.51577 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.49668 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.19026 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.08026 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.09674 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.00943 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.32316 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.57588 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.21471 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.08806 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.00145 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.06185 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.32381 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.18638 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.21458 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.0817 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.29825 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.05382 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.15775 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.26536 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.30188 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.08474 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.07116 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.11143 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.0581 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.55959 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.11791 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.22424 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.5045 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.02022 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.57016 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.29422 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.2713 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.09955 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.17561 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.40362 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.28097 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.51503 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.46113 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.10151 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.19175 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.39961 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.47081 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.10023 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.35263 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.44708 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.05994 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.07571 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.15164 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.5959 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.5965 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.21004 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.12714 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.14989 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.45042 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.02178 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.4482 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.59201 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.35453 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.00975 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.59325 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.38371 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.29124 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.48694 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.09492 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.19669 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.10252 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.09148 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.06828 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.12792 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.19319 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.38239 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.199 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.31931 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.52489 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.04651 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.29522 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.03214 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.12208 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.36557 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.08257 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.36971 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.09458 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.16772 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.55527 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.15088 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.34529 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.36126 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.17554 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.35273 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.3837 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.34506 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.0633 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.18822 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.04016 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.18153 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.02786 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.11476 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.41595 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.4897 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.51389 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.55342 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.51825 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.41491 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.28974 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.14457 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.52994 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.01394 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.04625 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.26342 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.47182 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.09362 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.1829 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.25738 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.57364 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.04485 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.24066 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.09977 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.06011 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.02678 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.30767 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.07679 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.12018 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.4132 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.13084 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.1585 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.14271 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.18547 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.04025 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.08133 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.0834 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.07793 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.1156 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.55951 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.56314 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.07789 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.14982 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.52836 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.17309 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.31892 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.12844 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.16844 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.01055 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.09444 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.49736 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.12517 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.11421 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.12655 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.15071 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.17025 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.0736 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.20457 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.55475 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.38263 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.59465 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.52614 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.53005 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.09615 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.4873 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.45806 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.05282 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.16041 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.17843 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.03153 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.56568 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.0415 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.18912 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.13226 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.26154 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.03281 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.01147 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.30065 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.07598 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.12713 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.09673 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.18518 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.16261 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.18666 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.40163 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.55563 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.34174 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.50462 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.54974 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.03053 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.08822 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.06882 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.52921 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.45055 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.06829 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.11003 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.15511 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.11495 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.06446 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.42985 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.14918 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.29981 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.56422 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.09056 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.37952 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.50768 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.20054 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.35991 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.44171 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.45703 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.56265 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.01838 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.15932 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.23386 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.01514 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.0397 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.0311 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.58851 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.51033 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.40256 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.14079 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.43204 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.03092 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.37033 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.00567 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.00974 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.1631 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.04464 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.05787 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.10147 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.174 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.03934 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.09443 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.14645 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.19424 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.14834 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.23427 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.47144 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.04191 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.21455 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.10705 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.18955 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.04483 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.19273 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.31271 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.08436 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.24421 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.11376 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.00806 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.51173 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.00005 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.46225 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.17339 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.52059 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.09344 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.08861 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.08946 for Parameter colsample_bytree exceed bound [0,1]\n",
      "colsample_bytree: Subsample ratio of columns, resample on each tree construction.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.55508 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.31715 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.44199 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.07686 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.17104 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1806, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 774, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/training.py\", line 199, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 2433, in update\n",
      "    _check_call(\n",
      "  File \"/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/xgboost/core.py\", line 323, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 1.10341 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/netmaster/.conda/envs/wuta/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1135: UserWarning: One or more of the test scores are non-finite: [       nan 0.64337688        nan        nan        nan        nan\n",
      "        nan 0.6812674  0.68771468 0.6535876  0.6791209         nan\n",
      " 0.65466258 0.6898733         nan        nan        nan        nan\n",
      "        nan        nan        nan 0.69363126 0.66675762        nan\n",
      "        nan 0.68153852 0.68933162        nan        nan        nan\n",
      "        nan 0.67562657 0.67723543        nan 0.67723369 0.6890631\n",
      " 0.64660037 0.68610582        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.64955476 0.66568091        nan\n",
      "        nan        nan 0.65573294        nan 0.691753          nan\n",
      "        nan        nan        nan        nan 0.68046066 0.69094366\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.67669635        nan 0.68287886        nan 0.6414914  0.68180445\n",
      " 0.65385324        nan        nan 0.68207356        nan 0.68960015\n",
      "        nan 0.69201951        nan        nan 0.67481809        nan\n",
      "        nan        nan 0.67455043        nan        nan 0.67992562\n",
      "        nan        nan        nan 0.68234353 0.68932816        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.66218397        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.6621883  0.67858269        nan        nan        nan\n",
      "        nan        nan        nan 0.65009413 0.64579132        nan\n",
      " 0.68664172        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.67938914 0.64714003 0.67186341 0.70061819\n",
      "        nan        nan 0.65143677        nan        nan        nan\n",
      " 0.69228457 0.67885093        nan 0.68503141 0.68180676        nan\n",
      "        nan        nan        nan 0.69201922        nan        nan\n",
      "        nan 0.68287886 0.69013548        nan        nan 0.68207731\n",
      " 0.64095637        nan 0.67857894        nan 0.6936275         nan\n",
      " 0.6680994  0.64444926 0.69524416 0.68422179        nan        nan\n",
      " 0.68126653        nan        nan 0.69282538        nan        nan\n",
      "        nan        nan 0.66030427        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.69121132        nan        nan        nan 0.67831156\n",
      "        nan        nan 0.655739          nan        nan        nan\n",
      "        nan 0.6500924         nan        nan        nan        nan\n",
      "        nan        nan        nan 0.68798609 0.68986839        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.65950071 0.66783116        nan 0.66138012\n",
      "        nan 0.66353297        nan 0.69336273        nan        nan\n",
      "        nan 0.6724048         nan        nan 0.66057223        nan\n",
      " 0.68664287        nan 0.65896279 0.67616074        nan        nan\n",
      "        nan        nan 0.68556818        nan        nan 0.68207558\n",
      "        nan        nan 0.64928595 0.68583758        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.67347487\n",
      "        nan        nan        nan        nan 0.68825433        nan\n",
      "        nan        nan 0.70115698        nan 0.69040314 0.68852344\n",
      "        nan 0.67481867        nan        nan        nan        nan\n",
      "        nan 0.66729901        nan        nan        nan 0.67696632\n",
      "        nan        nan        nan        nan        nan 0.6605728\n",
      " 0.65762217        nan        nan 0.67374427        nan        nan\n",
      "        nan 0.70948685 0.6527797         nan 0.67858384        nan\n",
      "        nan 0.6783156         nan        nan        nan        nan\n",
      " 0.66191804        nan 0.69067456 0.67589307        nan 0.66487705\n",
      "        nan        nan 0.642571   0.69336215 0.66406656        nan\n",
      "        nan 0.6686379         nan        nan        nan 0.68368617\n",
      "        nan        nan        nan        nan 0.64740567 0.67831301\n",
      " 0.68825693        nan        nan 0.68180705 0.66111246 0.70196228\n",
      " 0.69631943        nan        nan        nan        nan 0.68502968\n",
      "        nan        nan        nan 0.67051962        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.69013663        nan        nan 0.69121306        nan        nan\n",
      "        nan        nan        nan        nan 0.67992331        nan\n",
      " 0.68073005 0.66621623        nan 0.68718022        nan 0.68207327\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.67535717        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.66836388        nan        nan\n",
      " 0.67992216 0.65304852 0.63692382 0.66353297        nan 0.69900529\n",
      "        nan        nan        nan        nan 0.69255859        nan\n",
      "        nan 0.67885324        nan 0.66944521 0.69094279        nan\n",
      " 0.63773114        nan 0.66353326        nan        nan        nan\n",
      " 0.66944262        nan        nan        nan 0.68368617        nan\n",
      "        nan        nan 0.64552712 0.69255512        nan        nan\n",
      "        nan 0.67212992        nan 0.66594713 0.68073034        nan\n",
      " 0.6740128         nan        nan        nan        nan 0.65654199\n",
      "        nan        nan        nan        nan 0.6947045         nan\n",
      "        nan        nan        nan        nan 0.65035862 0.68637608\n",
      "        nan        nan        nan        nan 0.65224293        nan\n",
      "        nan        nan        nan        nan 0.66836648        nan\n",
      " 0.68637492        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.64525831        nan\n",
      "        nan 0.63827252        nan 0.68395326        nan        nan\n",
      "        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'alpha': 5, 'colsample_bytree': np.float64(0.6196676211639822), 'gamma': np.float64(0.4594074072727686), 'lambda': np.float64(1.2843342554503443), 'learning_rate': np.float64(0.012866875807393754), 'max_depth': 10, 'min_child_weight': 3, 'n_estimators': 300, 'scale_pos_weight': np.float64(1.30985891486832), 'subsample': np.float64(0.6957922037446137)}\n",
      "Best accuracy found:  0.7094868507674718\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "source": "best_parameters = {'alpha': 5, 'colsample_bytree': np.float64(0.6196676211639822), 'gamma': np.float64(0.4594074072727686), 'lambda': np.float64(1.2843342554503443), 'learning_rate': np.float64(0.012866875807393754), 'max_depth': 10, 'min_child_weight': 3, 'n_estimators': 300, 'scale_pos_weight': np.float64(1.30985891486832), 'subsample': np.float64(0.6957922037446137)}",
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1761149403833
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:33:56.307493Z",
     "start_time": "2025-12-04T20:33:56.301656Z"
    }
   },
   "outputs": [],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "source": [
    "y_train.describe()"
   ],
   "metadata": {
    "gather": {
     "logged": 1761149403987
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:33:58.971903Z",
     "start_time": "2025-12-04T20:33:58.961124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3721.000000\n",
       "mean        0.332438\n",
       "std         0.471150\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         1.000000\n",
       "max         1.000000\n",
       "Name: like_label, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "source": [
    "##Train \n",
    "xgb_clf_score = xgb.XGBClassifier(\n",
    "    enable_categorical=True,\n",
    "    verbosity=0\n",
    "    )\n",
    "    \n",
    "xgb_clf_score.set_params(**best_parameters)\n",
    "xgb_clf_score.fit(X_train, y_train)"
   ],
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1761149418922
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:34:05.629680Z",
     "start_time": "2025-12-04T20:34:04.014291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(alpha=5, base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=np.float64(0.6196676211639822), device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=True,\n",
       "              eval_metric=None, feature_types=None, feature_weights=None,\n",
       "              gamma=np.float64(0.4594074072727686), grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              lambda=np.float64(1.2843342554503443),\n",
       "              learning_rate=np.float64(0.012866875807393754), max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, ...)"
      ],
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(alpha=5, base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=np.float64(0.6196676211639822), device=None,\n",
       "              early_stopping_rounds=None, enable_categorical=True,\n",
       "              eval_metric=None, feature_types=None, feature_weights=None,\n",
       "              gamma=np.float64(0.4594074072727686), grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              lambda=np.float64(1.2843342554503443),\n",
       "              learning_rate=np.float64(0.012866875807393754), max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=3, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=300, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.1.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('objective',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">objective&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;binary:logistic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('base_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">base_score&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('booster',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">booster&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('callbacks',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">callbacks&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bylevel',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bylevel&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bynode',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bynode&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('colsample_bytree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">colsample_bytree&nbsp;</td>\n",
       "            <td class=\"value\">np.float64(0.6196676211639822)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('device',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">device&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('early_stopping_rounds',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">early_stopping_rounds&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('enable_categorical',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">enable_categorical&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('eval_metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">eval_metric&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_types',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_types&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('feature_weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">feature_weights&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('gamma',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">gamma&nbsp;</td>\n",
       "            <td class=\"value\">np.float64(0.4594074072727686)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('grow_policy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">grow_policy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('importance_type',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">importance_type&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('interaction_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">interaction_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('learning_rate',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">learning_rate&nbsp;</td>\n",
       "            <td class=\"value\">np.float64(0....6875807393754)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_bin',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_bin&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_threshold',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_threshold&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_cat_to_onehot',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_cat_to_onehot&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_delta_step',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_delta_step&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">10</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaves',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaves&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_child_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_child_weight&nbsp;</td>\n",
       "            <td class=\"value\">3</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('missing',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">missing&nbsp;</td>\n",
       "            <td class=\"value\">nan</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotone_constraints',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotone_constraints&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('multi_strategy',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">multi_strategy&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">300</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('num_parallel_tree',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">num_parallel_tree&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_alpha&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('reg_lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">reg_lambda&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('sampling_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">sampling_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('scale_pos_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">scale_pos_weight&nbsp;</td>\n",
       "            <td class=\"value\">np.float64(1.30985891486832)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('subsample',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">subsample&nbsp;</td>\n",
       "            <td class=\"value\">np.float64(0.6957922037446137)</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tree_method',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tree_method&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('validate_parameters',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">validate_parameters&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbosity',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbosity&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">alpha&nbsp;</td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('lambda',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">lambda&nbsp;</td>\n",
       "            <td class=\"value\">np.float64(1.2843342554503443)</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "source": [
    "#### Save Data and Models\n",
    "\n",
    "time_path = \"base_0\"\n",
    "if os.path.exists('./data_and_models/'+time_path) and os.path.isdir('./data_and_models/'+time_path):\n",
    "    shutil.rmtree('./data_and_models/'+time_path)\n",
    "\n",
    "os.makedirs('./data_and_models/'+time_path)\n",
    "\n",
    "os.system('cp ./data/x_train.pkl '+'./data_and_models/'+time_path)\n",
    "os.system('cp ./data/x_test.pkl '+'./data_and_models/'+time_path)\n",
    "\n",
    "os.system('cp ./data/y_train.pkl '+'./data_and_models/'+time_path)\n",
    "os.system('cp ./data/y_test.pkl '+'./data_and_models/'+time_path)\n",
    "\n",
    "os.system('cp ./data/cat_ordinal_encoder.pkl '+'./data_and_models/'+time_path)\n",
    "os.system('cp ./data/training_categories_array.pkl '+'./data_and_models/'+time_path)\n",
    "\n",
    "\n",
    "if True:\n",
    "    output_model = \"./data_and_models/\"+time_path+\"/001_xgboost\"\n",
    "\n",
    "\n",
    "    if os.path.exists(output_model) and os.path.isdir(output_model):\n",
    "        shutil.rmtree(output_model)\n",
    "    mlflow.sklearn.save_model(xgb_clf_score, output_model+\"/1\")\n",
    "    print(mlflow.__version__)"
   ],
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1761149425041
    },
    "editable": true,
    "run_control": {
     "frozen": false
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:35:40.756038Z",
     "start_time": "2025-12-04T20:35:39.125054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3.2\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "source": [
    "print(datetime.now())\n",
    "print(datetime.now()-start_time)"
   ],
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1761149425183
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:35:51.481363Z",
     "start_time": "2025-12-04T20:35:51.473843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-12-04 15:35:51.477200\n",
      "0:02:05.813100\n"
     ]
    }
   ],
   "execution_count": 62
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   },
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
