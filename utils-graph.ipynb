{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import math \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#%pip install seaborn\n",
    "import seaborn as sns\n"
   ],
   "metadata": {
    "gather": {
     "logged": 1745840473873
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:48:40.578991Z",
     "start_time": "2025-12-04T20:48:40.324816Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "def non_null_count(df: pd.DataFrame):\n",
    "\n",
    "    if df.isnull().sum().sum() != 0:\n",
    "        na_df = 100-(df.isnull().sum() / len(df)) * 100      \n",
    "        na_df = na_df.drop(na_df[na_df == 0].index).sort_values(ascending=False)\n",
    "        missing_data = pd.DataFrame({'Missing Ratio %' :na_df})\n",
    "        missing_data.plot(kind = \"barh\", figsize=(10,40))\n",
    "        plt.show()\n",
    "        print(missing_data.to_markdown())\n",
    "    else:\n",
    "        print('No data found')\n"
   ],
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:48:40.594163Z",
     "start_time": "2025-12-04T20:48:40.587461Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "def field_analysis_float(buckets_count, df_dt, baseField, tmpFieldName, exclude_percentile_offset=-1):\n",
    "\n",
    "    if baseField == tmpFieldName:\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    if exclude_percentile_offset > 0:\n",
    "        p1 = np.percentile(df_dt[tmpFieldName], exclude_percentile_offset, method='midpoint')        \n",
    "        p99 = np.percentile(df_dt[tmpFieldName], 100-exclude_percentile_offset, method='midpoint')\n",
    "        print('Range excluding outliers (',100-2*exclude_percentile_offset,'%):',p1,'->',p99)\n",
    "        localvalues = df_dt[(df_dt[tmpFieldName]>p1) & (df_dt[tmpFieldName]<p99)][tmpFieldName]\n",
    "        \n",
    "        if len(localvalues) == 0:\n",
    "            print(\"Error Calculating Outliers, rollback to full data\")\n",
    "            localvalues = df_dt[tmpFieldName]\n",
    "    else:   \n",
    "        localvalues = df_dt[tmpFieldName]\n",
    "\n",
    "\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    print(\"CORRELATION: \", tmpFieldName, df_dt[baseField].corr(df_dt[tmpFieldName]))\n",
    "\n",
    "    bins_tmp = np.linspace(df_dt[tmpFieldName].min(), df_dt[tmpFieldName].max(), buckets_count)\n",
    "    bins_tmp = np.around(bins_tmp, decimals=2)\n",
    "\n",
    "\n",
    "    f_hist = np.histogram(df_dt[tmpFieldName], bins=bins_tmp)\n",
    "    #print(f_hist)\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.xticks(rotation=90, fontsize=5)\n",
    "    plt.bar(x=f_hist[1][1:].astype(str), height=f_hist[0])\n",
    "\n",
    "    p_hist = np.histogram(df_dt[df_dt[baseField] == 1][tmpFieldName], bins=bins_tmp)\n",
    "    #print(p_hist)\n",
    "    p_factor = p_hist[0]/f_hist[0]\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(f_hist[1][1:], p_factor, marker = \".\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    df_table = pd.DataFrame({\"upper\": f_hist[1][1:], \"total\":f_hist[0], \"posi\": p_hist[0], \"%\": p_factor})\n",
    "\n",
    "    np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "    print(df_table.to_markdown())\n"
   ],
   "metadata": {
    "gather": {
     "logged": 1718352860455
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:48:40.670411Z",
     "start_time": "2025-12-04T20:48:40.646063Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "def field_analysis_category(df_dt, baseField, tmpFieldName):\n",
    "    counts_t = df_dt[tmpFieldName].value_counts()\n",
    "    if len(counts_t) == 0:\n",
    "        return\n",
    "\n",
    "    if True:\n",
    "        plt.subplot(1, 2, 1)\n",
    "        counts_t.plot(kind='bar')\n",
    "\n",
    "        corr = df_dt[[baseField, tmpFieldName]].apply(lambda x : pd.factorize(x)[0]).corr(method='pearson', min_periods=1)\n",
    "        print(\"---------------------------------------------------------\")\n",
    "        print(\"CORRELATION: \", corr)\n",
    "        print(\"Categories Count: \", counts_t)\n",
    "\n",
    "        cat_list = df_dt[tmpFieldName].dropna().unique()\n",
    "        cat_rate = []\n",
    "        for u_cat in cat_list:\n",
    "            cat_t = len(df_dt[df_dt[tmpFieldName] == u_cat])\n",
    "            cat_p = len( df_dt[ (df_dt[tmpFieldName] == u_cat) & (df_dt[baseField] == 1) ] )\n",
    "            cat_rate.append(cat_p/cat_t)\n",
    "\n",
    "        #print(cat_list.astype(str))\n",
    "        #print(len(cat_rate))\n",
    "        #print(cat_rate)\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.scatter(cat_list.astype(str), cat_rate, marker = \".\")\n",
    "        plt.show()\n",
    "\n",
    "        np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "        print(np.array((cat_list, counts_t, cat_rate)).T)"
   ],
   "metadata": {
    "gather": {
     "logged": 1718352860611
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:48:40.715542Z",
     "start_time": "2025-12-04T20:48:40.708097Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "def categories_unique_count(df_dt):\n",
    "    categories_df = df_dt.select_dtypes(include=[\"category\"])\n",
    "    result = categories_df.apply(pd.Series.nunique).sort_values(ascending=False) #unique\n",
    "    print(result.to_markdown())"
   ],
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:48:40.775498Z",
     "start_time": "2025-12-04T20:48:40.765982Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "def field_analysis_integer(buckets_count, df_dt, baseField, tmpFieldName, exclude_percentile_offset=-1):\n",
    "\n",
    "    if baseField == tmpFieldName:\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    if exclude_percentile_offset > 0:\n",
    "        p1 = np.percentile(df_dt[tmpFieldName], exclude_percentile_offset, method='midpoint')        \n",
    "        p99 = np.percentile(df_dt[tmpFieldName], 100-exclude_percentile_offset, method='midpoint')\n",
    "        print('Range excluding outliers (',100-2*exclude_percentile_offset,'%):',p1,'->',p99)\n",
    "        localvalues = df_dt[(df_dt[tmpFieldName]>p1) & (df_dt[tmpFieldName]<p99)][tmpFieldName]\n",
    "        \n",
    "        if len(localvalues) == 0:\n",
    "            print(\"Error Calculating Outliers, rollback to full data\")\n",
    "            localvalues = df_dt[tmpFieldName]\n",
    "    else:   \n",
    "        localvalues = df_dt[tmpFieldName]\n",
    "\n",
    "    local_min = localvalues.min()\n",
    "    nullValue = local_min-1\n",
    "    print(\"NullValue: \", nullValue)\n",
    "    print(\"NullCount: \", localvalues.isna().sum())\n",
    "    \n",
    "    localvalues.fillna(nullValue, inplace=True)\n",
    "\n",
    "    local_buckets_count = int(localvalues.max() - localvalues.min()+1)\n",
    "    buckets_count = min(buckets_count, local_buckets_count)\n",
    "\n",
    "    print('#Buckets : ', buckets_count)\n",
    "\n",
    "    bins_tmp = np.linspace(localvalues.min(), localvalues.max(), buckets_count)\n",
    "    bins_tmp = np.around(bins_tmp, decimals=0)\n",
    "\n",
    "    f_hist = np.histogram(localvalues, bins=bins_tmp)\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.xticks(rotation=90, fontsize=5)\n",
    "    plt.bar(x=f_hist[1][1:].astype(str), height=f_hist[0])\n",
    "\n",
    "    p_hist = np.histogram(df_dt[df_dt[baseField] == 1][tmpFieldName], bins=bins_tmp)\n",
    "    p_factor = p_hist[0]/f_hist[0]\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(f_hist[1][1:], p_factor, marker = \".\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    df_table = pd.DataFrame({\"upper\": f_hist[1][1:], \"total\":f_hist[0], \"posi\": p_hist[0], \"%\": p_factor})\n",
    "\n",
    "    np.set_printoptions(formatter={'float': '{: 0.3f}'.format})\n",
    "    print(df_table.to_markdown())\n"
   ],
   "metadata": {
    "gather": {
     "logged": 1718352860665
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:48:40.825457Z",
     "start_time": "2025-12-04T20:48:40.817565Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "def export_prediction(y_test, y_predicted_proba):\n",
    "    if y_predicted_proba.ndim == 1:\n",
    "        y_predicted_f = y_predicted_proba\n",
    "    else:\n",
    "        y_predicted_f = y_predicted_proba[:,1]\n",
    "    "
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-04T20:48:40.872432Z",
     "start_time": "2025-12-04T20:48:40.868989Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "from math import pi\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def evaluate_metrics(y_test, y_predicted_proba, threshold):\n",
    "    if y_predicted_proba.ndim == 1:\n",
    "        y_predicted = (y_predicted_proba >= threshold).astype(bool) \n",
    "    else:\n",
    "        y_predicted = (y_predicted_proba[:,1] >= threshold).astype(bool) \n",
    "\n",
    "    cm = confusion_matrix(y_test, y_predicted)\n",
    "\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    tnr = tn/(tn+fp)\n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    f1 = 2*precision*recall/(precision+recall)\n",
    "    # mcc = (tp*tn-fp*fn)/math.sqrt( (tp+fp)*(tp+fn)*(tn+fp)*(tn+fn) )\n",
    "    mcc = matthews_corrcoef(y_test, y_predicted)\n",
    "    auc = roc_auc_score(y_test, y_predicted)\n",
    "\n",
    "\n",
    "\n",
    "    ### Radar Graph\n",
    "    df = pd.DataFrame({\n",
    "    'group': ['Metrics'],\n",
    "    'Accuracy: '+\"{:.2f}\".format(100*accuracy): [100*accuracy],\n",
    "    'Precision: '+\"{:.2f}\".format(100*precision): [100*precision],\n",
    "    'Recall: '+\"{:.2f}\".format(100*recall): [100*recall],\n",
    "    'TNR: '+\"{:.2f}\".format(100*tnr): [100*tnr],\n",
    "    'F1: '+\"{:.2f}\".format(100*f1): [100*f1],\n",
    "    'MCC: '+\"{:.2f}\".format(100*mcc): [100*mcc],\n",
    "    'AUC: '+\"{:.2f}\".format(100*auc): [100*auc]\n",
    "    })\n",
    "\n",
    "    categories=list(df)[1:]\n",
    "    N = len(categories)\n",
    "\n",
    "    values=df.loc[0].drop('group').values.flatten().tolist()\n",
    "    values += values[:1]\n",
    "\n",
    "    angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "    angles += angles[:1]\n",
    "\n",
    "    ax = plt.subplot(111, polar=True)\n",
    "\n",
    "    plt.xticks(angles[:-1], categories, color='black', size=8)\n",
    "    plt.yticks([10,20,30,40,50,60,70,80,90], [\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"], color=\"grey\", size=7)\n",
    "\n",
    "    \n",
    "    plt.ylim(0,100)\n",
    "\n",
    "    ax.plot(angles, values, linewidth=1, linestyle='solid')\n",
    "\n",
    "    ax.fill(angles, values, 'b', alpha=0.1)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # End Radar\n",
    "\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "\n",
    "    print(\"========= Prediction on Test Set =========\")\n",
    "    print(cm)\n",
    "    print(\"-----------\")\n",
    "    print(accuracy, \" <-- Accuracy (all correct / all)\")\n",
    "    print(precision, \" <-- Precision: (true positives / predicted positives)\")\n",
    "    print(recall, \" <-- Recall/TPR (true positives / all actual positives):\")\n",
    "    print(tnr, \" <-- TNR (true negatives / all actual negatives):\")\n",
    "    print(f1, \" <-- F1\" )\n",
    "    print(mcc, \" <-- MCC [-1..0..1]\" )\n",
    "    print(auc, \" <-- AUC\" )\n",
    "    plt.show()\n"
   ],
   "metadata": {
    "gather": {
     "logged": 1718965010329
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:48:40.931514Z",
     "start_time": "2025-12-04T20:48:40.915091Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "def false_negative_list(y_test, y_predicted_proba, threshold, print_values_list=False):\n",
    "    tmp = pd.DataFrame({'y': y_test, 'predicted': y_predicted_proba[:,1]}).sort_values(by=['predicted'])\n",
    "    tmp = tmp[tmp[\"predicted\"]<threshold]\n",
    "    tmp = tmp[tmp[\"y\"]==1]\n",
    "\n",
    "    plt.bar(height=tmp[\"predicted\"], x=np.arange(start=1, stop=len(tmp)+1, step=1), color ='maroon', width = 0.4)\n",
    "    plt.show()\n",
    "    print(\"Count: \", len(tmp))\n",
    "\n",
    "    if print_values_list:\n",
    "        print(tmp.to_markdown()) "
   ],
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:48:40.977023Z",
     "start_time": "2025-12-04T20:48:40.971138Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "def false_positive_list(y_test, y_predicted_proba, threshold, print_values_list=False):\n",
    "    tmp = pd.DataFrame({'y': y_test, 'predicted': y_predicted_proba[:,1]}).sort_values(by=['predicted'])\n",
    "    tmp = tmp[tmp[\"predicted\"]>threshold]\n",
    "    tmp = tmp[tmp[\"y\"]==0]\n",
    "\n",
    "    plt.bar(height=tmp[\"predicted\"], x=np.arange(start=1, stop=len(tmp)+1, step=1), color ='maroon', width = 0.4)\n",
    "    plt.show()\n",
    "    print(\"Count: \", len(tmp))\n",
    "    \n",
    "    if print_values_list:\n",
    "        print(tmp.to_markdown()) "
   ],
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:48:41.029766Z",
     "start_time": "2025-12-04T20:48:41.023554Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "def real_positive_list(y_test, y_predicted_proba, print_values_list=False, range_start=0, range_end=10):\n",
    "    tmp = pd.DataFrame({'y': y_test, 'predicted': y_predicted_proba[:,1]}).sort_values(by=['predicted'], ascending=False)\n",
    "    # tmp_n = tmp[tmp[\"y\"]==0]\n",
    "    tmp_p = tmp[tmp[\"y\"]==1]\n",
    "\n",
    "    plt.bar(height=tmp_p[\"predicted\"], x=np.arange(start=1, stop=len(tmp_p)+1, step=1), color ='maroon', width = 0.4)\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Count: \", len(tmp_p))\n",
    "\n",
    "    if print_values_list:\n",
    "        print(tmp.iloc[range_start:range_end].to_markdown()) \n",
    "    #print(tmp.to_markdown()) "
   ],
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:48:41.080886Z",
     "start_time": "2025-12-04T20:48:41.075044Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "def full_histogram(y_test, y_predicted_proba, buckets_count=1000, graph_negative_threshold=0.5, print_values_list=False):\n",
    "    if y_predicted_proba.ndim == 1:\n",
    "        y_predicted = y_predicted_proba\n",
    "    else:\n",
    "        y_predicted = y_predicted_proba[:,1]\n",
    "\n",
    "\n",
    "    # y_test_pred = y_test.copy(deep=True)\n",
    "    # y_test_pred['prediction'] = y_predicted_proba[:,1]\n",
    "    # y_test_pred = y_test_pred.sort_values(by=['prediction'])\n",
    "    frame = {'IsFraud': y_test.copy(deep=True),\n",
    "            'prediction': y_predicted}\n",
    "\n",
    "    y_test_pred = pd.DataFrame(frame)\n",
    "\n",
    "    y_test_pred = y_test_pred.sort_values(by=['prediction'])\n",
    "\n",
    "    bins = np.linspace(0, 1, buckets_count)\n",
    "    plt.figure(figsize=(40, 10))\n",
    "    b_width = 0.001\n",
    "\n",
    "    ########\n",
    "\n",
    "\n",
    "    y_neg = y_test_pred[(y_test_pred['IsFraud']==0) & (y_test_pred[\"prediction\"]>graph_negative_threshold)]\n",
    "\n",
    "    n_hist = np.histogram(y_neg['prediction'], bins=bins)\n",
    "    plt.bar(height=n_hist[0], x=np.linspace(0, 1, buckets_count-1)+b_width, color ='green', width = b_width)\n",
    "\n",
    "    #######\n",
    "\n",
    "    y_pos = y_test_pred[y_test_pred['IsFraud']==1]\n",
    "\n",
    "    p_hist = np.histogram(y_pos['prediction'], bins=bins)\n",
    "    plt.bar(height=p_hist[0], x=np.linspace(0, 1, buckets_count-1), color ='red', width = b_width)\n",
    "\n",
    "    ########\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(\"RED: Fraud Label Positive;\", \"Showing: \", len(y_pos))\n",
    "    print(\"GREEN: Fraud Label Negative;\", \"Showing: \", len(y_neg), \" out of \", len(y_test_pred[y_test_pred['IsFraud']==0]))\n",
    "    print(\"For visual purposes \", len(y_test_pred[y_test_pred['IsFraud']==0])-len(y_neg), \" real negative records with prediction < \", graph_negative_threshold, \" are excluded\")\n",
    "\n",
    "    if print_values_list:\n",
    "        print(\"=============================\")\n",
    "        print(\"Real Positive predictions\")\n",
    "        print(y_pos.to_markdown()) \n",
    "        print(\"=============================\")\n",
    "        print(\"Real Negative predictions\")\n",
    "        print(y_neg.to_markdown()) \n"
   ],
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1730726917976
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:48:41.135188Z",
     "start_time": "2025-12-04T20:48:41.125268Z"
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "def positive_near_zero_report(y_test, y_predicted_proba, near_zero_threshold=0.001):\n",
    "    tmp_p = pd.DataFrame({'y': y_test, 'predicted': y_predicted_proba[:,1]}).sort_values(by=['predicted'])\n",
    "    tmp_p = tmp_p[(tmp_p[\"y\"]==1) & (tmp_p[\"predicted\"]<near_zero_threshold)]\n",
    "\n",
    "    print(tmp_p[\"predicted\"])\n",
    "\n",
    "    indexes = tmp_p.index.to_list()\n",
    "\n",
    "    return indexes"
   ],
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "gather": {
     "logged": 1719910193684
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:48:41.185578Z",
     "start_time": "2025-12-04T20:48:41.180834Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "def negative_near_one_report(y_test, y_predicted_proba, near_one_threshold=0.009):\n",
    "    tmp_p = pd.DataFrame({'y': y_test, 'predicted': y_predicted_proba[:,1]}).sort_values(by=['predicted'])\n",
    "    tmp_p = tmp_p[(tmp_p[\"y\"]==0) & (tmp_p[\"predicted\"]>near_one_threshold)]\n",
    "\n",
    "    indexes = tmp_p.index.to_list()\n",
    "\n",
    "    return indexes"
   ],
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:48:41.236857Z",
     "start_time": "2025-12-04T20:48:41.231028Z"
    }
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "def positive_near_one_report(y_test, y_predicted_proba, near_one_threshold=0.009):\n",
    "    tmp_p = pd.DataFrame({'y': y_test, 'predicted': y_predicted_proba[:,1]}).sort_values(by=['predicted'])\n",
    "    tmp_p = tmp_p[(tmp_p[\"y\"]==1) & (tmp_p[\"predicted\"]>near_one_threshold)]\n",
    "\n",
    "    indexes = tmp_p.index.to_list()\n",
    "\n",
    "    return indexes"
   ],
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:48:41.285046Z",
     "start_time": "2025-12-04T20:48:41.281913Z"
    }
   },
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "#import association_metrics as am\n",
    "\n",
    "def graphCorrelationCategorical(df_dt, baseField):\n",
    "    categories_df = df_dt.select_dtypes(include=[\"category\", \"bool\"])\n",
    "    categories_df.insert(loc=0, column=baseField, value=df_dt[baseField])\n",
    "    corr_cat = categories_df.apply(lambda x : pd.factorize(x)[0]).corr(method='pearson', min_periods=1)\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    sns.heatmap(corr_cat, annot=True, xticklabels=True, yticklabels=True)\n",
    "    \n",
    "    corr_cat = corr_cat.unstack().abs().sort_values(ascending=False)\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    corr_cat[baseField].plot.bar(legend=False, figsize=(20, 20))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    print(corr_cat[baseField].to_markdown())"
   ],
   "metadata": {
    "gather": {
     "logged": 1718470381887
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:48:41.333079Z",
     "start_time": "2025-12-04T20:48:41.327616Z"
    }
   },
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "def graphCorrelationNumerical(df_dt, baseField):\n",
    "    numerics_df = df_dt.select_dtypes(include=\"number\")\n",
    "    corr = numerics_df.corr()\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    sns.heatmap(corr, annot=True, xticklabels=True, yticklabels=True)\n",
    "\n",
    "\n",
    "    corr = corr.unstack().abs().sort_values(ascending=False)\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    corr[baseField].plot.bar(legend=False, figsize=(20, 20))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    print(corr[baseField].to_markdown())\n"
   ],
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:48:41.379458Z",
     "start_time": "2025-12-04T20:48:41.375964Z"
    }
   },
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "def graphCorrelationGeneral(df_dt, baseField):\n",
    "    general_df = df_dt.select_dtypes(include=[\"number\", \"category\", \"bool\"])\n",
    "    corr_gen = general_df.apply(lambda x : pd.factorize(x)[0]).corr(method='pearson', min_periods=1)\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    sns.heatmap(corr_gen, annot=False, xticklabels=True, yticklabels=True)\n",
    "    \n",
    "    corr_cat = corr_gen.unstack().abs().sort_values(ascending=False)\n",
    "\n",
    "    corr_gen = corr_gen.unstack().abs().sort_values(ascending=False)\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    corr_gen[baseField].plot.bar(legend=False, figsize=(20, 20))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    print(corr_gen[baseField].to_markdown())"
   ],
   "metadata": {
    "jupyter": {
     "source_hidden": false,
     "outputs_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "ExecuteTime": {
     "end_time": "2025-12-04T20:48:41.426788Z",
     "start_time": "2025-12-04T20:48:41.422792Z"
    }
   },
   "outputs": [],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
